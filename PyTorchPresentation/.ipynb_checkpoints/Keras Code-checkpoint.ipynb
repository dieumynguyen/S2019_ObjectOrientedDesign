{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automatic & Effective Honeybee Hive Monitoring Using Artificial Neural Networks \n",
    "CSCI 5502 F2018 - Data Mining <br>\n",
    "Final Project <br>\n",
    "<i> Team members: Dieu My Nguyen, Golnar Gharooni Fard </i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the base code for our best performing CNN (measured by overall and individual class accuracies as well as the F-1 measure). See the following settings for different models we ran:\n",
    "\n",
    "<u><b> 1. No data augmentation, basic CNN: </b></u>\n",
    "\n",
    "```python\n",
    "generator = ImageDataGenerator(\n",
    "                featurewise_center = False, \n",
    "                samplewise_center = False, \n",
    "                featurewise_std_normalization = False, \n",
    "                samplewise_std_normalization = False,  \n",
    "                zca_whitening = False,  \n",
    "                rotation_range = 0,  \n",
    "                zoom_range = 0, \n",
    "                width_shift_range = 0, \n",
    "                height_shift_range = 0, \n",
    "                horizontal_flip = False, \n",
    "                vertical_flip = False) \n",
    "```\n",
    "```python\n",
    "model2 = Sequential()\n",
    "model2.add(Conv2D(5, kernel_size=3, \n",
    "          input_shape=(img_width, img_height,3), \n",
    "          activation='relu', padding='same'))\n",
    "model2.add(MaxPool2D(2))\n",
    "model2.add(Conv2D(10, kernel_size=3, \n",
    "          activation='relu', padding='same'))\n",
    "model2.add(Flatten())\n",
    "model2.add(Dense(train_y.columns.size, activation='softmax'))\n",
    "```\n",
    "\n",
    "<u><b> 2. Offline data augmentation, basic CNN: </b></u>\n",
    "\n",
    "See dataset_generation.ipynb for generating augmented dataset. <br>\n",
    "CNN architecture same as above.\n",
    "\n",
    "<u><b> 3. Online data augmentation, basic CNN: </b></u>\n",
    "\n",
    "```python\n",
    "generator = ImageDataGenerator(\n",
    "                featurewise_center = False, \n",
    "                samplewise_center = False, \n",
    "                featurewise_std_normalization = False, \n",
    "                samplewise_std_normalization = False,  \n",
    "                zca_whitening = False,  \n",
    "                rotation_range = 180,  \n",
    "                zoom_range = 0.1, \n",
    "                width_shift_range = 0.2, \n",
    "                height_shift_range = 0.2, \n",
    "                horizontal_flip = True, \n",
    "                vertical_flip = True)\n",
    "```\n",
    "\n",
    "CNN architecture same as above.\n",
    "\n",
    "<u><b> 4. Online data augmentation, complex CNN: </b></u>\n",
    "\n",
    "Same generator as above.\n",
    "\n",
    "```python\n",
    "model2 = Sequential()\n",
    "model2.add(Conv2D(5, kernel_size=3, \n",
    "          input_shape=(img_width, img_height,3), \n",
    "          activation='relu', padding='same'))\n",
    "model2.add(MaxPool2D(2))\n",
    "model2.add(Conv2D(10, kernel_size=3, \n",
    "          activation='relu', padding='same'))\n",
    "model2.add(MaxPool2D(2))\n",
    "model2.add(Conv2D(50, kernel_size=3, \n",
    "          activation='relu', padding='same'))\n",
    "model2.add(MaxPool2D(2))\n",
    "model2.add(Flatten())\n",
    "model2.add(Dense(train_y.columns.size, activation='softmax'))\n",
    "```\n",
    "\n",
    "<u><b> 5. Online data augmentation, complex CNN + dropout: </b></u>\n",
    "\n",
    "Same generator as above.\n",
    "\n",
    "```python\n",
    "model2=Sequential()\n",
    "model2.add(Conv2D(5, kernel_size=3, \n",
    "          input_shape=(img_width, img_height,3), \n",
    "          activation='relu', padding='same'))\n",
    "model2.add(MaxPool2D(2))\n",
    "model2.add(Conv2D(10, kernel_size=3, \n",
    "          activation='relu', padding='same'))\n",
    "model2.add(MaxPool2D(2))\n",
    "model2.add(Conv2D(50, kernel_size=3, \n",
    "          activation='relu', padding='same'))\n",
    "model2.add(MaxPool2D(2))\n",
    "model2.add(Flatten())\n",
    "model2.add(Dense(units=100, activation='relu'  ))\n",
    "model2.add(Dropout(0.1))\n",
    "model2.add(Dense(units=100, activation='relu'  ))\n",
    "model2.add(Dropout(0.1))\n",
    "model2.add(Dense(units=100, activation='relu'  ))\n",
    "model2.add(Dropout(0.3))\n",
    "model2.add(Dense(train_y.columns.size, activation='softmax'))\n",
    "```\n",
    "\n",
    "<u><b> 6. Online data augmentation, more complex CNN + dropout: </b></u>\n",
    "\n",
    "```python\n",
    "def cnn():\n",
    "    kernel = (3, 3) # size of our kernel\n",
    "    model = Sequential() # first layer    \n",
    "    model.add(Conv2D(96, kernel , activation = 'relu', \n",
    "                     padding = 'same', \n",
    "                     input_shape = (img_width,img_height,img_channels)))    \n",
    "    model.add(Dropout(0.2)) # prevent the model from overfitting    \n",
    "    model.add(Conv2D(96, kernel, activation = 'relu', padding = 'same'))  \n",
    "    model.add(Conv2D(96, kernel, activation = 'relu', padding = 'same', strides = 2))    \n",
    "    model.add(Dropout(0.5)) # prevent the model from overfitting\n",
    "    model.add(Conv2D(192, kernel, activation = 'relu', padding = 'same'))    \n",
    "    model.add(Conv2D(192, kernel, activation = 'relu', padding = 'same'))\n",
    "    model.add(Conv2D(192, kernel, activation = 'relu', padding = 'same', strides = 2))    \n",
    "    model.add(Dropout(0.5))        \n",
    "    model.add(Conv2D(192, kernel, padding = 'same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(192, (1, 1),padding = 'valid'))\n",
    "    model.add(Activation('relu'))\n",
    "    # number of neurons in the last layer are \n",
    "    # equal to the number of output class labeles\n",
    "    model.add(Conv2D(6, (1, 1), padding = 'valid'))\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    model.add(Activation('softmax'))\n",
    "    model.summary()\n",
    "    return model\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base code for CNN image classifier "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Imports & settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################\n",
    "# Libraries\n",
    "#####################################\n",
    "\n",
    "# Common libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "# Image processing\n",
    "import imageio\n",
    "import skimage\n",
    "import skimage.io\n",
    "import skimage.transform\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style='ticks', palette='Set2')\n",
    "\n",
    "# Sklearn\n",
    "import scipy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "# Keras & Tensorflow\n",
    "import tensorflow\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten, MaxPool2D, Dropout, BatchNormalization, LeakyReLU\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers.core import Activation\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.callbacks import History\n",
    "\n",
    "#####################################\n",
    "# Settings\n",
    "#####################################\n",
    "\n",
    "# Set random seed to make results reproducable\n",
    "np.random.seed(42)\n",
    "tensorflow.set_random_seed(42)\n",
    "\n",
    "# Global variables\n",
    "img_folder = 'honey-bee-annotated-images/bee_imgs/'\n",
    "img_width = 100\n",
    "img_height = 100\n",
    "img_channels = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Read & process data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Read and process csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read csv data containing image filenames and class labels\n",
    "bees = pd.read_csv('honey-bee-annotated-images/bee_data.csv', \n",
    "                    index_col = False,  \n",
    "                    parse_dates = {'datetime':[1, 2]},\n",
    "                    dtype = {'subspecies':'category', 'health':'category','caste':'category'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>file</th>\n",
       "      <th>location</th>\n",
       "      <th>zip code</th>\n",
       "      <th>subspecies</th>\n",
       "      <th>health</th>\n",
       "      <th>pollen_carrying</th>\n",
       "      <th>caste</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-08-28 16:07:00</td>\n",
       "      <td>041_066.png</td>\n",
       "      <td>Alvin, TX, USA</td>\n",
       "      <td>77511</td>\n",
       "      <td>-1</td>\n",
       "      <td>hive being robbed</td>\n",
       "      <td>False</td>\n",
       "      <td>worker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-08-28 16:07:00</td>\n",
       "      <td>041_072.png</td>\n",
       "      <td>Alvin, TX, USA</td>\n",
       "      <td>77511</td>\n",
       "      <td>-1</td>\n",
       "      <td>hive being robbed</td>\n",
       "      <td>False</td>\n",
       "      <td>worker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-08-28 16:07:00</td>\n",
       "      <td>041_073.png</td>\n",
       "      <td>Alvin, TX, USA</td>\n",
       "      <td>77511</td>\n",
       "      <td>-1</td>\n",
       "      <td>hive being robbed</td>\n",
       "      <td>False</td>\n",
       "      <td>worker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-08-28 16:07:00</td>\n",
       "      <td>041_067.png</td>\n",
       "      <td>Alvin, TX, USA</td>\n",
       "      <td>77511</td>\n",
       "      <td>-1</td>\n",
       "      <td>hive being robbed</td>\n",
       "      <td>False</td>\n",
       "      <td>worker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-08-28 16:07:00</td>\n",
       "      <td>041_059.png</td>\n",
       "      <td>Alvin, TX, USA</td>\n",
       "      <td>77511</td>\n",
       "      <td>-1</td>\n",
       "      <td>hive being robbed</td>\n",
       "      <td>False</td>\n",
       "      <td>worker</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             datetime         file        location  zip code subspecies  \\\n",
       "0 2018-08-28 16:07:00  041_066.png  Alvin, TX, USA     77511         -1   \n",
       "1 2018-08-28 16:07:00  041_072.png  Alvin, TX, USA     77511         -1   \n",
       "2 2018-08-28 16:07:00  041_073.png  Alvin, TX, USA     77511         -1   \n",
       "3 2018-08-28 16:07:00  041_067.png  Alvin, TX, USA     77511         -1   \n",
       "4 2018-08-28 16:07:00  041_059.png  Alvin, TX, USA     77511         -1   \n",
       "\n",
       "              health  pollen_carrying   caste  \n",
       "0  hive being robbed            False  worker  \n",
       "1  hive being robbed            False  worker  \n",
       "2  hive being robbed            False  worker  \n",
       "3  hive being robbed            False  worker  \n",
       "4  hive being robbed            False  worker  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop nans\n",
    "bees.dropna(inplace = True)\n",
    "\n",
    "# Filter out image files that don't exist\n",
    "img_exists = bees['file'].apply(lambda f: os.path.exists(img_folder + f))\n",
    "bees = bees[img_exists]\n",
    "\n",
    "# View head of dataframe\n",
    "bees.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_img(file):\n",
    "    \"\"\"\n",
    "    Read and resize an image to defined size, adjust channels. \n",
    "    Note: This function uses global vars: img_folder, img_channels\n",
    "    \"\"\"\n",
    "    img = skimage.io.imread(img_folder + file)\n",
    "    img = skimage.transform.resize(img, (img_width, img_height), mode='reflect')\n",
    "    \n",
    "    return img[:,:,:img_channels]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Split and plot data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(bees):\n",
    "    \"\"\" \n",
    "    Split to train, test, and validation. \n",
    "    @param bees: Bee dataset to split\n",
    "    \"\"\"\n",
    "    # Split to train and test\n",
    "    train_bees, test_bees = train_test_split(bees, random_state=24)\n",
    "\n",
    "    # Split train to train and validation datasets\n",
    "    # Validation for use during training\n",
    "    train_bees, val_bees = train_test_split(train_bees, test_size=0.1, random_state=24)\n",
    "\n",
    "    return train_bees, val_bees, test_bees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data(bees, class_name):\n",
    "    \"\"\"\n",
    "    Plot distribution of classes\n",
    "    @param bees: total dataset to use\n",
    "    @param class_name: class in dataset to plot\n",
    "    \"\"\"\n",
    "    fig = plt.figure(figsize=(8,4))\n",
    "    plt.xticks(rotation=20)\n",
    "    plt.ylabel('Count')\n",
    "    plt.hist(bees[class_name], align='left', orientation='vertical')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_balanced(train_bees, field_name):\n",
    "    \"\"\"\n",
    "    Plot distribution of field by categories before and after balancing\n",
    "    @param train_bees: before balancing\n",
    "    @param train_bees_bal: after balancing\n",
    "    @param field_name: balancing field\n",
    "    \"\"\"\n",
    "    f, ax = plt.subplots(1, 1, figsize=(3,4))\n",
    "    ax = train_bees[field_name].value_counts().plot(kind='bar', width=0.8)\n",
    "    ax.set_title('%s' % field_name)\n",
    "    ax.set_ylabel('Count')\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "train_bees, val_bees, test_bees = split_data(bees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c2a4cf5f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_balanced(train_bees, 'health')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Online data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare2train(train_bees, val_bees, test_bees, field_name):\n",
    "    \"\"\"\n",
    "    Load images for features, drop other columns\n",
    "    One hot encode for label, drop other columns\n",
    "    @return: image generator, train images, validation images, test images, train labels, validation labels, test labels\n",
    "    \"\"\"\n",
    "    # Bees already splitted to train, validation and test\n",
    "    # Load and transform images to have equal width/height/channels. \n",
    "    # read_img function is defined in the beginning to use in both health and subspecies. \n",
    "    # Use np.stack to get NumPy array for CNN input\n",
    "\n",
    "    # Train data\n",
    "    train_X = np.stack(train_bees['file'].apply(read_img))\n",
    "    train_y  = pd.get_dummies(train_bees[field_name], drop_first=False)\n",
    "\n",
    "    # Validation during training data to calc val_loss metric\n",
    "    val_X = np.stack(val_bees['file'].apply(read_img))\n",
    "    val_y = pd.get_dummies(val_bees[field_name], drop_first=False)\n",
    "\n",
    "    # Test data\n",
    "    test_X = np.stack(test_bees['file'].apply(read_img))\n",
    "    test_y = pd.get_dummies(test_bees[field_name], drop_first=False)\n",
    "\n",
    "    # Data augmentation - a little bit rotate, zoom and shift input images.\n",
    "    generator = ImageDataGenerator(\n",
    "            featurewise_center = False,  # set input mean to 0 over the dataset\n",
    "            samplewise_center = False,  # set each sample mean to 0\n",
    "            featurewise_std_normalization = False,  # divide inputs by std of the dataset\n",
    "            samplewise_std_normalization = False,  # divide each input by its std\n",
    "            zca_whitening = False,  # apply ZCA whitening\n",
    "            rotation_range = 180,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "            zoom_range = 0.1, # Randomly zoom image \n",
    "            width_shift_range = 0.2,  # randomly shift images horizontally (fraction of total width)\n",
    "            height_shift_range = 0.2,  # randomly shift images vertically (fraction of total height)\n",
    "            horizontal_flip = True,  # randomly flip images\n",
    "            vertical_flip = True)\n",
    "\n",
    "    generator.fit(train_X)\n",
    "    \n",
    "    return (generator, train_X, val_X, test_X, train_y, val_y, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call image preparation and one hot encoding\n",
    "generator, train_X, val_X, test_X, train_y, val_y, test_y = prepare2train(train_bees, val_bees, test_bees, 'health')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. CNN for classification of bee colony health"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "50/50 [==============================] - 114s 2s/step - loss: 1.2376 - acc: 0.6237 - val_loss: 1.0982 - val_acc: 0.6443\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.64433, saving model to best_cnn.h5\n",
      "Epoch 2/1000\n",
      "50/50 [==============================] - 33s 656ms/step - loss: 0.9540 - acc: 0.6568 - val_loss: 0.8131 - val_acc: 0.6881\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.64433 to 0.68814, saving model to best_cnn.h5\n",
      "Epoch 3/1000\n",
      "50/50 [==============================] - 32s 649ms/step - loss: 0.8035 - acc: 0.6867 - val_loss: 0.6870 - val_acc: 0.7088\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.68814 to 0.70876, saving model to best_cnn.h5\n",
      "Epoch 4/1000\n",
      "50/50 [==============================] - 36s 725ms/step - loss: 0.6865 - acc: 0.7203 - val_loss: 0.5571 - val_acc: 0.7887\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.70876 to 0.78866, saving model to best_cnn.h5\n",
      "Epoch 5/1000\n",
      "50/50 [==============================] - 52s 1s/step - loss: 0.5599 - acc: 0.7760 - val_loss: 0.5485 - val_acc: 0.7964\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.78866 to 0.79639, saving model to best_cnn.h5\n",
      "Epoch 6/1000\n",
      "50/50 [==============================] - 31s 623ms/step - loss: 0.5409 - acc: 0.7854 - val_loss: 0.5348 - val_acc: 0.7706\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.79639\n",
      "Epoch 7/1000\n",
      "50/50 [==============================] - 33s 660ms/step - loss: 0.4805 - acc: 0.8050 - val_loss: 0.5761 - val_acc: 0.7397\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.79639\n",
      "Epoch 8/1000\n",
      "50/50 [==============================] - 37s 733ms/step - loss: 0.4708 - acc: 0.8171 - val_loss: 0.4227 - val_acc: 0.8093\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.79639 to 0.80928, saving model to best_cnn.h5\n",
      "Epoch 9/1000\n",
      "50/50 [==============================] - 31s 619ms/step - loss: 0.4315 - acc: 0.8208 - val_loss: 0.4902 - val_acc: 0.7577\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.80928\n",
      "Epoch 10/1000\n",
      "50/50 [==============================] - 30s 607ms/step - loss: 0.4032 - acc: 0.8314 - val_loss: 0.4253 - val_acc: 0.8015\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.80928\n",
      "Epoch 11/1000\n",
      "50/50 [==============================] - 32s 633ms/step - loss: 0.3896 - acc: 0.8409 - val_loss: 0.3548 - val_acc: 0.8273\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.80928 to 0.82732, saving model to best_cnn.h5\n",
      "Epoch 12/1000\n",
      "50/50 [==============================] - 25s 492ms/step - loss: 0.3573 - acc: 0.8482 - val_loss: 0.4775 - val_acc: 0.8170\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.82732\n",
      "Epoch 13/1000\n",
      "50/50 [==============================] - 24s 481ms/step - loss: 0.3774 - acc: 0.8376 - val_loss: 0.5435 - val_acc: 0.7758\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.82732\n",
      "Epoch 14/1000\n",
      "50/50 [==============================] - 24s 484ms/step - loss: 0.3413 - acc: 0.8537 - val_loss: 0.3404 - val_acc: 0.8402\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.82732 to 0.84021, saving model to best_cnn.h5\n",
      "Epoch 15/1000\n",
      "50/50 [==============================] - 24s 479ms/step - loss: 0.3089 - acc: 0.8657 - val_loss: 0.3063 - val_acc: 0.8840\n",
      "\n",
      "Epoch 00015: val_acc improved from 0.84021 to 0.88402, saving model to best_cnn.h5\n",
      "Epoch 16/1000\n",
      "50/50 [==============================] - 24s 477ms/step - loss: 0.3210 - acc: 0.8664 - val_loss: 0.3377 - val_acc: 0.8737\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.88402\n",
      "Epoch 17/1000\n",
      "50/50 [==============================] - 24s 486ms/step - loss: 0.3457 - acc: 0.8545 - val_loss: 0.2974 - val_acc: 0.8582\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.88402\n",
      "Epoch 18/1000\n",
      "50/50 [==============================] - 24s 483ms/step - loss: 0.2920 - acc: 0.8738 - val_loss: 0.3077 - val_acc: 0.8840\n",
      "\n",
      "Epoch 00018: val_acc improved from 0.88402 to 0.88402, saving model to best_cnn.h5\n",
      "Epoch 19/1000\n",
      "50/50 [==============================] - 24s 488ms/step - loss: 0.3145 - acc: 0.8758 - val_loss: 0.4556 - val_acc: 0.8041\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.88402\n",
      "Epoch 20/1000\n",
      "50/50 [==============================] - 24s 481ms/step - loss: 0.2972 - acc: 0.8660 - val_loss: 0.2775 - val_acc: 0.8814\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.88402\n",
      "Epoch 21/1000\n",
      "50/50 [==============================] - 26s 529ms/step - loss: 0.2727 - acc: 0.8872 - val_loss: 0.3382 - val_acc: 0.8866\n",
      "\n",
      "Epoch 00021: val_acc improved from 0.88402 to 0.88660, saving model to best_cnn.h5\n",
      "Epoch 22/1000\n",
      "50/50 [==============================] - 25s 499ms/step - loss: 0.2461 - acc: 0.8913 - val_loss: 0.2335 - val_acc: 0.9098\n",
      "\n",
      "Epoch 00022: val_acc improved from 0.88660 to 0.90979, saving model to best_cnn.h5\n",
      "Epoch 23/1000\n",
      "50/50 [==============================] - 24s 480ms/step - loss: 0.2545 - acc: 0.8831 - val_loss: 0.2419 - val_acc: 0.8840\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.90979\n",
      "Epoch 24/1000\n",
      "50/50 [==============================] - 27s 531ms/step - loss: 0.2370 - acc: 0.8940 - val_loss: 0.2519 - val_acc: 0.9175\n",
      "\n",
      "Epoch 00024: val_acc improved from 0.90979 to 0.91753, saving model to best_cnn.h5\n",
      "Epoch 25/1000\n",
      "50/50 [==============================] - 26s 530ms/step - loss: 0.2544 - acc: 0.8858 - val_loss: 0.2332 - val_acc: 0.8995\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.91753\n",
      "Epoch 26/1000\n",
      "50/50 [==============================] - 26s 512ms/step - loss: 0.2575 - acc: 0.8861 - val_loss: 0.2849 - val_acc: 0.9072\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.91753\n",
      "Epoch 27/1000\n",
      "50/50 [==============================] - 27s 533ms/step - loss: 0.2252 - acc: 0.8990 - val_loss: 0.2486 - val_acc: 0.8763\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.91753\n",
      "Epoch 28/1000\n",
      "50/50 [==============================] - 26s 514ms/step - loss: 0.2626 - acc: 0.8838 - val_loss: 0.2318 - val_acc: 0.9046\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.91753\n",
      "Epoch 29/1000\n",
      "50/50 [==============================] - 26s 513ms/step - loss: 0.2465 - acc: 0.8894 - val_loss: 0.2135 - val_acc: 0.9330\n",
      "\n",
      "Epoch 00029: val_acc improved from 0.91753 to 0.93299, saving model to best_cnn.h5\n",
      "Epoch 30/1000\n",
      "50/50 [==============================] - 27s 542ms/step - loss: 0.2093 - acc: 0.9102 - val_loss: 0.2705 - val_acc: 0.8737\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.93299\n",
      "Epoch 31/1000\n",
      "50/50 [==============================] - 27s 540ms/step - loss: 0.2137 - acc: 0.8943 - val_loss: 0.2061 - val_acc: 0.9124\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.93299\n",
      "Epoch 32/1000\n",
      "50/50 [==============================] - 26s 516ms/step - loss: 0.2179 - acc: 0.9031 - val_loss: 0.2237 - val_acc: 0.9072\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.93299\n",
      "Epoch 33/1000\n",
      "50/50 [==============================] - 28s 560ms/step - loss: 0.2295 - acc: 0.8990 - val_loss: 0.2069 - val_acc: 0.9149\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.93299\n",
      "Epoch 34/1000\n",
      "50/50 [==============================] - 28s 559ms/step - loss: 0.2406 - acc: 0.8916 - val_loss: 0.2510 - val_acc: 0.9175\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.93299\n",
      "Epoch 35/1000\n",
      "50/50 [==============================] - 26s 524ms/step - loss: 0.2825 - acc: 0.8867 - val_loss: 0.2401 - val_acc: 0.9175\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.93299\n",
      "Epoch 36/1000\n",
      "50/50 [==============================] - 26s 525ms/step - loss: 0.2042 - acc: 0.9048 - val_loss: 0.2518 - val_acc: 0.8969\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.93299\n",
      "Epoch 37/1000\n",
      "50/50 [==============================] - 26s 514ms/step - loss: 0.2008 - acc: 0.9085 - val_loss: 0.2221 - val_acc: 0.9278\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.93299\n",
      "Epoch 38/1000\n",
      "50/50 [==============================] - 30s 595ms/step - loss: 0.2081 - acc: 0.9121 - val_loss: 0.2315 - val_acc: 0.9072\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.93299\n",
      "Epoch 39/1000\n",
      "50/50 [==============================] - 29s 585ms/step - loss: 0.2089 - acc: 0.9038 - val_loss: 0.2288 - val_acc: 0.8814\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.93299\n",
      "Epoch 40/1000\n",
      "50/50 [==============================] - 27s 540ms/step - loss: 0.2323 - acc: 0.9007 - val_loss: 0.2850 - val_acc: 0.8789\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.93299\n",
      "Epoch 41/1000\n",
      "50/50 [==============================] - 26s 515ms/step - loss: 0.2073 - acc: 0.9143 - val_loss: 0.2662 - val_acc: 0.8918\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.93299\n",
      "Epoch 42/1000\n",
      "50/50 [==============================] - 26s 515ms/step - loss: 0.1807 - acc: 0.9167 - val_loss: 0.2008 - val_acc: 0.9201\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.93299\n",
      "Epoch 43/1000\n",
      "50/50 [==============================] - 26s 520ms/step - loss: 0.2284 - acc: 0.9004 - val_loss: 0.2040 - val_acc: 0.9175\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.93299\n",
      "Epoch 44/1000\n",
      "50/50 [==============================] - 26s 517ms/step - loss: 0.2262 - acc: 0.8982 - val_loss: 0.1927 - val_acc: 0.9433\n",
      "\n",
      "Epoch 00044: val_acc improved from 0.93299 to 0.94330, saving model to best_cnn.h5\n",
      "Epoch 45/1000\n",
      "50/50 [==============================] - 27s 538ms/step - loss: 0.2244 - acc: 0.9011 - val_loss: 0.2455 - val_acc: 0.9098\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.94330\n",
      "Epoch 46/1000\n",
      "50/50 [==============================] - 26s 530ms/step - loss: 0.2268 - acc: 0.9040 - val_loss: 0.1979 - val_acc: 0.9201\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.94330\n",
      "Epoch 47/1000\n",
      "50/50 [==============================] - 25s 506ms/step - loss: 0.1764 - acc: 0.9167 - val_loss: 0.2123 - val_acc: 0.9175\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.94330\n",
      "Epoch 48/1000\n",
      "50/50 [==============================] - 25s 507ms/step - loss: 0.1879 - acc: 0.9078 - val_loss: 0.2332 - val_acc: 0.8943\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.94330\n",
      "Epoch 49/1000\n",
      "50/50 [==============================] - 26s 521ms/step - loss: 0.2082 - acc: 0.9037 - val_loss: 0.2502 - val_acc: 0.9124\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.94330\n",
      "Epoch 50/1000\n",
      "50/50 [==============================] - 26s 519ms/step - loss: 0.1915 - acc: 0.9092 - val_loss: 0.1985 - val_acc: 0.9433\n",
      "\n",
      "Epoch 00050: val_acc improved from 0.94330 to 0.94330, saving model to best_cnn.h5\n",
      "Epoch 51/1000\n",
      "50/50 [==============================] - 27s 543ms/step - loss: 0.1783 - acc: 0.9161 - val_loss: 0.2106 - val_acc: 0.9330\n",
      "\n",
      "Epoch 00051: val_acc did not improve from 0.94330\n",
      "Epoch 52/1000\n",
      "50/50 [==============================] - 30s 610ms/step - loss: 0.2232 - acc: 0.9046 - val_loss: 0.1742 - val_acc: 0.9381\n",
      "\n",
      "Epoch 00052: val_acc did not improve from 0.94330\n",
      "Epoch 53/1000\n",
      "50/50 [==============================] - 27s 539ms/step - loss: 0.1932 - acc: 0.9153 - val_loss: 0.1753 - val_acc: 0.9227\n",
      "\n",
      "Epoch 00053: val_acc did not improve from 0.94330\n",
      "Epoch 54/1000\n",
      "50/50 [==============================] - 26s 516ms/step - loss: 0.1744 - acc: 0.9154 - val_loss: 0.1940 - val_acc: 0.9330\n",
      "\n",
      "Epoch 00054: val_acc did not improve from 0.94330\n",
      "Epoch 55/1000\n",
      "50/50 [==============================] - 25s 507ms/step - loss: 0.1736 - acc: 0.9180 - val_loss: 0.1836 - val_acc: 0.9381\n",
      "\n",
      "Epoch 00055: val_acc did not improve from 0.94330\n",
      "Epoch 56/1000\n",
      "50/50 [==============================] - 25s 503ms/step - loss: 0.1728 - acc: 0.9159 - val_loss: 0.1719 - val_acc: 0.9459\n",
      "\n",
      "Epoch 00056: val_acc improved from 0.94330 to 0.94588, saving model to best_cnn.h5\n",
      "Epoch 57/1000\n",
      "50/50 [==============================] - 26s 519ms/step - loss: 0.1974 - acc: 0.9163 - val_loss: 0.1774 - val_acc: 0.9149\n",
      "\n",
      "Epoch 00057: val_acc did not improve from 0.94588\n",
      "Epoch 58/1000\n",
      "50/50 [==============================] - 26s 523ms/step - loss: 0.1764 - acc: 0.9235 - val_loss: 0.1667 - val_acc: 0.9485\n",
      "\n",
      "Epoch 00058: val_acc improved from 0.94588 to 0.94845, saving model to best_cnn.h5\n",
      "Epoch 59/1000\n",
      "50/50 [==============================] - 26s 513ms/step - loss: 0.1752 - acc: 0.9136 - val_loss: 0.1951 - val_acc: 0.9356\n",
      "\n",
      "Epoch 00059: val_acc did not improve from 0.94845\n",
      "Epoch 60/1000\n",
      "50/50 [==============================] - 26s 517ms/step - loss: 0.1748 - acc: 0.9213 - val_loss: 0.1953 - val_acc: 0.9407\n",
      "\n",
      "Epoch 00060: val_acc did not improve from 0.94845\n",
      "Epoch 61/1000\n",
      "50/50 [==============================] - 25s 505ms/step - loss: 0.1630 - acc: 0.9216 - val_loss: 0.1629 - val_acc: 0.9356\n",
      "\n",
      "Epoch 00061: val_acc did not improve from 0.94845\n",
      "Epoch 62/1000\n",
      "50/50 [==============================] - 25s 508ms/step - loss: 0.1752 - acc: 0.9205 - val_loss: 0.2384 - val_acc: 0.9124\n",
      "\n",
      "Epoch 00062: val_acc did not improve from 0.94845\n",
      "Epoch 63/1000\n",
      "50/50 [==============================] - 26s 529ms/step - loss: 0.1890 - acc: 0.9146 - val_loss: 0.2111 - val_acc: 0.9304\n",
      "\n",
      "Epoch 00063: val_acc did not improve from 0.94845\n",
      "Epoch 64/1000\n",
      "50/50 [==============================] - 25s 507ms/step - loss: 0.1858 - acc: 0.9234 - val_loss: 0.1737 - val_acc: 0.9381\n",
      "\n",
      "Epoch 00064: val_acc did not improve from 0.94845\n",
      "Epoch 65/1000\n",
      "50/50 [==============================] - 25s 509ms/step - loss: 0.1761 - acc: 0.9204 - val_loss: 0.1739 - val_acc: 0.9485\n",
      "\n",
      "Epoch 00065: val_acc did not improve from 0.94845\n",
      "Epoch 66/1000\n",
      "50/50 [==============================] - 25s 510ms/step - loss: 0.1571 - acc: 0.9310 - val_loss: 0.1720 - val_acc: 0.9433\n",
      "\n",
      "Epoch 00066: val_acc did not improve from 0.94845\n",
      "Epoch 67/1000\n",
      "50/50 [==============================] - 31s 618ms/step - loss: 0.1511 - acc: 0.9309 - val_loss: 0.1781 - val_acc: 0.9330\n",
      "\n",
      "Epoch 00067: val_acc did not improve from 0.94845\n",
      "Epoch 68/1000\n",
      "50/50 [==============================] - 32s 643ms/step - loss: 0.1739 - acc: 0.9250 - val_loss: 0.2378 - val_acc: 0.9330\n",
      "\n",
      "Epoch 00068: val_acc did not improve from 0.94845\n",
      "Epoch 69/1000\n",
      "50/50 [==============================] - 28s 550ms/step - loss: 0.1695 - acc: 0.9260 - val_loss: 0.2519 - val_acc: 0.9021\n",
      "\n",
      "Epoch 00069: val_acc did not improve from 0.94845\n",
      "Epoch 70/1000\n",
      "50/50 [==============================] - 28s 551ms/step - loss: 0.1648 - acc: 0.9296 - val_loss: 0.1662 - val_acc: 0.9485\n",
      "\n",
      "Epoch 00070: val_acc did not improve from 0.94845\n",
      "Epoch 71/1000\n",
      "50/50 [==============================] - 29s 584ms/step - loss: 0.1887 - acc: 0.9243 - val_loss: 0.1772 - val_acc: 0.9407\n",
      "\n",
      "Epoch 00071: val_acc did not improve from 0.94845\n",
      "Epoch 72/1000\n",
      "50/50 [==============================] - 26s 526ms/step - loss: 0.1452 - acc: 0.9350 - val_loss: 0.1837 - val_acc: 0.9485\n",
      "\n",
      "Epoch 00072: val_acc did not improve from 0.94845\n",
      "Epoch 73/1000\n",
      "50/50 [==============================] - 27s 538ms/step - loss: 0.1509 - acc: 0.9287 - val_loss: 0.2216 - val_acc: 0.9304\n",
      "\n",
      "Epoch 00073: val_acc did not improve from 0.94845\n",
      "Epoch 74/1000\n",
      "50/50 [==============================] - 44s 879ms/step - loss: 0.1533 - acc: 0.9335 - val_loss: 0.1630 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00074: val_acc improved from 0.94845 to 0.95876, saving model to best_cnn.h5\n",
      "Epoch 75/1000\n",
      "50/50 [==============================] - 35s 698ms/step - loss: 0.1530 - acc: 0.9326 - val_loss: 0.1664 - val_acc: 0.9485\n",
      "\n",
      "Epoch 00075: val_acc did not improve from 0.95876\n",
      "Epoch 76/1000\n",
      "50/50 [==============================] - 37s 745ms/step - loss: 0.2279 - acc: 0.9071 - val_loss: 0.1686 - val_acc: 0.9562\n",
      "\n",
      "Epoch 00076: val_acc did not improve from 0.95876\n",
      "Epoch 77/1000\n",
      "50/50 [==============================] - 35s 691ms/step - loss: 0.1606 - acc: 0.9301 - val_loss: 0.1476 - val_acc: 0.9562\n",
      "\n",
      "Epoch 00077: val_acc did not improve from 0.95876\n",
      "Epoch 78/1000\n",
      "50/50 [==============================] - 27s 547ms/step - loss: 0.1350 - acc: 0.9380 - val_loss: 0.1455 - val_acc: 0.9485\n",
      "\n",
      "Epoch 00078: val_acc did not improve from 0.95876\n",
      "Epoch 79/1000\n",
      "50/50 [==============================] - 25s 502ms/step - loss: 0.1427 - acc: 0.9317 - val_loss: 0.1888 - val_acc: 0.9459\n",
      "\n",
      "Epoch 00079: val_acc did not improve from 0.95876\n",
      "Epoch 80/1000\n",
      "50/50 [==============================] - 32s 634ms/step - loss: 0.1837 - acc: 0.9291 - val_loss: 0.2196 - val_acc: 0.9381\n",
      "\n",
      "Epoch 00080: val_acc did not improve from 0.95876\n",
      "Epoch 81/1000\n",
      "50/50 [==============================] - 491s 10s/step - loss: 0.1581 - acc: 0.9320 - val_loss: 0.1954 - val_acc: 0.9227\n",
      "\n",
      "Epoch 00081: val_acc did not improve from 0.95876\n",
      "Epoch 82/1000\n",
      "50/50 [==============================] - 50s 1s/step - loss: 0.1703 - acc: 0.9186 - val_loss: 0.1930 - val_acc: 0.9201\n",
      "\n",
      "Epoch 00082: val_acc did not improve from 0.95876\n",
      "Epoch 83/1000\n",
      "50/50 [==============================] - 36s 712ms/step - loss: 0.1586 - acc: 0.9250 - val_loss: 0.1752 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00083: val_acc improved from 0.95876 to 0.95876, saving model to best_cnn.h5\n",
      "Epoch 84/1000\n",
      "50/50 [==============================] - 41s 822ms/step - loss: 0.1392 - acc: 0.9417 - val_loss: 0.1577 - val_acc: 0.9639\n",
      "\n",
      "Epoch 00084: val_acc improved from 0.95876 to 0.96392, saving model to best_cnn.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/1000\n",
      "50/50 [==============================] - 35s 705ms/step - loss: 0.1515 - acc: 0.9323 - val_loss: 0.2213 - val_acc: 0.9021\n",
      "\n",
      "Epoch 00085: val_acc did not improve from 0.96392\n",
      "Epoch 86/1000\n",
      "50/50 [==============================] - 49s 974ms/step - loss: 0.1555 - acc: 0.9307 - val_loss: 0.1633 - val_acc: 0.9562\n",
      "\n",
      "Epoch 00086: val_acc did not improve from 0.96392\n",
      "Epoch 87/1000\n",
      "50/50 [==============================] - 34s 673ms/step - loss: 0.1591 - acc: 0.9269 - val_loss: 0.1611 - val_acc: 0.9613\n",
      "\n",
      "Epoch 00087: val_acc did not improve from 0.96392\n",
      "Epoch 88/1000\n",
      "50/50 [==============================] - 37s 736ms/step - loss: 0.1725 - acc: 0.9320 - val_loss: 0.1452 - val_acc: 0.9510\n",
      "\n",
      "Epoch 00088: val_acc did not improve from 0.96392\n",
      "Epoch 89/1000\n",
      "50/50 [==============================] - 29s 589ms/step - loss: 0.1449 - acc: 0.9331 - val_loss: 0.2094 - val_acc: 0.9433\n",
      "\n",
      "Epoch 00089: val_acc did not improve from 0.96392\n",
      "Epoch 90/1000\n",
      "50/50 [==============================] - 27s 548ms/step - loss: 0.1449 - acc: 0.9360 - val_loss: 0.1605 - val_acc: 0.9613\n",
      "\n",
      "Epoch 00090: val_acc did not improve from 0.96392\n",
      "Epoch 91/1000\n",
      "50/50 [==============================] - 27s 539ms/step - loss: 0.1448 - acc: 0.9352 - val_loss: 0.1800 - val_acc: 0.9330\n",
      "\n",
      "Epoch 00091: val_acc did not improve from 0.96392\n",
      "Epoch 92/1000\n",
      "50/50 [==============================] - 24s 485ms/step - loss: 0.1431 - acc: 0.9363 - val_loss: 0.1600 - val_acc: 0.9485\n",
      "\n",
      "Epoch 00092: val_acc did not improve from 0.96392\n",
      "Epoch 93/1000\n",
      "50/50 [==============================] - 24s 474ms/step - loss: 0.1808 - acc: 0.9295 - val_loss: 0.1682 - val_acc: 0.9381\n",
      "\n",
      "Epoch 00093: val_acc did not improve from 0.96392\n",
      "Epoch 94/1000\n",
      "50/50 [==============================] - 27s 548ms/step - loss: 0.1436 - acc: 0.9393 - val_loss: 0.1515 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00094: val_acc did not improve from 0.96392\n",
      "Epoch 95/1000\n",
      "50/50 [==============================] - 35s 696ms/step - loss: 0.1610 - acc: 0.9295 - val_loss: 0.1563 - val_acc: 0.9459\n",
      "\n",
      "Epoch 00095: val_acc did not improve from 0.96392\n",
      "Epoch 96/1000\n",
      "50/50 [==============================] - 41s 822ms/step - loss: 0.1452 - acc: 0.9353 - val_loss: 0.1327 - val_acc: 0.9562\n",
      "\n",
      "Epoch 00096: val_acc did not improve from 0.96392\n",
      "Epoch 97/1000\n",
      "50/50 [==============================] - 35s 690ms/step - loss: 0.1487 - acc: 0.9404 - val_loss: 0.1598 - val_acc: 0.9356\n",
      "\n",
      "Epoch 00097: val_acc did not improve from 0.96392\n",
      "Epoch 98/1000\n",
      "50/50 [==============================] - 31s 618ms/step - loss: 0.1781 - acc: 0.9231 - val_loss: 0.1738 - val_acc: 0.9356\n",
      "\n",
      "Epoch 00098: val_acc did not improve from 0.96392\n",
      "Epoch 99/1000\n",
      "50/50 [==============================] - 26s 516ms/step - loss: 0.1450 - acc: 0.9413 - val_loss: 0.1595 - val_acc: 0.9304\n",
      "\n",
      "Epoch 00099: val_acc did not improve from 0.96392\n",
      "Epoch 100/1000\n",
      "50/50 [==============================] - 29s 583ms/step - loss: 0.1486 - acc: 0.9371 - val_loss: 0.1386 - val_acc: 0.9562\n",
      "\n",
      "Epoch 00100: val_acc did not improve from 0.96392\n",
      "Epoch 101/1000\n",
      "50/50 [==============================] - 32s 648ms/step - loss: 0.1299 - acc: 0.9443 - val_loss: 0.1397 - val_acc: 0.9691\n",
      "\n",
      "Epoch 00101: val_acc improved from 0.96392 to 0.96907, saving model to best_cnn.h5\n",
      "Epoch 102/1000\n",
      "50/50 [==============================] - 27s 533ms/step - loss: 0.1377 - acc: 0.9331 - val_loss: 0.1596 - val_acc: 0.9381\n",
      "\n",
      "Epoch 00102: val_acc did not improve from 0.96907\n",
      "Epoch 103/1000\n",
      "50/50 [==============================] - 35s 700ms/step - loss: 0.1657 - acc: 0.9309 - val_loss: 0.1670 - val_acc: 0.9613\n",
      "\n",
      "Epoch 00103: val_acc did not improve from 0.96907\n",
      "Epoch 104/1000\n",
      "50/50 [==============================] - 33s 670ms/step - loss: 0.1574 - acc: 0.9314 - val_loss: 0.1995 - val_acc: 0.9253\n",
      "\n",
      "Epoch 00104: val_acc did not improve from 0.96907\n",
      "Epoch 105/1000\n",
      "50/50 [==============================] - 35s 701ms/step - loss: 0.1414 - acc: 0.9427 - val_loss: 0.1244 - val_acc: 0.9613\n",
      "\n",
      "Epoch 00105: val_acc did not improve from 0.96907\n",
      "Epoch 106/1000\n",
      "50/50 [==============================] - 27s 544ms/step - loss: 0.1229 - acc: 0.9470 - val_loss: 0.1270 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00106: val_acc did not improve from 0.96907\n",
      "Epoch 107/1000\n",
      "50/50 [==============================] - 30s 594ms/step - loss: 0.1421 - acc: 0.9395 - val_loss: 0.1608 - val_acc: 0.9459\n",
      "\n",
      "Epoch 00107: val_acc did not improve from 0.96907\n",
      "Epoch 108/1000\n",
      "50/50 [==============================] - 30s 591ms/step - loss: 0.1396 - acc: 0.9450 - val_loss: 0.2241 - val_acc: 0.9330\n",
      "\n",
      "Epoch 00108: val_acc did not improve from 0.96907\n",
      "Epoch 109/1000\n",
      "50/50 [==============================] - 26s 516ms/step - loss: 0.1367 - acc: 0.9426 - val_loss: 0.1272 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00109: val_acc did not improve from 0.96907\n",
      "Epoch 110/1000\n",
      "50/50 [==============================] - 27s 547ms/step - loss: 0.1419 - acc: 0.9412 - val_loss: 0.1728 - val_acc: 0.9536\n",
      "\n",
      "Epoch 00110: val_acc did not improve from 0.96907\n",
      "Epoch 111/1000\n",
      "50/50 [==============================] - 29s 577ms/step - loss: 0.1182 - acc: 0.9497 - val_loss: 0.1371 - val_acc: 0.9485\n",
      "\n",
      "Epoch 00111: val_acc did not improve from 0.96907\n",
      "Epoch 112/1000\n",
      "50/50 [==============================] - 33s 662ms/step - loss: 0.1343 - acc: 0.9447 - val_loss: 0.1846 - val_acc: 0.9330\n",
      "\n",
      "Epoch 00112: val_acc did not improve from 0.96907\n",
      "Epoch 113/1000\n",
      "50/50 [==============================] - 28s 562ms/step - loss: 0.1259 - acc: 0.9443 - val_loss: 0.1492 - val_acc: 0.9459\n",
      "\n",
      "Epoch 00113: val_acc did not improve from 0.96907\n",
      "Epoch 114/1000\n",
      "50/50 [==============================] - 28s 557ms/step - loss: 0.2015 - acc: 0.9214 - val_loss: 0.1421 - val_acc: 0.9459\n",
      "\n",
      "Epoch 00114: val_acc did not improve from 0.96907\n",
      "Epoch 115/1000\n",
      "50/50 [==============================] - 25s 498ms/step - loss: 0.1371 - acc: 0.9409 - val_loss: 0.1634 - val_acc: 0.9304\n",
      "\n",
      "Epoch 00115: val_acc did not improve from 0.96907\n",
      "Epoch 116/1000\n",
      "50/50 [==============================] - 30s 606ms/step - loss: 0.1323 - acc: 0.9426 - val_loss: 0.1424 - val_acc: 0.9485\n",
      "\n",
      "Epoch 00116: val_acc did not improve from 0.96907\n",
      "Epoch 117/1000\n",
      "50/50 [==============================] - 40s 808ms/step - loss: 0.1267 - acc: 0.9420 - val_loss: 0.1324 - val_acc: 0.9536\n",
      "\n",
      "Epoch 00117: val_acc did not improve from 0.96907\n",
      "Epoch 118/1000\n",
      "50/50 [==============================] - 31s 626ms/step - loss: 0.1348 - acc: 0.9413 - val_loss: 0.1567 - val_acc: 0.9536\n",
      "\n",
      "Epoch 00118: val_acc did not improve from 0.96907\n",
      "Epoch 119/1000\n",
      "50/50 [==============================] - 30s 605ms/step - loss: 0.1178 - acc: 0.9493 - val_loss: 0.1350 - val_acc: 0.9485\n",
      "\n",
      "Epoch 00119: val_acc did not improve from 0.96907\n",
      "Epoch 120/1000\n",
      "50/50 [==============================] - 29s 583ms/step - loss: 0.1368 - acc: 0.9402 - val_loss: 0.1501 - val_acc: 0.9613\n",
      "\n",
      "Epoch 00120: val_acc did not improve from 0.96907\n",
      "Epoch 121/1000\n",
      "50/50 [==============================] - 29s 580ms/step - loss: 0.1462 - acc: 0.9362 - val_loss: 0.1525 - val_acc: 0.9381\n",
      "\n",
      "Epoch 00121: val_acc did not improve from 0.96907\n",
      "Epoch 122/1000\n",
      "50/50 [==============================] - 31s 625ms/step - loss: 0.1344 - acc: 0.9443 - val_loss: 0.1328 - val_acc: 0.9407\n",
      "\n",
      "Epoch 00122: val_acc did not improve from 0.96907\n",
      "Epoch 123/1000\n",
      "50/50 [==============================] - 28s 567ms/step - loss: 0.1162 - acc: 0.9507 - val_loss: 0.1406 - val_acc: 0.9433\n",
      "\n",
      "Epoch 00123: val_acc did not improve from 0.96907\n",
      "Epoch 124/1000\n",
      "50/50 [==============================] - 35s 710ms/step - loss: 0.1377 - acc: 0.9441 - val_loss: 0.1518 - val_acc: 0.9485\n",
      "\n",
      "Epoch 00124: val_acc did not improve from 0.96907\n",
      "Epoch 125/1000\n",
      "50/50 [==============================] - 32s 639ms/step - loss: 0.1424 - acc: 0.9427 - val_loss: 0.1098 - val_acc: 0.9639\n",
      "\n",
      "Epoch 00125: val_acc did not improve from 0.96907\n",
      "Epoch 126/1000\n",
      "50/50 [==============================] - 25s 503ms/step - loss: 0.1177 - acc: 0.9497 - val_loss: 0.1226 - val_acc: 0.9562\n",
      "\n",
      "Epoch 00126: val_acc did not improve from 0.96907\n",
      "Epoch 127/1000\n",
      "50/50 [==============================] - 25s 490ms/step - loss: 0.1218 - acc: 0.9520 - val_loss: 0.1099 - val_acc: 0.9536\n",
      "\n",
      "Epoch 00127: val_acc did not improve from 0.96907\n",
      "Epoch 128/1000\n",
      "50/50 [==============================] - 25s 503ms/step - loss: 0.1455 - acc: 0.9433 - val_loss: 0.1664 - val_acc: 0.9562\n",
      "\n",
      "Epoch 00128: val_acc did not improve from 0.96907\n",
      "Epoch 129/1000\n",
      "50/50 [==============================] - 31s 628ms/step - loss: 0.1618 - acc: 0.9396 - val_loss: 0.1183 - val_acc: 0.9665\n",
      "\n",
      "Epoch 00129: val_acc did not improve from 0.96907\n",
      "Epoch 130/1000\n",
      "50/50 [==============================] - 32s 649ms/step - loss: 0.1452 - acc: 0.9344 - val_loss: 0.1694 - val_acc: 0.9407\n",
      "\n",
      "Epoch 00130: val_acc did not improve from 0.96907\n",
      "Epoch 131/1000\n",
      "50/50 [==============================] - 32s 643ms/step - loss: 0.1338 - acc: 0.9433 - val_loss: 0.1164 - val_acc: 0.9639\n",
      "\n",
      "Epoch 00131: val_acc did not improve from 0.96907\n",
      "Epoch 132/1000\n",
      "50/50 [==============================] - 28s 550ms/step - loss: 0.1152 - acc: 0.9480 - val_loss: 0.1269 - val_acc: 0.9613\n",
      "\n",
      "Epoch 00132: val_acc did not improve from 0.96907\n",
      "Epoch 133/1000\n",
      "50/50 [==============================] - 28s 552ms/step - loss: 0.1378 - acc: 0.9403 - val_loss: 0.1822 - val_acc: 0.9433\n",
      "\n",
      "Epoch 00133: val_acc did not improve from 0.96907\n",
      "Epoch 134/1000\n",
      "50/50 [==============================] - 32s 634ms/step - loss: 0.1474 - acc: 0.9429 - val_loss: 0.1277 - val_acc: 0.9459\n",
      "\n",
      "Epoch 00134: val_acc did not improve from 0.96907\n",
      "Epoch 135/1000\n",
      "50/50 [==============================] - 25s 509ms/step - loss: 0.1476 - acc: 0.9369 - val_loss: 0.1614 - val_acc: 0.9407\n",
      "\n",
      "Epoch 00135: val_acc did not improve from 0.96907\n",
      "Epoch 136/1000\n",
      "50/50 [==============================] - 26s 519ms/step - loss: 0.1283 - acc: 0.9445 - val_loss: 0.1661 - val_acc: 0.9407\n",
      "\n",
      "Epoch 00136: val_acc did not improve from 0.96907\n",
      "Epoch 137/1000\n",
      "50/50 [==============================] - 25s 496ms/step - loss: 0.1208 - acc: 0.9489 - val_loss: 0.1442 - val_acc: 0.9485\n",
      "\n",
      "Epoch 00137: val_acc did not improve from 0.96907\n",
      "Epoch 138/1000\n",
      "50/50 [==============================] - 30s 593ms/step - loss: 0.1373 - acc: 0.9373 - val_loss: 0.1473 - val_acc: 0.9639\n",
      "\n",
      "Epoch 00138: val_acc did not improve from 0.96907\n",
      "Epoch 139/1000\n",
      "50/50 [==============================] - 29s 584ms/step - loss: 0.1315 - acc: 0.9465 - val_loss: 0.1650 - val_acc: 0.9485\n",
      "\n",
      "Epoch 00139: val_acc did not improve from 0.96907\n",
      "Epoch 140/1000\n",
      "50/50 [==============================] - 40s 804ms/step - loss: 0.1497 - acc: 0.9350 - val_loss: 0.1576 - val_acc: 0.9536\n",
      "\n",
      "Epoch 00140: val_acc did not improve from 0.96907\n",
      "Epoch 141/1000\n",
      "50/50 [==============================] - 62s 1s/step - loss: 0.1488 - acc: 0.9325 - val_loss: 0.1422 - val_acc: 0.9459\n",
      "\n",
      "Epoch 00141: val_acc did not improve from 0.96907\n",
      "Epoch 142/1000\n",
      "50/50 [==============================] - 45s 897ms/step - loss: 0.1138 - acc: 0.9532 - val_loss: 0.1284 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00142: val_acc did not improve from 0.96907\n",
      "Epoch 143/1000\n",
      "50/50 [==============================] - 44s 885ms/step - loss: 0.1312 - acc: 0.9401 - val_loss: 0.1509 - val_acc: 0.9536\n",
      "\n",
      "Epoch 00143: val_acc did not improve from 0.96907\n",
      "Epoch 144/1000\n",
      "50/50 [==============================] - 49s 989ms/step - loss: 0.1234 - acc: 0.9443 - val_loss: 0.1259 - val_acc: 0.9510\n",
      "\n",
      "Epoch 00144: val_acc did not improve from 0.96907\n",
      "Epoch 145/1000\n",
      "50/50 [==============================] - 53s 1s/step - loss: 0.1185 - acc: 0.9483 - val_loss: 0.1078 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00145: val_acc did not improve from 0.96907\n",
      "Epoch 146/1000\n",
      "50/50 [==============================] - 48s 953ms/step - loss: 0.1316 - acc: 0.9466 - val_loss: 0.1770 - val_acc: 0.9304\n",
      "\n",
      "Epoch 00146: val_acc did not improve from 0.96907\n",
      "Epoch 147/1000\n",
      "50/50 [==============================] - 37s 733ms/step - loss: 0.1311 - acc: 0.9503 - val_loss: 0.1359 - val_acc: 0.9536\n",
      "\n",
      "Epoch 00147: val_acc did not improve from 0.96907\n",
      "Epoch 148/1000\n",
      "50/50 [==============================] - 38s 753ms/step - loss: 0.1115 - acc: 0.9530 - val_loss: 0.0888 - val_acc: 0.9691\n",
      "\n",
      "Epoch 00148: val_acc improved from 0.96907 to 0.96907, saving model to best_cnn.h5\n",
      "Epoch 149/1000\n",
      "50/50 [==============================] - 39s 784ms/step - loss: 0.1101 - acc: 0.9499 - val_loss: 0.1320 - val_acc: 0.9510\n",
      "\n",
      "Epoch 00149: val_acc did not improve from 0.96907\n",
      "Epoch 150/1000\n",
      "50/50 [==============================] - 34s 689ms/step - loss: 0.1219 - acc: 0.9476 - val_loss: 0.1378 - val_acc: 0.9407\n",
      "\n",
      "Epoch 00150: val_acc did not improve from 0.96907\n",
      "Epoch 151/1000\n",
      "50/50 [==============================] - 31s 621ms/step - loss: 0.1154 - acc: 0.9523 - val_loss: 0.1341 - val_acc: 0.9459\n",
      "\n",
      "Epoch 00151: val_acc did not improve from 0.96907\n",
      "Epoch 152/1000\n",
      "50/50 [==============================] - 30s 595ms/step - loss: 0.1159 - acc: 0.9456 - val_loss: 0.1211 - val_acc: 0.9407\n",
      "\n",
      "Epoch 00152: val_acc did not improve from 0.96907\n",
      "Epoch 153/1000\n",
      "50/50 [==============================] - 33s 667ms/step - loss: 0.1107 - acc: 0.9557 - val_loss: 0.1592 - val_acc: 0.9330\n",
      "\n",
      "Epoch 00153: val_acc did not improve from 0.96907\n",
      "Epoch 154/1000\n",
      "50/50 [==============================] - 28s 559ms/step - loss: 0.1221 - acc: 0.9436 - val_loss: 0.1289 - val_acc: 0.9639\n",
      "\n",
      "Epoch 00154: val_acc did not improve from 0.96907\n",
      "Epoch 155/1000\n",
      "50/50 [==============================] - 28s 563ms/step - loss: 0.1353 - acc: 0.9403 - val_loss: 0.1612 - val_acc: 0.9381\n",
      "\n",
      "Epoch 00155: val_acc did not improve from 0.96907\n",
      "Epoch 156/1000\n",
      "50/50 [==============================] - 25s 493ms/step - loss: 0.1220 - acc: 0.9477 - val_loss: 0.1377 - val_acc: 0.9381\n",
      "\n",
      "Epoch 00156: val_acc did not improve from 0.96907\n",
      "Epoch 157/1000\n",
      "50/50 [==============================] - 25s 497ms/step - loss: 0.1174 - acc: 0.9471 - val_loss: 0.1050 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00157: val_acc did not improve from 0.96907\n",
      "Epoch 158/1000\n",
      "50/50 [==============================] - 26s 517ms/step - loss: 0.1150 - acc: 0.9510 - val_loss: 0.1449 - val_acc: 0.9485\n",
      "\n",
      "Epoch 00158: val_acc did not improve from 0.96907\n",
      "Epoch 159/1000\n",
      "50/50 [==============================] - 26s 527ms/step - loss: 0.1226 - acc: 0.9473 - val_loss: 0.1301 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00159: val_acc did not improve from 0.96907\n",
      "Epoch 160/1000\n",
      "50/50 [==============================] - 26s 522ms/step - loss: 0.1133 - acc: 0.9507 - val_loss: 0.1377 - val_acc: 0.9639\n",
      "\n",
      "Epoch 00160: val_acc did not improve from 0.96907\n",
      "Epoch 161/1000\n",
      "50/50 [==============================] - 26s 530ms/step - loss: 0.1153 - acc: 0.9512 - val_loss: 0.1535 - val_acc: 0.9613\n",
      "\n",
      "Epoch 00161: val_acc did not improve from 0.96907\n",
      "Epoch 162/1000\n",
      "50/50 [==============================] - 33s 664ms/step - loss: 0.1055 - acc: 0.9573 - val_loss: 0.2797 - val_acc: 0.9227\n",
      "\n",
      "Epoch 00162: val_acc did not improve from 0.96907\n",
      "Epoch 163/1000\n",
      "50/50 [==============================] - 30s 595ms/step - loss: 0.2177 - acc: 0.9216 - val_loss: 0.1460 - val_acc: 0.9433\n",
      "\n",
      "Epoch 00163: val_acc did not improve from 0.96907\n",
      "Epoch 164/1000\n",
      "50/50 [==============================] - 28s 551ms/step - loss: 0.1246 - acc: 0.9480 - val_loss: 0.1203 - val_acc: 0.9665\n",
      "\n",
      "Epoch 00164: val_acc did not improve from 0.96907\n",
      "Epoch 165/1000\n",
      "50/50 [==============================] - 28s 552ms/step - loss: 0.0995 - acc: 0.9580 - val_loss: 0.1367 - val_acc: 0.9510\n",
      "\n",
      "Epoch 00165: val_acc did not improve from 0.96907\n",
      "Epoch 166/1000\n",
      "50/50 [==============================] - 26s 515ms/step - loss: 0.1173 - acc: 0.9537 - val_loss: 0.1303 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00166: val_acc did not improve from 0.96907\n",
      "Epoch 167/1000\n",
      "50/50 [==============================] - 27s 539ms/step - loss: 0.1095 - acc: 0.9553 - val_loss: 0.1982 - val_acc: 0.9278\n",
      "\n",
      "Epoch 00167: val_acc did not improve from 0.96907\n",
      "Epoch 168/1000\n",
      "50/50 [==============================] - 26s 517ms/step - loss: 0.1106 - acc: 0.9560 - val_loss: 0.1661 - val_acc: 0.9562\n",
      "\n",
      "Epoch 00168: val_acc did not improve from 0.96907\n",
      "Epoch 169/1000\n",
      "50/50 [==============================] - 26s 526ms/step - loss: 0.1112 - acc: 0.9540 - val_loss: 0.1156 - val_acc: 0.9639\n",
      "\n",
      "Epoch 00169: val_acc did not improve from 0.96907\n",
      "Epoch 170/1000\n",
      "50/50 [==============================] - 26s 520ms/step - loss: 0.1149 - acc: 0.9513 - val_loss: 0.1129 - val_acc: 0.9613\n",
      "\n",
      "Epoch 00170: val_acc did not improve from 0.96907\n",
      "Epoch 171/1000\n",
      "50/50 [==============================] - 25s 508ms/step - loss: 0.1334 - acc: 0.9430 - val_loss: 0.1923 - val_acc: 0.9304\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00171: val_acc did not improve from 0.96907\n",
      "Epoch 172/1000\n",
      "50/50 [==============================] - 28s 554ms/step - loss: 0.1316 - acc: 0.9434 - val_loss: 0.1566 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00172: val_acc did not improve from 0.96907\n",
      "Epoch 173/1000\n",
      "50/50 [==============================] - 27s 543ms/step - loss: 0.1089 - acc: 0.9543 - val_loss: 0.1234 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00173: val_acc did not improve from 0.96907\n",
      "Epoch 174/1000\n",
      "50/50 [==============================] - 27s 533ms/step - loss: 0.1267 - acc: 0.9473 - val_loss: 0.1512 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00174: val_acc did not improve from 0.96907\n",
      "Epoch 175/1000\n",
      "50/50 [==============================] - 26s 515ms/step - loss: 0.1128 - acc: 0.9540 - val_loss: 0.1168 - val_acc: 0.9613\n",
      "\n",
      "Epoch 00175: val_acc did not improve from 0.96907\n",
      "Epoch 176/1000\n",
      "50/50 [==============================] - 28s 559ms/step - loss: 0.1024 - acc: 0.9570 - val_loss: 0.1807 - val_acc: 0.9381\n",
      "\n",
      "Epoch 00176: val_acc did not improve from 0.96907\n",
      "Epoch 177/1000\n",
      "50/50 [==============================] - 27s 544ms/step - loss: 0.1190 - acc: 0.9515 - val_loss: 0.1141 - val_acc: 0.9459\n",
      "\n",
      "Epoch 00177: val_acc did not improve from 0.96907\n",
      "Epoch 178/1000\n",
      "50/50 [==============================] - 25s 505ms/step - loss: 0.1232 - acc: 0.9493 - val_loss: 0.1252 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00178: val_acc did not improve from 0.96907\n",
      "Epoch 179/1000\n",
      "50/50 [==============================] - 25s 505ms/step - loss: 0.1162 - acc: 0.9503 - val_loss: 0.1527 - val_acc: 0.9381\n",
      "\n",
      "Epoch 00179: val_acc did not improve from 0.96907\n",
      "Epoch 180/1000\n",
      "50/50 [==============================] - 25s 505ms/step - loss: 0.1332 - acc: 0.9423 - val_loss: 0.1371 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00180: val_acc did not improve from 0.96907\n",
      "Epoch 181/1000\n",
      "50/50 [==============================] - 25s 507ms/step - loss: 0.1341 - acc: 0.9433 - val_loss: 0.1437 - val_acc: 0.9536\n",
      "\n",
      "Epoch 00181: val_acc did not improve from 0.96907\n",
      "Epoch 182/1000\n",
      "50/50 [==============================] - 25s 494ms/step - loss: 0.1208 - acc: 0.9530 - val_loss: 0.1888 - val_acc: 0.9356\n",
      "\n",
      "Epoch 00182: val_acc did not improve from 0.96907\n",
      "Epoch 183/1000\n",
      "50/50 [==============================] - 24s 489ms/step - loss: 0.1128 - acc: 0.9520 - val_loss: 0.1119 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00183: val_acc did not improve from 0.96907\n",
      "Epoch 184/1000\n",
      "50/50 [==============================] - 25s 491ms/step - loss: 0.0988 - acc: 0.9583 - val_loss: 0.1475 - val_acc: 0.9407\n",
      "\n",
      "Epoch 00184: val_acc did not improve from 0.96907\n",
      "Epoch 185/1000\n",
      "50/50 [==============================] - 25s 498ms/step - loss: 0.1069 - acc: 0.9570 - val_loss: 0.2061 - val_acc: 0.9381\n",
      "\n",
      "Epoch 00185: val_acc did not improve from 0.96907\n",
      "Epoch 186/1000\n",
      "50/50 [==============================] - 25s 498ms/step - loss: 0.1590 - acc: 0.9375 - val_loss: 0.1295 - val_acc: 0.9639\n",
      "\n",
      "Epoch 00186: val_acc did not improve from 0.96907\n",
      "Epoch 187/1000\n",
      "50/50 [==============================] - 24s 489ms/step - loss: 0.1368 - acc: 0.9405 - val_loss: 0.1320 - val_acc: 0.9485\n",
      "\n",
      "Epoch 00187: val_acc did not improve from 0.96907\n",
      "Epoch 188/1000\n",
      "50/50 [==============================] - 24s 479ms/step - loss: 0.1139 - acc: 0.9544 - val_loss: 0.1205 - val_acc: 0.9536\n",
      "\n",
      "Epoch 00188: val_acc did not improve from 0.96907\n",
      "Epoch 189/1000\n",
      "50/50 [==============================] - 25s 499ms/step - loss: 0.1072 - acc: 0.9540 - val_loss: 0.1420 - val_acc: 0.9536\n",
      "\n",
      "Epoch 00189: val_acc did not improve from 0.96907\n",
      "Epoch 190/1000\n",
      "50/50 [==============================] - 25s 498ms/step - loss: 0.1163 - acc: 0.9523 - val_loss: 0.1306 - val_acc: 0.9613\n",
      "\n",
      "Epoch 00190: val_acc did not improve from 0.96907\n",
      "Epoch 191/1000\n",
      "50/50 [==============================] - 25s 502ms/step - loss: 0.1352 - acc: 0.9417 - val_loss: 0.1020 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00191: val_acc did not improve from 0.96907\n",
      "Epoch 192/1000\n",
      "50/50 [==============================] - 36s 715ms/step - loss: 0.0942 - acc: 0.9577 - val_loss: 0.1215 - val_acc: 0.9613\n",
      "\n",
      "Epoch 00192: val_acc did not improve from 0.96907\n",
      "Epoch 193/1000\n",
      "50/50 [==============================] - 40s 793ms/step - loss: 0.1041 - acc: 0.9557 - val_loss: 0.1141 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00193: val_acc did not improve from 0.96907\n",
      "Epoch 194/1000\n",
      "50/50 [==============================] - 33s 657ms/step - loss: 0.1012 - acc: 0.9520 - val_loss: 0.1014 - val_acc: 0.9691\n",
      "\n",
      "Epoch 00194: val_acc did not improve from 0.96907\n",
      "Epoch 195/1000\n",
      "50/50 [==============================] - 27s 538ms/step - loss: 0.0932 - acc: 0.9603 - val_loss: 0.1311 - val_acc: 0.9433\n",
      "\n",
      "Epoch 00195: val_acc did not improve from 0.96907\n",
      "Epoch 196/1000\n",
      "50/50 [==============================] - 25s 510ms/step - loss: 0.1016 - acc: 0.9547 - val_loss: 0.1853 - val_acc: 0.9407\n",
      "\n",
      "Epoch 00196: val_acc did not improve from 0.96907\n",
      "Epoch 197/1000\n",
      "50/50 [==============================] - 25s 503ms/step - loss: 0.1186 - acc: 0.9497 - val_loss: 0.1723 - val_acc: 0.9381\n",
      "\n",
      "Epoch 00197: val_acc did not improve from 0.96907\n",
      "Epoch 198/1000\n",
      "50/50 [==============================] - 25s 495ms/step - loss: 0.1259 - acc: 0.9499 - val_loss: 0.1404 - val_acc: 0.9485\n",
      "\n",
      "Epoch 00198: val_acc did not improve from 0.96907\n",
      "Epoch 199/1000\n",
      "50/50 [==============================] - 30s 610ms/step - loss: 0.1175 - acc: 0.9552 - val_loss: 0.1355 - val_acc: 0.9485\n",
      "\n",
      "Epoch 00199: val_acc did not improve from 0.96907\n",
      "Epoch 200/1000\n",
      "50/50 [==============================] - 27s 538ms/step - loss: 0.1124 - acc: 0.9525 - val_loss: 0.1093 - val_acc: 0.9485\n",
      "\n",
      "Epoch 00200: val_acc did not improve from 0.96907\n",
      "Epoch 201/1000\n",
      "50/50 [==============================] - 25s 508ms/step - loss: 0.1187 - acc: 0.9512 - val_loss: 0.1238 - val_acc: 0.9459\n",
      "\n",
      "Epoch 00201: val_acc did not improve from 0.96907\n",
      "Epoch 202/1000\n",
      "50/50 [==============================] - 25s 495ms/step - loss: 0.0971 - acc: 0.9617 - val_loss: 0.1231 - val_acc: 0.9613\n",
      "\n",
      "Epoch 00202: val_acc did not improve from 0.96907\n",
      "Epoch 203/1000\n",
      "50/50 [==============================] - 29s 571ms/step - loss: 0.0864 - acc: 0.9615 - val_loss: 0.1014 - val_acc: 0.9639\n",
      "\n",
      "Epoch 00203: val_acc did not improve from 0.96907\n",
      "Epoch 204/1000\n",
      "50/50 [==============================] - 48s 954ms/step - loss: 0.1123 - acc: 0.9527 - val_loss: 0.1116 - val_acc: 0.9536\n",
      "\n",
      "Epoch 00204: val_acc did not improve from 0.96907\n",
      "Epoch 205/1000\n",
      "50/50 [==============================] - 33s 653ms/step - loss: 0.1338 - acc: 0.9407 - val_loss: 0.1990 - val_acc: 0.9407\n",
      "\n",
      "Epoch 00205: val_acc did not improve from 0.96907\n",
      "Epoch 206/1000\n",
      "50/50 [==============================] - 28s 565ms/step - loss: 0.1214 - acc: 0.9494 - val_loss: 0.1204 - val_acc: 0.9562\n",
      "\n",
      "Epoch 00206: val_acc did not improve from 0.96907\n",
      "Epoch 207/1000\n",
      "50/50 [==============================] - 27s 542ms/step - loss: 0.1091 - acc: 0.9549 - val_loss: 0.1259 - val_acc: 0.9510\n",
      "\n",
      "Epoch 00207: val_acc did not improve from 0.96907\n",
      "Epoch 208/1000\n",
      "50/50 [==============================] - 26s 526ms/step - loss: 0.1057 - acc: 0.9563 - val_loss: 0.1043 - val_acc: 0.9639\n",
      "\n",
      "Epoch 00208: val_acc did not improve from 0.96907\n",
      "Epoch 209/1000\n",
      "50/50 [==============================] - 27s 531ms/step - loss: 0.1016 - acc: 0.9579 - val_loss: 0.1433 - val_acc: 0.9510\n",
      "\n",
      "Epoch 00209: val_acc did not improve from 0.96907\n",
      "Epoch 210/1000\n",
      "50/50 [==============================] - 26s 517ms/step - loss: 0.1047 - acc: 0.9613 - val_loss: 0.0950 - val_acc: 0.9716\n",
      "\n",
      "Epoch 00210: val_acc improved from 0.96907 to 0.97165, saving model to best_cnn.h5\n",
      "Epoch 211/1000\n",
      "50/50 [==============================] - 25s 494ms/step - loss: 0.1059 - acc: 0.9540 - val_loss: 0.0990 - val_acc: 0.9639\n",
      "\n",
      "Epoch 00211: val_acc did not improve from 0.97165\n",
      "Epoch 212/1000\n",
      "50/50 [==============================] - 25s 491ms/step - loss: 0.1115 - acc: 0.9520 - val_loss: 0.1272 - val_acc: 0.9407\n",
      "\n",
      "Epoch 00212: val_acc did not improve from 0.97165\n",
      "Epoch 213/1000\n",
      "50/50 [==============================] - 24s 474ms/step - loss: 0.1261 - acc: 0.9476 - val_loss: 0.1198 - val_acc: 0.9562\n",
      "\n",
      "Epoch 00213: val_acc did not improve from 0.97165\n",
      "Epoch 214/1000\n",
      "50/50 [==============================] - 24s 471ms/step - loss: 0.0911 - acc: 0.9617 - val_loss: 0.1381 - val_acc: 0.9433\n",
      "\n",
      "Epoch 00214: val_acc did not improve from 0.97165\n",
      "Epoch 215/1000\n",
      "50/50 [==============================] - 23s 467ms/step - loss: 0.1256 - acc: 0.9545 - val_loss: 0.1274 - val_acc: 0.9459\n",
      "\n",
      "Epoch 00215: val_acc did not improve from 0.97165\n",
      "Epoch 216/1000\n",
      "50/50 [==============================] - 24s 473ms/step - loss: 0.1064 - acc: 0.9575 - val_loss: 0.1388 - val_acc: 0.9536\n",
      "\n",
      "Epoch 00216: val_acc did not improve from 0.97165\n",
      "Epoch 217/1000\n",
      "50/50 [==============================] - 24s 478ms/step - loss: 0.0974 - acc: 0.9593 - val_loss: 0.1209 - val_acc: 0.9562\n",
      "\n",
      "Epoch 00217: val_acc did not improve from 0.97165\n",
      "Epoch 218/1000\n",
      "50/50 [==============================] - 25s 503ms/step - loss: 0.1026 - acc: 0.9540 - val_loss: 0.1057 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00218: val_acc did not improve from 0.97165\n",
      "Epoch 219/1000\n",
      "50/50 [==============================] - 24s 485ms/step - loss: 0.0968 - acc: 0.9623 - val_loss: 0.1079 - val_acc: 0.9639\n",
      "\n",
      "Epoch 00219: val_acc did not improve from 0.97165\n",
      "Epoch 220/1000\n",
      "50/50 [==============================] - 24s 472ms/step - loss: 0.1154 - acc: 0.9527 - val_loss: 0.1153 - val_acc: 0.9562\n",
      "\n",
      "Epoch 00220: val_acc did not improve from 0.97165\n",
      "Epoch 221/1000\n",
      "50/50 [==============================] - 24s 475ms/step - loss: 0.0968 - acc: 0.9620 - val_loss: 0.1161 - val_acc: 0.9536\n",
      "\n",
      "Epoch 00221: val_acc did not improve from 0.97165\n",
      "Epoch 222/1000\n",
      "50/50 [==============================] - 24s 475ms/step - loss: 0.1001 - acc: 0.9574 - val_loss: 0.1636 - val_acc: 0.9407\n",
      "\n",
      "Epoch 00222: val_acc did not improve from 0.97165\n",
      "Epoch 223/1000\n",
      "50/50 [==============================] - 24s 476ms/step - loss: 0.0965 - acc: 0.9600 - val_loss: 0.1149 - val_acc: 0.9510\n",
      "\n",
      "Epoch 00223: val_acc did not improve from 0.97165\n",
      "Epoch 224/1000\n",
      "50/50 [==============================] - 23s 468ms/step - loss: 0.1024 - acc: 0.9565 - val_loss: 0.1102 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00224: val_acc did not improve from 0.97165\n",
      "Epoch 225/1000\n",
      "50/50 [==============================] - 24s 474ms/step - loss: 0.1229 - acc: 0.9562 - val_loss: 0.2498 - val_acc: 0.9227\n",
      "\n",
      "Epoch 00225: val_acc did not improve from 0.97165\n",
      "Epoch 226/1000\n",
      "50/50 [==============================] - 24s 472ms/step - loss: 0.1177 - acc: 0.9481 - val_loss: 0.0903 - val_acc: 0.9613\n",
      "\n",
      "Epoch 00226: val_acc did not improve from 0.97165\n",
      "Epoch 227/1000\n",
      "50/50 [==============================] - 24s 471ms/step - loss: 0.1006 - acc: 0.9620 - val_loss: 0.1350 - val_acc: 0.9459\n",
      "\n",
      "Epoch 00227: val_acc did not improve from 0.97165\n",
      "Epoch 228/1000\n",
      "50/50 [==============================] - 26s 510ms/step - loss: 0.0840 - acc: 0.9653 - val_loss: 0.1156 - val_acc: 0.9639\n",
      "\n",
      "Epoch 00228: val_acc did not improve from 0.97165\n",
      "Epoch 229/1000\n",
      "50/50 [==============================] - 34s 686ms/step - loss: 0.0921 - acc: 0.9607 - val_loss: 0.1123 - val_acc: 0.9536\n",
      "\n",
      "Epoch 00229: val_acc did not improve from 0.97165\n",
      "Epoch 230/1000\n",
      "50/50 [==============================] - 34s 677ms/step - loss: 0.0851 - acc: 0.9607 - val_loss: 0.1895 - val_acc: 0.9278\n",
      "\n",
      "Epoch 00230: val_acc did not improve from 0.97165\n",
      "Epoch 231/1000\n",
      "50/50 [==============================] - 32s 647ms/step - loss: 0.1621 - acc: 0.9452 - val_loss: 0.1070 - val_acc: 0.9613\n",
      "\n",
      "Epoch 00231: val_acc did not improve from 0.97165\n",
      "Epoch 232/1000\n",
      "50/50 [==============================] - 30s 597ms/step - loss: 0.0947 - acc: 0.9632 - val_loss: 0.1194 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00232: val_acc did not improve from 0.97165\n",
      "Epoch 233/1000\n",
      "50/50 [==============================] - 32s 642ms/step - loss: 0.0895 - acc: 0.9650 - val_loss: 0.1726 - val_acc: 0.9459\n",
      "\n",
      "Epoch 00233: val_acc did not improve from 0.97165\n",
      "Epoch 234/1000\n",
      "50/50 [==============================] - 32s 649ms/step - loss: 0.0790 - acc: 0.9660 - val_loss: 0.1064 - val_acc: 0.9639\n",
      "\n",
      "Epoch 00234: val_acc did not improve from 0.97165\n",
      "Epoch 235/1000\n",
      "50/50 [==============================] - 28s 552ms/step - loss: 0.1086 - acc: 0.9537 - val_loss: 0.1736 - val_acc: 0.9278\n",
      "\n",
      "Epoch 00235: val_acc did not improve from 0.97165\n",
      "Epoch 236/1000\n",
      "50/50 [==============================] - 32s 635ms/step - loss: 0.1186 - acc: 0.9532 - val_loss: 0.0891 - val_acc: 0.9665\n",
      "\n",
      "Epoch 00236: val_acc did not improve from 0.97165\n",
      "Epoch 237/1000\n",
      "50/50 [==============================] - 29s 572ms/step - loss: 0.0971 - acc: 0.9597 - val_loss: 0.1120 - val_acc: 0.9639\n",
      "\n",
      "Epoch 00237: val_acc did not improve from 0.97165\n",
      "Epoch 238/1000\n",
      "50/50 [==============================] - 25s 491ms/step - loss: 0.0890 - acc: 0.9630 - val_loss: 0.0821 - val_acc: 0.9639\n",
      "\n",
      "Epoch 00238: val_acc did not improve from 0.97165\n",
      "Epoch 239/1000\n",
      "50/50 [==============================] - 30s 592ms/step - loss: 0.0977 - acc: 0.9590 - val_loss: 0.1758 - val_acc: 0.9433\n",
      "\n",
      "Epoch 00239: val_acc did not improve from 0.97165\n",
      "Epoch 240/1000\n",
      "50/50 [==============================] - 30s 598ms/step - loss: 0.1012 - acc: 0.9589 - val_loss: 0.1158 - val_acc: 0.9562\n",
      "\n",
      "Epoch 00240: val_acc did not improve from 0.97165\n",
      "Epoch 241/1000\n",
      "50/50 [==============================] - 33s 655ms/step - loss: 0.0966 - acc: 0.9613 - val_loss: 0.0930 - val_acc: 0.9613\n",
      "\n",
      "Epoch 00241: val_acc did not improve from 0.97165\n",
      "Epoch 242/1000\n",
      "50/50 [==============================] - 38s 759ms/step - loss: 0.1009 - acc: 0.9607 - val_loss: 0.1169 - val_acc: 0.9639\n",
      "\n",
      "Epoch 00242: val_acc did not improve from 0.97165\n",
      "Epoch 243/1000\n",
      "50/50 [==============================] - 38s 764ms/step - loss: 0.1026 - acc: 0.9580 - val_loss: 0.1557 - val_acc: 0.9613\n",
      "\n",
      "Epoch 00243: val_acc did not improve from 0.97165\n",
      "Epoch 244/1000\n",
      "50/50 [==============================] - 33s 656ms/step - loss: 0.1155 - acc: 0.9497 - val_loss: 0.1861 - val_acc: 0.9201\n",
      "\n",
      "Epoch 00244: val_acc did not improve from 0.97165\n",
      "Epoch 245/1000\n",
      "50/50 [==============================] - 32s 635ms/step - loss: 0.0891 - acc: 0.9620 - val_loss: 0.1014 - val_acc: 0.9613\n",
      "\n",
      "Epoch 00245: val_acc did not improve from 0.97165\n",
      "Epoch 246/1000\n",
      "50/50 [==============================] - 29s 584ms/step - loss: 0.0958 - acc: 0.9577 - val_loss: 0.1009 - val_acc: 0.9510\n",
      "\n",
      "Epoch 00246: val_acc did not improve from 0.97165\n",
      "Epoch 247/1000\n",
      "50/50 [==============================] - 30s 599ms/step - loss: 0.0945 - acc: 0.9595 - val_loss: 0.1206 - val_acc: 0.9562\n",
      "\n",
      "Epoch 00247: val_acc did not improve from 0.97165\n",
      "Epoch 248/1000\n",
      "50/50 [==============================] - 35s 697ms/step - loss: 0.1108 - acc: 0.9503 - val_loss: 0.1524 - val_acc: 0.9356\n",
      "\n",
      "Epoch 00248: val_acc did not improve from 0.97165\n",
      "Epoch 249/1000\n",
      "50/50 [==============================] - 39s 784ms/step - loss: 0.0940 - acc: 0.9580 - val_loss: 0.1192 - val_acc: 0.9665\n",
      "\n",
      "Epoch 00249: val_acc did not improve from 0.97165\n",
      "Epoch 250/1000\n",
      "50/50 [==============================] - 43s 859ms/step - loss: 0.1116 - acc: 0.9477 - val_loss: 0.1341 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00250: val_acc did not improve from 0.97165\n",
      "Epoch 251/1000\n",
      "50/50 [==============================] - 45s 909ms/step - loss: 0.1203 - acc: 0.9480 - val_loss: 0.1012 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00251: val_acc did not improve from 0.97165\n",
      "Epoch 252/1000\n",
      "50/50 [==============================] - 40s 792ms/step - loss: 0.0841 - acc: 0.9680 - val_loss: 0.1035 - val_acc: 0.9536\n",
      "\n",
      "Epoch 00252: val_acc did not improve from 0.97165\n",
      "Epoch 253/1000\n",
      "50/50 [==============================] - 39s 789ms/step - loss: 0.0981 - acc: 0.9582 - val_loss: 0.1105 - val_acc: 0.9536\n",
      "\n",
      "Epoch 00253: val_acc did not improve from 0.97165\n",
      "Epoch 254/1000\n",
      "50/50 [==============================] - 33s 661ms/step - loss: 0.0972 - acc: 0.9607 - val_loss: 0.1074 - val_acc: 0.9536\n",
      "\n",
      "Epoch 00254: val_acc did not improve from 0.97165\n",
      "Epoch 255/1000\n",
      "50/50 [==============================] - 34s 689ms/step - loss: 0.0971 - acc: 0.9555 - val_loss: 0.1276 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00255: val_acc did not improve from 0.97165\n",
      "Epoch 256/1000\n",
      "50/50 [==============================] - 44s 881ms/step - loss: 0.0936 - acc: 0.9610 - val_loss: 0.1195 - val_acc: 0.9613\n",
      "\n",
      "Epoch 00256: val_acc did not improve from 0.97165\n",
      "Epoch 257/1000\n",
      "50/50 [==============================] - 35s 693ms/step - loss: 0.0934 - acc: 0.9610 - val_loss: 0.1357 - val_acc: 0.9536\n",
      "\n",
      "Epoch 00257: val_acc did not improve from 0.97165\n",
      "Epoch 258/1000\n",
      "50/50 [==============================] - 32s 632ms/step - loss: 0.0836 - acc: 0.9643 - val_loss: 0.1466 - val_acc: 0.9356\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00258: val_acc did not improve from 0.97165\n",
      "Epoch 259/1000\n",
      "50/50 [==============================] - 33s 653ms/step - loss: 0.1017 - acc: 0.9567 - val_loss: 0.1058 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00259: val_acc did not improve from 0.97165\n",
      "Epoch 260/1000\n",
      "50/50 [==============================] - 44s 871ms/step - loss: 0.0959 - acc: 0.9619 - val_loss: 0.1405 - val_acc: 0.9407\n",
      "\n",
      "Epoch 00260: val_acc did not improve from 0.97165\n",
      "Epoch 261/1000\n",
      "50/50 [==============================] - 32s 638ms/step - loss: 0.0950 - acc: 0.9612 - val_loss: 0.1113 - val_acc: 0.9485\n",
      "\n",
      "Epoch 00261: val_acc did not improve from 0.97165\n",
      "Epoch 262/1000\n",
      "50/50 [==============================] - 31s 626ms/step - loss: 0.0832 - acc: 0.9669 - val_loss: 0.1664 - val_acc: 0.9407\n",
      "\n",
      "Epoch 00262: val_acc did not improve from 0.97165\n",
      "Epoch 263/1000\n",
      "50/50 [==============================] - 44s 884ms/step - loss: 0.1003 - acc: 0.9577 - val_loss: 0.1400 - val_acc: 0.9485\n",
      "\n",
      "Epoch 00263: val_acc did not improve from 0.97165\n",
      "Epoch 264/1000\n",
      "50/50 [==============================] - 34s 683ms/step - loss: 0.0911 - acc: 0.9640 - val_loss: 0.1052 - val_acc: 0.9639\n",
      "\n",
      "Epoch 00264: val_acc did not improve from 0.97165\n",
      "Epoch 265/1000\n",
      "50/50 [==============================] - 35s 692ms/step - loss: 0.1094 - acc: 0.9580 - val_loss: 0.1645 - val_acc: 0.9485\n",
      "\n",
      "Epoch 00265: val_acc did not improve from 0.97165\n",
      "Epoch 266/1000\n",
      "50/50 [==============================] - 41s 818ms/step - loss: 0.0910 - acc: 0.9587 - val_loss: 0.1584 - val_acc: 0.9485\n",
      "\n",
      "Epoch 00266: val_acc did not improve from 0.97165\n",
      "Epoch 267/1000\n",
      "50/50 [==============================] - 40s 793ms/step - loss: 0.0861 - acc: 0.9653 - val_loss: 0.1687 - val_acc: 0.9356\n",
      "\n",
      "Epoch 00267: val_acc did not improve from 0.97165\n",
      "Epoch 268/1000\n",
      "50/50 [==============================] - 36s 721ms/step - loss: 0.1341 - acc: 0.9447 - val_loss: 0.1650 - val_acc: 0.9253\n",
      "\n",
      "Epoch 00268: val_acc did not improve from 0.97165\n",
      "Epoch 269/1000\n",
      "50/50 [==============================] - 36s 727ms/step - loss: 0.0951 - acc: 0.9593 - val_loss: 0.1080 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00269: val_acc did not improve from 0.97165\n",
      "Epoch 270/1000\n",
      "50/50 [==============================] - 36s 722ms/step - loss: 0.0837 - acc: 0.9653 - val_loss: 0.0851 - val_acc: 0.9613\n",
      "\n",
      "Epoch 00270: val_acc did not improve from 0.97165\n",
      "Epoch 271/1000\n",
      "50/50 [==============================] - 38s 761ms/step - loss: 0.0992 - acc: 0.9581 - val_loss: 0.0668 - val_acc: 0.9742\n",
      "\n",
      "Epoch 00271: val_acc improved from 0.97165 to 0.97423, saving model to best_cnn.h5\n",
      "Epoch 272/1000\n",
      "50/50 [==============================] - 27s 549ms/step - loss: 0.1072 - acc: 0.9602 - val_loss: 0.1492 - val_acc: 0.9330\n",
      "\n",
      "Epoch 00272: val_acc did not improve from 0.97423\n",
      "Epoch 273/1000\n",
      "50/50 [==============================] - 26s 527ms/step - loss: 0.0888 - acc: 0.9623 - val_loss: 0.0929 - val_acc: 0.9536\n",
      "\n",
      "Epoch 00273: val_acc did not improve from 0.97423\n",
      "Epoch 274/1000\n",
      "50/50 [==============================] - 25s 496ms/step - loss: 0.0768 - acc: 0.9723 - val_loss: 0.1093 - val_acc: 0.9562\n",
      "\n",
      "Epoch 00274: val_acc did not improve from 0.97423\n",
      "Epoch 275/1000\n",
      "50/50 [==============================] - 24s 481ms/step - loss: 0.0949 - acc: 0.9619 - val_loss: 0.1399 - val_acc: 0.9485\n",
      "\n",
      "Epoch 00275: val_acc did not improve from 0.97423\n",
      "Epoch 276/1000\n",
      "50/50 [==============================] - 32s 644ms/step - loss: 0.0920 - acc: 0.9650 - val_loss: 0.0853 - val_acc: 0.9691\n",
      "\n",
      "Epoch 00276: val_acc did not improve from 0.97423\n",
      "Epoch 277/1000\n",
      "50/50 [==============================] - 39s 781ms/step - loss: 0.1032 - acc: 0.9599 - val_loss: 0.1461 - val_acc: 0.9433\n",
      "\n",
      "Epoch 00277: val_acc did not improve from 0.97423\n",
      "Epoch 278/1000\n",
      "50/50 [==============================] - 48s 963ms/step - loss: 0.1204 - acc: 0.9525 - val_loss: 0.0966 - val_acc: 0.9536\n",
      "\n",
      "Epoch 00278: val_acc did not improve from 0.97423\n",
      "Epoch 279/1000\n",
      "50/50 [==============================] - 49s 976ms/step - loss: 0.1041 - acc: 0.9592 - val_loss: 0.1316 - val_acc: 0.9536\n",
      "\n",
      "Epoch 00279: val_acc did not improve from 0.97423\n",
      "Epoch 280/1000\n",
      "50/50 [==============================] - 35s 701ms/step - loss: 0.1127 - acc: 0.9535 - val_loss: 0.0750 - val_acc: 0.9665\n",
      "\n",
      "Epoch 00280: val_acc did not improve from 0.97423\n",
      "Epoch 281/1000\n",
      "50/50 [==============================] - 37s 740ms/step - loss: 0.0931 - acc: 0.9630 - val_loss: 0.0848 - val_acc: 0.9639\n",
      "\n",
      "Epoch 00281: val_acc did not improve from 0.97423\n",
      "Epoch 282/1000\n",
      "50/50 [==============================] - 35s 704ms/step - loss: 0.0824 - acc: 0.9650 - val_loss: 0.0771 - val_acc: 0.9691\n",
      "\n",
      "Epoch 00282: val_acc did not improve from 0.97423\n",
      "Epoch 283/1000\n",
      "50/50 [==============================] - 34s 688ms/step - loss: 0.1245 - acc: 0.9527 - val_loss: 0.1457 - val_acc: 0.9433\n",
      "\n",
      "Epoch 00283: val_acc did not improve from 0.97423\n",
      "Epoch 284/1000\n",
      "50/50 [==============================] - 38s 755ms/step - loss: 0.1112 - acc: 0.9567 - val_loss: 0.2095 - val_acc: 0.9433\n",
      "\n",
      "Epoch 00284: val_acc did not improve from 0.97423\n",
      "Epoch 285/1000\n",
      "50/50 [==============================] - 37s 740ms/step - loss: 0.1213 - acc: 0.9559 - val_loss: 0.1506 - val_acc: 0.9536\n",
      "\n",
      "Epoch 00285: val_acc did not improve from 0.97423\n",
      "Epoch 286/1000\n",
      "50/50 [==============================] - 32s 644ms/step - loss: 0.1001 - acc: 0.9615 - val_loss: 0.1150 - val_acc: 0.9485\n",
      "\n",
      "Epoch 00286: val_acc did not improve from 0.97423\n",
      "Epoch 287/1000\n",
      "50/50 [==============================] - 27s 530ms/step - loss: 0.1123 - acc: 0.9555 - val_loss: 0.1413 - val_acc: 0.9356\n",
      "\n",
      "Epoch 00287: val_acc did not improve from 0.97423\n",
      "Epoch 288/1000\n",
      "50/50 [==============================] - 28s 558ms/step - loss: 0.0918 - acc: 0.9632 - val_loss: 0.0851 - val_acc: 0.9665\n",
      "\n",
      "Epoch 00288: val_acc did not improve from 0.97423\n",
      "Epoch 289/1000\n",
      "50/50 [==============================] - 26s 510ms/step - loss: 0.0769 - acc: 0.9713 - val_loss: 0.1134 - val_acc: 0.9562\n",
      "\n",
      "Epoch 00289: val_acc did not improve from 0.97423\n",
      "Epoch 290/1000\n",
      "50/50 [==============================] - 24s 480ms/step - loss: 0.0776 - acc: 0.9670 - val_loss: 0.0910 - val_acc: 0.9691\n",
      "\n",
      "Epoch 00290: val_acc did not improve from 0.97423\n",
      "Epoch 291/1000\n",
      "50/50 [==============================] - 25s 494ms/step - loss: 0.0728 - acc: 0.9677 - val_loss: 0.1818 - val_acc: 0.9356\n",
      "\n",
      "Epoch 00291: val_acc did not improve from 0.97423\n",
      "Epoch 292/1000\n",
      "50/50 [==============================] - 28s 556ms/step - loss: 0.0878 - acc: 0.9659 - val_loss: 0.0996 - val_acc: 0.9613\n",
      "\n",
      "Epoch 00292: val_acc did not improve from 0.97423\n",
      "Epoch 293/1000\n",
      "50/50 [==============================] - 30s 595ms/step - loss: 0.0787 - acc: 0.9623 - val_loss: 0.0841 - val_acc: 0.9716\n",
      "\n",
      "Epoch 00293: val_acc did not improve from 0.97423\n",
      "Epoch 294/1000\n",
      "50/50 [==============================] - 25s 495ms/step - loss: 0.1120 - acc: 0.9550 - val_loss: 0.1219 - val_acc: 0.9459\n",
      "\n",
      "Epoch 00294: val_acc did not improve from 0.97423\n",
      "Epoch 295/1000\n",
      "50/50 [==============================] - 25s 506ms/step - loss: 0.1017 - acc: 0.9569 - val_loss: 0.1049 - val_acc: 0.9665\n",
      "\n",
      "Epoch 00295: val_acc did not improve from 0.97423\n",
      "Epoch 296/1000\n",
      "50/50 [==============================] - 31s 616ms/step - loss: 0.0882 - acc: 0.9657 - val_loss: 0.1905 - val_acc: 0.9356\n",
      "\n",
      "Epoch 00296: val_acc did not improve from 0.97423\n",
      "Epoch 297/1000\n",
      "50/50 [==============================] - 41s 824ms/step - loss: 0.0826 - acc: 0.9673 - val_loss: 0.0980 - val_acc: 0.9613\n",
      "\n",
      "Epoch 00297: val_acc did not improve from 0.97423\n",
      "Epoch 298/1000\n",
      "50/50 [==============================] - 37s 736ms/step - loss: 0.0910 - acc: 0.9653 - val_loss: 0.1463 - val_acc: 0.9510\n",
      "\n",
      "Epoch 00298: val_acc did not improve from 0.97423\n",
      "Epoch 299/1000\n",
      "50/50 [==============================] - 32s 649ms/step - loss: 0.0933 - acc: 0.9599 - val_loss: 0.1202 - val_acc: 0.9536\n",
      "\n",
      "Epoch 00299: val_acc did not improve from 0.97423\n",
      "Epoch 300/1000\n",
      "50/50 [==============================] - 32s 636ms/step - loss: 0.0821 - acc: 0.9689 - val_loss: 0.0945 - val_acc: 0.9613\n",
      "\n",
      "Epoch 00300: val_acc did not improve from 0.97423\n",
      "Epoch 301/1000\n",
      "50/50 [==============================] - 26s 523ms/step - loss: 0.0783 - acc: 0.9699 - val_loss: 0.1003 - val_acc: 0.9665\n",
      "\n",
      "Epoch 00301: val_acc did not improve from 0.97423\n",
      "Epoch 302/1000\n",
      "50/50 [==============================] - 24s 486ms/step - loss: 0.0827 - acc: 0.9670 - val_loss: 0.0892 - val_acc: 0.9639\n",
      "\n",
      "Epoch 00302: val_acc did not improve from 0.97423\n",
      "Epoch 303/1000\n",
      "50/50 [==============================] - 24s 479ms/step - loss: 0.0868 - acc: 0.9647 - val_loss: 0.0891 - val_acc: 0.9613\n",
      "\n",
      "Epoch 00303: val_acc did not improve from 0.97423\n",
      "Epoch 304/1000\n",
      "50/50 [==============================] - 28s 553ms/step - loss: 0.1009 - acc: 0.9577 - val_loss: 0.2212 - val_acc: 0.9201\n",
      "\n",
      "Epoch 00304: val_acc did not improve from 0.97423\n",
      "Epoch 305/1000\n",
      "50/50 [==============================] - 24s 482ms/step - loss: 0.0820 - acc: 0.9653 - val_loss: 0.1579 - val_acc: 0.9536\n",
      "\n",
      "Epoch 00305: val_acc did not improve from 0.97423\n",
      "Epoch 306/1000\n",
      "50/50 [==============================] - 1731s 35s/step - loss: 0.1099 - acc: 0.9610 - val_loss: 0.0917 - val_acc: 0.9639\n",
      "\n",
      "Epoch 00306: val_acc did not improve from 0.97423\n",
      "Epoch 307/1000\n",
      "50/50 [==============================] - 42s 845ms/step - loss: 0.0756 - acc: 0.9683 - val_loss: 0.0971 - val_acc: 0.9613\n",
      "\n",
      "Epoch 00307: val_acc did not improve from 0.97423\n",
      "Epoch 308/1000\n",
      "50/50 [==============================] - 35s 700ms/step - loss: 0.0802 - acc: 0.9669 - val_loss: 0.1717 - val_acc: 0.9433\n",
      "\n",
      "Epoch 00308: val_acc did not improve from 0.97423\n",
      "Epoch 309/1000\n",
      "50/50 [==============================] - 32s 632ms/step - loss: 0.0857 - acc: 0.9680 - val_loss: 0.1180 - val_acc: 0.9536\n",
      "\n",
      "Epoch 00309: val_acc did not improve from 0.97423\n",
      "Epoch 310/1000\n",
      "50/50 [==============================] - 28s 570ms/step - loss: 0.1095 - acc: 0.9539 - val_loss: 0.0865 - val_acc: 0.9691\n",
      "\n",
      "Epoch 00310: val_acc did not improve from 0.97423\n",
      "Epoch 311/1000\n",
      "50/50 [==============================] - 32s 643ms/step - loss: 0.1175 - acc: 0.9513 - val_loss: 0.1981 - val_acc: 0.9253\n",
      "\n",
      "Epoch 00311: val_acc did not improve from 0.97423\n",
      "Epoch 312/1000\n",
      "50/50 [==============================] - 32s 638ms/step - loss: 0.0859 - acc: 0.9652 - val_loss: 0.1133 - val_acc: 0.9536\n",
      "\n",
      "Epoch 00312: val_acc did not improve from 0.97423\n",
      "Epoch 313/1000\n",
      "50/50 [==============================] - 30s 595ms/step - loss: 0.1023 - acc: 0.9572 - val_loss: 0.1539 - val_acc: 0.9485\n",
      "\n",
      "Epoch 00313: val_acc did not improve from 0.97423\n",
      "Epoch 314/1000\n",
      "50/50 [==============================] - 31s 617ms/step - loss: 0.0818 - acc: 0.9677 - val_loss: 0.0825 - val_acc: 0.9562\n",
      "\n",
      "Epoch 00314: val_acc did not improve from 0.97423\n",
      "Epoch 315/1000\n",
      "50/50 [==============================] - 28s 566ms/step - loss: 0.0734 - acc: 0.9727 - val_loss: 0.1292 - val_acc: 0.9459\n",
      "\n",
      "Epoch 00315: val_acc did not improve from 0.97423\n",
      "Epoch 316/1000\n",
      "50/50 [==============================] - 31s 624ms/step - loss: 0.0611 - acc: 0.9763 - val_loss: 0.1717 - val_acc: 0.9433\n",
      "\n",
      "Epoch 00316: val_acc did not improve from 0.97423\n",
      "Epoch 317/1000\n",
      "50/50 [==============================] - 29s 576ms/step - loss: 0.1225 - acc: 0.9510 - val_loss: 0.1635 - val_acc: 0.9433\n",
      "\n",
      "Epoch 00317: val_acc did not improve from 0.97423\n",
      "Epoch 318/1000\n",
      "50/50 [==============================] - 28s 566ms/step - loss: 0.1007 - acc: 0.9625 - val_loss: 0.1227 - val_acc: 0.9536\n",
      "\n",
      "Epoch 00318: val_acc did not improve from 0.97423\n",
      "Epoch 319/1000\n",
      "50/50 [==============================] - 31s 626ms/step - loss: 0.0831 - acc: 0.9680 - val_loss: 0.0955 - val_acc: 0.9639\n",
      "\n",
      "Epoch 00319: val_acc did not improve from 0.97423\n",
      "Epoch 320/1000\n",
      "50/50 [==============================] - 33s 659ms/step - loss: 0.0836 - acc: 0.9673 - val_loss: 0.0768 - val_acc: 0.9742\n",
      "\n",
      "Epoch 00320: val_acc did not improve from 0.97423\n",
      "Epoch 321/1000\n",
      "50/50 [==============================] - 36s 724ms/step - loss: 0.0764 - acc: 0.9713 - val_loss: 0.1566 - val_acc: 0.9459\n",
      "\n",
      "Epoch 00321: val_acc did not improve from 0.97423\n",
      "Epoch 322/1000\n",
      "50/50 [==============================] - 32s 635ms/step - loss: 0.1036 - acc: 0.9590 - val_loss: 0.1638 - val_acc: 0.9356\n",
      "\n",
      "Epoch 00322: val_acc did not improve from 0.97423\n",
      "Epoch 323/1000\n",
      "50/50 [==============================] - 30s 597ms/step - loss: 0.0957 - acc: 0.9630 - val_loss: 0.1121 - val_acc: 0.9562\n",
      "\n",
      "Epoch 00323: val_acc did not improve from 0.97423\n",
      "Epoch 324/1000\n",
      "50/50 [==============================] - 31s 629ms/step - loss: 0.0748 - acc: 0.9669 - val_loss: 0.0821 - val_acc: 0.9716\n",
      "\n",
      "Epoch 00324: val_acc did not improve from 0.97423\n",
      "Epoch 325/1000\n",
      "50/50 [==============================] - 26s 516ms/step - loss: 0.0718 - acc: 0.9707 - val_loss: 0.0919 - val_acc: 0.9639\n",
      "\n",
      "Epoch 00325: val_acc did not improve from 0.97423\n",
      "Epoch 326/1000\n",
      "50/50 [==============================] - 26s 518ms/step - loss: 0.1405 - acc: 0.9465 - val_loss: 0.6690 - val_acc: 0.8170\n",
      "\n",
      "Epoch 00326: val_acc did not improve from 0.97423\n",
      "Epoch 327/1000\n",
      "50/50 [==============================] - 26s 523ms/step - loss: 0.1534 - acc: 0.9480 - val_loss: 0.1127 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00327: val_acc did not improve from 0.97423\n",
      "Epoch 328/1000\n",
      "50/50 [==============================] - 26s 518ms/step - loss: 0.1087 - acc: 0.9597 - val_loss: 0.1334 - val_acc: 0.9433\n",
      "\n",
      "Epoch 00328: val_acc did not improve from 0.97423\n",
      "Epoch 329/1000\n",
      "50/50 [==============================] - 26s 522ms/step - loss: 0.0968 - acc: 0.9643 - val_loss: 0.1063 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00329: val_acc did not improve from 0.97423\n",
      "Epoch 330/1000\n",
      "50/50 [==============================] - 26s 515ms/step - loss: 0.0866 - acc: 0.9630 - val_loss: 0.1141 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00330: val_acc did not improve from 0.97423\n",
      "Epoch 331/1000\n",
      "50/50 [==============================] - 25s 509ms/step - loss: 0.0817 - acc: 0.9647 - val_loss: 0.1306 - val_acc: 0.9459\n",
      "\n",
      "Epoch 00331: val_acc did not improve from 0.97423\n",
      "Epoch 332/1000\n",
      "50/50 [==============================] - 27s 538ms/step - loss: 0.0843 - acc: 0.9649 - val_loss: 0.1426 - val_acc: 0.9407\n",
      "\n",
      "Epoch 00332: val_acc did not improve from 0.97423\n",
      "Epoch 333/1000\n",
      "50/50 [==============================] - 42s 842ms/step - loss: 0.0835 - acc: 0.9657 - val_loss: 0.0834 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00333: val_acc did not improve from 0.97423\n",
      "Epoch 334/1000\n",
      "50/50 [==============================] - 41s 817ms/step - loss: 0.0735 - acc: 0.9717 - val_loss: 0.1685 - val_acc: 0.9381\n",
      "\n",
      "Epoch 00334: val_acc did not improve from 0.97423\n",
      "Epoch 335/1000\n",
      "50/50 [==============================] - 37s 749ms/step - loss: 0.0794 - acc: 0.9667 - val_loss: 0.0825 - val_acc: 0.9613\n",
      "\n",
      "Epoch 00335: val_acc did not improve from 0.97423\n",
      "Epoch 336/1000\n",
      "50/50 [==============================] - 38s 761ms/step - loss: 0.0775 - acc: 0.9730 - val_loss: 0.1401 - val_acc: 0.9459\n",
      "\n",
      "Epoch 00336: val_acc did not improve from 0.97423\n",
      "Epoch 337/1000\n",
      "50/50 [==============================] - 40s 791ms/step - loss: 0.0826 - acc: 0.9640 - val_loss: 0.0946 - val_acc: 0.9665\n",
      "\n",
      "Epoch 00337: val_acc did not improve from 0.97423\n",
      "Epoch 338/1000\n",
      "50/50 [==============================] - 34s 682ms/step - loss: 0.0887 - acc: 0.9629 - val_loss: 0.0744 - val_acc: 0.9665\n",
      "\n",
      "Epoch 00338: val_acc did not improve from 0.97423\n",
      "Epoch 339/1000\n",
      "50/50 [==============================] - 42s 849ms/step - loss: 0.0893 - acc: 0.9637 - val_loss: 0.1019 - val_acc: 0.9613\n",
      "\n",
      "Epoch 00339: val_acc did not improve from 0.97423\n",
      "Epoch 340/1000\n",
      "50/50 [==============================] - 35s 706ms/step - loss: 0.0832 - acc: 0.9653 - val_loss: 0.0984 - val_acc: 0.9639\n",
      "\n",
      "Epoch 00340: val_acc did not improve from 0.97423\n",
      "Epoch 341/1000\n",
      "50/50 [==============================] - 37s 742ms/step - loss: 0.0934 - acc: 0.9623 - val_loss: 0.1858 - val_acc: 0.9407\n",
      "\n",
      "Epoch 00341: val_acc did not improve from 0.97423\n",
      "Epoch 342/1000\n",
      "50/50 [==============================] - 53s 1s/step - loss: 0.0963 - acc: 0.9623 - val_loss: 0.0974 - val_acc: 0.9639\n",
      "\n",
      "Epoch 00342: val_acc did not improve from 0.97423\n",
      "Epoch 343/1000\n",
      "50/50 [==============================] - 33s 662ms/step - loss: 0.0667 - acc: 0.9730 - val_loss: 0.0710 - val_acc: 0.9665\n",
      "\n",
      "Epoch 00343: val_acc did not improve from 0.97423\n",
      "Epoch 344/1000\n",
      "50/50 [==============================] - 28s 553ms/step - loss: 0.0668 - acc: 0.9723 - val_loss: 0.0953 - val_acc: 0.9665\n",
      "\n",
      "Epoch 00344: val_acc did not improve from 0.97423\n",
      "Epoch 345/1000\n",
      "50/50 [==============================] - 24s 484ms/step - loss: 0.0821 - acc: 0.9693 - val_loss: 0.1069 - val_acc: 0.9639\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00345: val_acc did not improve from 0.97423\n",
      "Epoch 346/1000\n",
      "50/50 [==============================] - 24s 488ms/step - loss: 0.0698 - acc: 0.9727 - val_loss: 0.1102 - val_acc: 0.9562\n",
      "\n",
      "Epoch 00346: val_acc did not improve from 0.97423\n",
      "Epoch 347/1000\n",
      "50/50 [==============================] - 23s 465ms/step - loss: 0.0741 - acc: 0.9692 - val_loss: 0.2172 - val_acc: 0.9278\n",
      "\n",
      "Epoch 00347: val_acc did not improve from 0.97423\n",
      "Epoch 348/1000\n",
      "50/50 [==============================] - 24s 470ms/step - loss: 0.0824 - acc: 0.9690 - val_loss: 0.1219 - val_acc: 0.9536\n",
      "\n",
      "Epoch 00348: val_acc did not improve from 0.97423\n",
      "Epoch 349/1000\n",
      "50/50 [==============================] - 24s 471ms/step - loss: 0.0832 - acc: 0.9683 - val_loss: 0.1506 - val_acc: 0.9485\n",
      "\n",
      "Epoch 00349: val_acc did not improve from 0.97423\n",
      "Epoch 350/1000\n",
      "50/50 [==============================] - 23s 467ms/step - loss: 0.0874 - acc: 0.9655 - val_loss: 0.1264 - val_acc: 0.9381\n",
      "\n",
      "Epoch 00350: val_acc did not improve from 0.97423\n",
      "Epoch 351/1000\n",
      "50/50 [==============================] - 24s 473ms/step - loss: 0.0681 - acc: 0.9733 - val_loss: 0.1067 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00351: val_acc did not improve from 0.97423\n",
      "Epoch 352/1000\n",
      "50/50 [==============================] - 24s 471ms/step - loss: 0.0683 - acc: 0.9713 - val_loss: 0.1331 - val_acc: 0.9562\n",
      "\n",
      "Epoch 00352: val_acc did not improve from 0.97423\n",
      "Epoch 353/1000\n",
      "50/50 [==============================] - 28s 563ms/step - loss: 0.0675 - acc: 0.9757 - val_loss: 0.0937 - val_acc: 0.9613\n",
      "\n",
      "Epoch 00353: val_acc did not improve from 0.97423\n",
      "Epoch 354/1000\n",
      "50/50 [==============================] - 30s 609ms/step - loss: 0.0978 - acc: 0.9617 - val_loss: 0.1786 - val_acc: 0.9330\n",
      "\n",
      "Epoch 00354: val_acc did not improve from 0.97423\n",
      "Epoch 355/1000\n",
      "50/50 [==============================] - 30s 609ms/step - loss: 0.0873 - acc: 0.9603 - val_loss: 0.1088 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00355: val_acc did not improve from 0.97423\n",
      "Epoch 356/1000\n",
      "50/50 [==============================] - 35s 708ms/step - loss: 0.0811 - acc: 0.9670 - val_loss: 0.0857 - val_acc: 0.9562\n",
      "\n",
      "Epoch 00356: val_acc did not improve from 0.97423\n",
      "Epoch 357/1000\n",
      "50/50 [==============================] - 27s 540ms/step - loss: 0.0893 - acc: 0.9655 - val_loss: 0.1422 - val_acc: 0.9485\n",
      "\n",
      "Epoch 00357: val_acc did not improve from 0.97423\n",
      "Epoch 358/1000\n",
      "50/50 [==============================] - 31s 615ms/step - loss: 0.0691 - acc: 0.9695 - val_loss: 0.1316 - val_acc: 0.9562\n",
      "\n",
      "Epoch 00358: val_acc did not improve from 0.97423\n",
      "Epoch 359/1000\n",
      "50/50 [==============================] - 38s 755ms/step - loss: 0.0713 - acc: 0.9699 - val_loss: 0.0797 - val_acc: 0.9613\n",
      "\n",
      "Epoch 00359: val_acc did not improve from 0.97423\n",
      "Epoch 360/1000\n",
      "50/50 [==============================] - 32s 645ms/step - loss: 0.0819 - acc: 0.9713 - val_loss: 0.1117 - val_acc: 0.9613\n",
      "\n",
      "Epoch 00360: val_acc did not improve from 0.97423\n",
      "Epoch 361/1000\n",
      "50/50 [==============================] - 31s 612ms/step - loss: 0.0944 - acc: 0.9617 - val_loss: 0.1034 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00361: val_acc did not improve from 0.97423\n",
      "Epoch 362/1000\n",
      "50/50 [==============================] - 26s 513ms/step - loss: 0.0971 - acc: 0.9599 - val_loss: 0.1485 - val_acc: 0.9510\n",
      "\n",
      "Epoch 00362: val_acc did not improve from 0.97423\n",
      "Epoch 363/1000\n",
      "50/50 [==============================] - 24s 485ms/step - loss: 0.0822 - acc: 0.9673 - val_loss: 0.0749 - val_acc: 0.9665\n",
      "\n",
      "Epoch 00363: val_acc did not improve from 0.97423\n",
      "Epoch 364/1000\n",
      "50/50 [==============================] - 24s 479ms/step - loss: 0.0812 - acc: 0.9657 - val_loss: 0.0862 - val_acc: 0.9639\n",
      "\n",
      "Epoch 00364: val_acc did not improve from 0.97423\n",
      "Epoch 365/1000\n",
      "50/50 [==============================] - 24s 472ms/step - loss: 0.0892 - acc: 0.9621 - val_loss: 0.1596 - val_acc: 0.9433\n",
      "\n",
      "Epoch 00365: val_acc did not improve from 0.97423\n",
      "Epoch 366/1000\n",
      "50/50 [==============================] - 24s 476ms/step - loss: 0.0941 - acc: 0.9611 - val_loss: 0.0931 - val_acc: 0.9613\n",
      "\n",
      "Epoch 00366: val_acc did not improve from 0.97423\n",
      "Epoch 367/1000\n",
      "50/50 [==============================] - 24s 477ms/step - loss: 0.0865 - acc: 0.9650 - val_loss: 0.1039 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00367: val_acc did not improve from 0.97423\n",
      "Epoch 368/1000\n",
      "50/50 [==============================] - 24s 476ms/step - loss: 0.0859 - acc: 0.9683 - val_loss: 0.1189 - val_acc: 0.9613\n",
      "\n",
      "Epoch 00368: val_acc did not improve from 0.97423\n",
      "Epoch 369/1000\n",
      "50/50 [==============================] - 23s 468ms/step - loss: 0.0713 - acc: 0.9703 - val_loss: 0.1029 - val_acc: 0.9639\n",
      "\n",
      "Epoch 00369: val_acc did not improve from 0.97423\n",
      "Epoch 370/1000\n",
      "50/50 [==============================] - 24s 473ms/step - loss: 0.1145 - acc: 0.9523 - val_loss: 0.1333 - val_acc: 0.9381\n",
      "\n",
      "Epoch 00370: val_acc did not improve from 0.97423\n",
      "Epoch 371/1000\n",
      "50/50 [==============================] - 24s 480ms/step - loss: 0.0837 - acc: 0.9647 - val_loss: 0.1201 - val_acc: 0.9691\n",
      "\n",
      "Epoch 00371: val_acc did not improve from 0.97423\n",
      "Epoch 372/1000\n",
      "50/50 [==============================] - 24s 470ms/step - loss: 0.0731 - acc: 0.9703 - val_loss: 0.1502 - val_acc: 0.9407\n",
      "\n",
      "Epoch 00372: val_acc did not improve from 0.97423\n",
      "Epoch 373/1000\n",
      "50/50 [==============================] - 26s 523ms/step - loss: 0.0762 - acc: 0.9680 - val_loss: 0.1020 - val_acc: 0.9536\n",
      "\n",
      "Epoch 00373: val_acc did not improve from 0.97423\n",
      "Epoch 374/1000\n",
      "50/50 [==============================] - 26s 519ms/step - loss: 0.1109 - acc: 0.9543 - val_loss: 0.1375 - val_acc: 0.9536\n",
      "\n",
      "Epoch 00374: val_acc did not improve from 0.97423\n",
      "Epoch 375/1000\n",
      "50/50 [==============================] - 26s 513ms/step - loss: 0.0719 - acc: 0.9709 - val_loss: 0.1296 - val_acc: 0.9510\n",
      "\n",
      "Epoch 00375: val_acc did not improve from 0.97423\n",
      "Epoch 376/1000\n",
      "50/50 [==============================] - 25s 508ms/step - loss: 0.0887 - acc: 0.9662 - val_loss: 0.1120 - val_acc: 0.9639\n",
      "\n",
      "Epoch 00376: val_acc did not improve from 0.97423\n",
      "Epoch 377/1000\n",
      "50/50 [==============================] - 28s 570ms/step - loss: 0.0757 - acc: 0.9669 - val_loss: 0.1278 - val_acc: 0.9485\n",
      "\n",
      "Epoch 00377: val_acc did not improve from 0.97423\n",
      "Epoch 378/1000\n",
      "50/50 [==============================] - 26s 511ms/step - loss: 0.0801 - acc: 0.9722 - val_loss: 0.1615 - val_acc: 0.9459\n",
      "\n",
      "Epoch 00378: val_acc did not improve from 0.97423\n",
      "Epoch 379/1000\n",
      "50/50 [==============================] - 25s 505ms/step - loss: 0.0850 - acc: 0.9621 - val_loss: 0.1491 - val_acc: 0.9433\n",
      "\n",
      "Epoch 00379: val_acc did not improve from 0.97423\n",
      "Epoch 380/1000\n",
      "50/50 [==============================] - 26s 527ms/step - loss: 0.0807 - acc: 0.9667 - val_loss: 0.0875 - val_acc: 0.9665\n",
      "\n",
      "Epoch 00380: val_acc did not improve from 0.97423\n",
      "Epoch 381/1000\n",
      "50/50 [==============================] - 27s 531ms/step - loss: 0.0784 - acc: 0.9693 - val_loss: 0.0751 - val_acc: 0.9665\n",
      "\n",
      "Epoch 00381: val_acc did not improve from 0.97423\n",
      "Epoch 382/1000\n",
      "50/50 [==============================] - 26s 523ms/step - loss: 0.0660 - acc: 0.9700 - val_loss: 0.0705 - val_acc: 0.9639\n",
      "\n",
      "Epoch 00382: val_acc did not improve from 0.97423\n",
      "Epoch 383/1000\n",
      "50/50 [==============================] - 28s 551ms/step - loss: 0.0822 - acc: 0.9717 - val_loss: 0.0936 - val_acc: 0.9716\n",
      "\n",
      "Epoch 00383: val_acc did not improve from 0.97423\n",
      "Epoch 384/1000\n",
      "50/50 [==============================] - 29s 574ms/step - loss: 0.0781 - acc: 0.9657 - val_loss: 0.1151 - val_acc: 0.9562\n",
      "\n",
      "Epoch 00384: val_acc did not improve from 0.97423\n",
      "Epoch 385/1000\n",
      "50/50 [==============================] - 26s 528ms/step - loss: 0.0863 - acc: 0.9660 - val_loss: 0.1838 - val_acc: 0.9253\n",
      "\n",
      "Epoch 00385: val_acc did not improve from 0.97423\n",
      "Epoch 386/1000\n",
      "50/50 [==============================] - 25s 494ms/step - loss: 0.1221 - acc: 0.9542 - val_loss: 0.1109 - val_acc: 0.9433\n",
      "\n",
      "Epoch 00386: val_acc did not improve from 0.97423\n",
      "Epoch 387/1000\n",
      "50/50 [==============================] - 24s 480ms/step - loss: 0.0681 - acc: 0.9757 - val_loss: 0.0727 - val_acc: 0.9691\n",
      "\n",
      "Epoch 00387: val_acc did not improve from 0.97423\n",
      "Epoch 388/1000\n",
      "50/50 [==============================] - 25s 501ms/step - loss: 0.0795 - acc: 0.9687 - val_loss: 0.0689 - val_acc: 0.9716\n",
      "\n",
      "Epoch 00388: val_acc did not improve from 0.97423\n",
      "Epoch 389/1000\n",
      "50/50 [==============================] - 25s 491ms/step - loss: 0.0808 - acc: 0.9662 - val_loss: 0.0794 - val_acc: 0.9691\n",
      "\n",
      "Epoch 00389: val_acc did not improve from 0.97423\n",
      "Epoch 390/1000\n",
      "50/50 [==============================] - 28s 559ms/step - loss: 0.0669 - acc: 0.9720 - val_loss: 0.0760 - val_acc: 0.9691\n",
      "\n",
      "Epoch 00390: val_acc did not improve from 0.97423\n",
      "Epoch 391/1000\n",
      "50/50 [==============================] - 24s 481ms/step - loss: 0.0759 - acc: 0.9670 - val_loss: 0.0861 - val_acc: 0.9613\n",
      "\n",
      "Epoch 00391: val_acc did not improve from 0.97423\n",
      "Epoch 392/1000\n",
      "50/50 [==============================] - 28s 554ms/step - loss: 0.0780 - acc: 0.9670 - val_loss: 0.0604 - val_acc: 0.9742\n",
      "\n",
      "Epoch 00392: val_acc did not improve from 0.97423\n",
      "Epoch 393/1000\n",
      "50/50 [==============================] - 24s 483ms/step - loss: 0.0622 - acc: 0.9737 - val_loss: 0.1107 - val_acc: 0.9510\n",
      "\n",
      "Epoch 00393: val_acc did not improve from 0.97423\n",
      "Epoch 394/1000\n",
      "50/50 [==============================] - 24s 483ms/step - loss: 0.0749 - acc: 0.9707 - val_loss: 0.0659 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00394: val_acc improved from 0.97423 to 0.97938, saving model to best_cnn.h5\n",
      "Epoch 395/1000\n",
      "50/50 [==============================] - 25s 500ms/step - loss: 0.0689 - acc: 0.9710 - val_loss: 0.1030 - val_acc: 0.9665\n",
      "\n",
      "Epoch 00395: val_acc did not improve from 0.97938\n",
      "Epoch 396/1000\n",
      "50/50 [==============================] - 26s 527ms/step - loss: 0.0830 - acc: 0.9700 - val_loss: 0.1472 - val_acc: 0.9330\n",
      "\n",
      "Epoch 00396: val_acc did not improve from 0.97938\n",
      "Epoch 397/1000\n",
      "50/50 [==============================] - 24s 477ms/step - loss: 0.0950 - acc: 0.9649 - val_loss: 0.1252 - val_acc: 0.9356\n",
      "\n",
      "Epoch 00397: val_acc did not improve from 0.97938\n",
      "Epoch 398/1000\n",
      "50/50 [==============================] - 23s 469ms/step - loss: 0.0722 - acc: 0.9720 - val_loss: 0.0597 - val_acc: 0.9716\n",
      "\n",
      "Epoch 00398: val_acc did not improve from 0.97938\n",
      "Epoch 399/1000\n",
      "50/50 [==============================] - 24s 477ms/step - loss: 0.0746 - acc: 0.9703 - val_loss: 0.1158 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00399: val_acc did not improve from 0.97938\n",
      "Epoch 400/1000\n",
      "50/50 [==============================] - 24s 484ms/step - loss: 0.0725 - acc: 0.9700 - val_loss: 0.0820 - val_acc: 0.9613\n",
      "\n",
      "Epoch 00400: val_acc did not improve from 0.97938\n",
      "Epoch 401/1000\n",
      "50/50 [==============================] - 24s 473ms/step - loss: 0.0925 - acc: 0.9623 - val_loss: 0.1741 - val_acc: 0.9407\n",
      "\n",
      "Epoch 00401: val_acc did not improve from 0.97938\n",
      "Epoch 402/1000\n",
      "50/50 [==============================] - 23s 469ms/step - loss: 0.0941 - acc: 0.9672 - val_loss: 0.1451 - val_acc: 0.9485\n",
      "\n",
      "Epoch 00402: val_acc did not improve from 0.97938\n",
      "Epoch 403/1000\n",
      "50/50 [==============================] - 24s 481ms/step - loss: 0.0821 - acc: 0.9650 - val_loss: 0.1145 - val_acc: 0.9562\n",
      "\n",
      "Epoch 00403: val_acc did not improve from 0.97938\n",
      "Epoch 404/1000\n",
      "50/50 [==============================] - 24s 479ms/step - loss: 0.0730 - acc: 0.9719 - val_loss: 0.0739 - val_acc: 0.9691\n",
      "\n",
      "Epoch 00404: val_acc did not improve from 0.97938\n",
      "Epoch 405/1000\n",
      "50/50 [==============================] - 24s 483ms/step - loss: 0.0750 - acc: 0.9672 - val_loss: 0.1143 - val_acc: 0.9510\n",
      "\n",
      "Epoch 00405: val_acc did not improve from 0.97938\n",
      "Epoch 406/1000\n",
      "50/50 [==============================] - 24s 475ms/step - loss: 0.0733 - acc: 0.9695 - val_loss: 0.0853 - val_acc: 0.9665\n",
      "\n",
      "Epoch 00406: val_acc did not improve from 0.97938\n",
      "Epoch 407/1000\n",
      "50/50 [==============================] - 27s 548ms/step - loss: 0.0773 - acc: 0.9650 - val_loss: 0.0700 - val_acc: 0.9691\n",
      "\n",
      "Epoch 00407: val_acc did not improve from 0.97938\n",
      "Epoch 408/1000\n",
      "50/50 [==============================] - 24s 489ms/step - loss: 0.0700 - acc: 0.9730 - val_loss: 0.1028 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00408: val_acc did not improve from 0.97938\n",
      "Epoch 409/1000\n",
      "50/50 [==============================] - 24s 475ms/step - loss: 0.0761 - acc: 0.9685 - val_loss: 0.1134 - val_acc: 0.9536\n",
      "\n",
      "Epoch 00409: val_acc did not improve from 0.97938\n",
      "Epoch 410/1000\n",
      "50/50 [==============================] - 24s 485ms/step - loss: 0.0639 - acc: 0.9740 - val_loss: 0.1400 - val_acc: 0.9433\n",
      "\n",
      "Epoch 00410: val_acc did not improve from 0.97938\n",
      "Epoch 411/1000\n",
      "50/50 [==============================] - 25s 505ms/step - loss: 0.0821 - acc: 0.9670 - val_loss: 0.0605 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00411: val_acc did not improve from 0.97938\n",
      "Epoch 412/1000\n",
      "50/50 [==============================] - 29s 574ms/step - loss: 0.0771 - acc: 0.9653 - val_loss: 0.1133 - val_acc: 0.9459\n",
      "\n",
      "Epoch 00412: val_acc did not improve from 0.97938\n",
      "Epoch 413/1000\n",
      "50/50 [==============================] - 24s 480ms/step - loss: 0.0805 - acc: 0.9662 - val_loss: 0.0758 - val_acc: 0.9691\n",
      "\n",
      "Epoch 00413: val_acc did not improve from 0.97938\n",
      "Epoch 414/1000\n",
      "50/50 [==============================] - 24s 480ms/step - loss: 0.0601 - acc: 0.9767 - val_loss: 0.0750 - val_acc: 0.9665\n",
      "\n",
      "Epoch 00414: val_acc did not improve from 0.97938\n",
      "Epoch 415/1000\n",
      "50/50 [==============================] - 24s 473ms/step - loss: 0.0655 - acc: 0.9747 - val_loss: 0.0763 - val_acc: 0.9639\n",
      "\n",
      "Epoch 00415: val_acc did not improve from 0.97938\n",
      "Epoch 416/1000\n",
      "50/50 [==============================] - 24s 473ms/step - loss: 0.1067 - acc: 0.9587 - val_loss: 0.0780 - val_acc: 0.9691\n",
      "\n",
      "Epoch 00416: val_acc did not improve from 0.97938\n",
      "Epoch 417/1000\n",
      "50/50 [==============================] - 24s 483ms/step - loss: 0.0668 - acc: 0.9707 - val_loss: 0.0624 - val_acc: 0.9691\n",
      "\n",
      "Epoch 00417: val_acc did not improve from 0.97938\n",
      "Epoch 418/1000\n",
      "50/50 [==============================] - 25s 503ms/step - loss: 0.0787 - acc: 0.9677 - val_loss: 0.0657 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00418: val_acc did not improve from 0.97938\n",
      "Epoch 419/1000\n",
      "50/50 [==============================] - 24s 483ms/step - loss: 0.0924 - acc: 0.9643 - val_loss: 0.1203 - val_acc: 0.9716\n",
      "\n",
      "Epoch 00419: val_acc did not improve from 0.97938\n",
      "Epoch 420/1000\n",
      "50/50 [==============================] - 25s 492ms/step - loss: 0.0727 - acc: 0.9707 - val_loss: 0.1365 - val_acc: 0.9381\n",
      "\n",
      "Epoch 00420: val_acc did not improve from 0.97938\n",
      "Epoch 421/1000\n",
      "50/50 [==============================] - 25s 500ms/step - loss: 0.0896 - acc: 0.9640 - val_loss: 0.0970 - val_acc: 0.9562\n",
      "\n",
      "Epoch 00421: val_acc did not improve from 0.97938\n",
      "Epoch 422/1000\n",
      "50/50 [==============================] - 24s 477ms/step - loss: 0.0697 - acc: 0.9717 - val_loss: 0.0571 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00422: val_acc improved from 0.97938 to 0.97938, saving model to best_cnn.h5\n",
      "Epoch 423/1000\n",
      "50/50 [==============================] - 24s 472ms/step - loss: 0.0664 - acc: 0.9743 - val_loss: 0.0965 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00423: val_acc did not improve from 0.97938\n",
      "Epoch 424/1000\n",
      "50/50 [==============================] - 24s 477ms/step - loss: 0.0903 - acc: 0.9653 - val_loss: 0.1625 - val_acc: 0.9407\n",
      "\n",
      "Epoch 00424: val_acc did not improve from 0.97938\n",
      "Epoch 425/1000\n",
      "50/50 [==============================] - 24s 476ms/step - loss: 0.0889 - acc: 0.9670 - val_loss: 0.0751 - val_acc: 0.9691\n",
      "\n",
      "Epoch 00425: val_acc did not improve from 0.97938\n",
      "Epoch 426/1000\n",
      "50/50 [==============================] - 24s 471ms/step - loss: 0.0737 - acc: 0.9697 - val_loss: 0.0714 - val_acc: 0.9691\n",
      "\n",
      "Epoch 00426: val_acc did not improve from 0.97938\n",
      "Epoch 427/1000\n",
      "50/50 [==============================] - 24s 486ms/step - loss: 0.0677 - acc: 0.9730 - val_loss: 0.0787 - val_acc: 0.9691\n",
      "\n",
      "Epoch 00427: val_acc did not improve from 0.97938\n",
      "Epoch 428/1000\n",
      "50/50 [==============================] - 24s 480ms/step - loss: 0.0734 - acc: 0.9697 - val_loss: 0.1076 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00428: val_acc did not improve from 0.97938\n",
      "Epoch 429/1000\n",
      "50/50 [==============================] - 24s 483ms/step - loss: 0.0675 - acc: 0.9740 - val_loss: 0.0762 - val_acc: 0.9716\n",
      "\n",
      "Epoch 00429: val_acc did not improve from 0.97938\n",
      "Epoch 430/1000\n",
      "50/50 [==============================] - 24s 473ms/step - loss: 0.0676 - acc: 0.9733 - val_loss: 0.1378 - val_acc: 0.9536\n",
      "\n",
      "Epoch 00430: val_acc did not improve from 0.97938\n",
      "Epoch 431/1000\n",
      "50/50 [==============================] - 23s 469ms/step - loss: 0.1886 - acc: 0.9421 - val_loss: 0.1323 - val_acc: 0.9485\n",
      "\n",
      "Epoch 00431: val_acc did not improve from 0.97938\n",
      "Epoch 432/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 23s 468ms/step - loss: 0.1105 - acc: 0.9550 - val_loss: 0.0844 - val_acc: 0.9742\n",
      "\n",
      "Epoch 00432: val_acc did not improve from 0.97938\n",
      "Epoch 433/1000\n",
      "50/50 [==============================] - 25s 499ms/step - loss: 0.0836 - acc: 0.9707 - val_loss: 0.0763 - val_acc: 0.9691\n",
      "\n",
      "Epoch 00433: val_acc did not improve from 0.97938\n",
      "Epoch 434/1000\n",
      "50/50 [==============================] - 24s 486ms/step - loss: 0.0720 - acc: 0.9687 - val_loss: 0.0884 - val_acc: 0.9639\n",
      "\n",
      "Epoch 00434: val_acc did not improve from 0.97938\n",
      "Epoch 435/1000\n",
      "50/50 [==============================] - 24s 471ms/step - loss: 0.0721 - acc: 0.9697 - val_loss: 0.0951 - val_acc: 0.9665\n",
      "\n",
      "Epoch 00435: val_acc did not improve from 0.97938\n",
      "Epoch 436/1000\n",
      "50/50 [==============================] - 24s 480ms/step - loss: 0.0785 - acc: 0.9660 - val_loss: 0.1016 - val_acc: 0.9639\n",
      "\n",
      "Epoch 00436: val_acc did not improve from 0.97938\n",
      "Epoch 437/1000\n",
      "50/50 [==============================] - 24s 475ms/step - loss: 0.0541 - acc: 0.9805 - val_loss: 0.0801 - val_acc: 0.9691\n",
      "\n",
      "Epoch 00437: val_acc did not improve from 0.97938\n",
      "Epoch 438/1000\n",
      "50/50 [==============================] - 24s 473ms/step - loss: 0.0745 - acc: 0.9707 - val_loss: 0.1633 - val_acc: 0.9510\n",
      "\n",
      "Epoch 00438: val_acc did not improve from 0.97938\n",
      "Epoch 439/1000\n",
      "50/50 [==============================] - 24s 478ms/step - loss: 0.1061 - acc: 0.9620 - val_loss: 0.1509 - val_acc: 0.9459\n",
      "\n",
      "Epoch 00439: val_acc did not improve from 0.97938\n",
      "Epoch 440/1000\n",
      "50/50 [==============================] - 24s 480ms/step - loss: 0.0656 - acc: 0.9720 - val_loss: 0.0690 - val_acc: 0.9691\n",
      "\n",
      "Epoch 00440: val_acc did not improve from 0.97938\n",
      "Epoch 441/1000\n",
      "50/50 [==============================] - 24s 472ms/step - loss: 0.0814 - acc: 0.9707 - val_loss: 0.0877 - val_acc: 0.9639\n",
      "\n",
      "Epoch 00441: val_acc did not improve from 0.97938\n",
      "Epoch 442/1000\n",
      "50/50 [==============================] - 24s 473ms/step - loss: 0.0826 - acc: 0.9672 - val_loss: 0.0773 - val_acc: 0.9716\n",
      "\n",
      "Epoch 00442: val_acc did not improve from 0.97938\n",
      "Epoch 443/1000\n",
      "50/50 [==============================] - 24s 471ms/step - loss: 0.0755 - acc: 0.9733 - val_loss: 0.0788 - val_acc: 0.9665\n",
      "\n",
      "Epoch 00443: val_acc did not improve from 0.97938\n",
      "Epoch 444/1000\n",
      "50/50 [==============================] - 26s 522ms/step - loss: 0.0697 - acc: 0.9703 - val_loss: 0.0930 - val_acc: 0.9639\n",
      "\n",
      "Epoch 00444: val_acc did not improve from 0.97938\n",
      "Epoch 445/1000\n",
      "50/50 [==============================] - 24s 477ms/step - loss: 0.1134 - acc: 0.9577 - val_loss: 0.1442 - val_acc: 0.9304\n",
      "\n",
      "Epoch 00445: val_acc did not improve from 0.97938\n",
      "Epoch 446/1000\n",
      "50/50 [==============================] - 24s 476ms/step - loss: 0.0793 - acc: 0.9663 - val_loss: 0.1059 - val_acc: 0.9562\n",
      "\n",
      "Epoch 00446: val_acc did not improve from 0.97938\n",
      "Epoch 447/1000\n",
      "50/50 [==============================] - 24s 473ms/step - loss: 0.0709 - acc: 0.9717 - val_loss: 0.1564 - val_acc: 0.9459\n",
      "\n",
      "Epoch 00447: val_acc did not improve from 0.97938\n",
      "Epoch 448/1000\n",
      "50/50 [==============================] - 24s 481ms/step - loss: 0.0736 - acc: 0.9700 - val_loss: 0.1264 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00448: val_acc did not improve from 0.97938\n",
      "Epoch 449/1000\n",
      "50/50 [==============================] - 26s 516ms/step - loss: 0.0821 - acc: 0.9700 - val_loss: 0.0686 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00449: val_acc did not improve from 0.97938\n",
      "Epoch 450/1000\n",
      "50/50 [==============================] - 25s 492ms/step - loss: 0.0741 - acc: 0.9717 - val_loss: 0.1065 - val_acc: 0.9536\n",
      "\n",
      "Epoch 00450: val_acc did not improve from 0.97938\n",
      "Epoch 451/1000\n",
      "50/50 [==============================] - 25s 501ms/step - loss: 0.0626 - acc: 0.9780 - val_loss: 0.1350 - val_acc: 0.9459\n",
      "\n",
      "Epoch 00451: val_acc did not improve from 0.97938\n",
      "Epoch 452/1000\n",
      "50/50 [==============================] - 23s 469ms/step - loss: 0.0783 - acc: 0.9747 - val_loss: 0.0980 - val_acc: 0.9639\n",
      "\n",
      "Epoch 00452: val_acc did not improve from 0.97938\n",
      "Epoch 453/1000\n",
      "50/50 [==============================] - 24s 475ms/step - loss: 0.0731 - acc: 0.9703 - val_loss: 0.1640 - val_acc: 0.9433\n",
      "\n",
      "Epoch 00453: val_acc did not improve from 0.97938\n",
      "Epoch 454/1000\n",
      "50/50 [==============================] - 25s 499ms/step - loss: 0.0825 - acc: 0.9703 - val_loss: 0.1141 - val_acc: 0.9433\n",
      "\n",
      "Epoch 00454: val_acc did not improve from 0.97938\n",
      "Epoch 455/1000\n",
      "50/50 [==============================] - 28s 552ms/step - loss: 0.0647 - acc: 0.9759 - val_loss: 0.1019 - val_acc: 0.9536\n",
      "\n",
      "Epoch 00455: val_acc did not improve from 0.97938\n",
      "Epoch 456/1000\n",
      "50/50 [==============================] - 24s 482ms/step - loss: 0.0580 - acc: 0.9777 - val_loss: 0.1019 - val_acc: 0.9665\n",
      "\n",
      "Epoch 00456: val_acc did not improve from 0.97938\n",
      "Epoch 457/1000\n",
      "50/50 [==============================] - 24s 473ms/step - loss: 0.0886 - acc: 0.9644 - val_loss: 0.0758 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00457: val_acc did not improve from 0.97938\n",
      "Epoch 458/1000\n",
      "50/50 [==============================] - 24s 471ms/step - loss: 0.0681 - acc: 0.9727 - val_loss: 0.0669 - val_acc: 0.9742\n",
      "\n",
      "Epoch 00458: val_acc did not improve from 0.97938\n",
      "Epoch 459/1000\n",
      "50/50 [==============================] - 24s 476ms/step - loss: 0.0756 - acc: 0.9693 - val_loss: 0.1010 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00459: val_acc did not improve from 0.97938\n",
      "Epoch 460/1000\n",
      "50/50 [==============================] - 24s 471ms/step - loss: 0.1206 - acc: 0.9613 - val_loss: 0.2435 - val_acc: 0.9407\n",
      "\n",
      "Epoch 00460: val_acc did not improve from 0.97938\n",
      "Epoch 461/1000\n",
      "50/50 [==============================] - 24s 474ms/step - loss: 0.0946 - acc: 0.9610 - val_loss: 0.0762 - val_acc: 0.9742\n",
      "\n",
      "Epoch 00461: val_acc did not improve from 0.97938\n",
      "Epoch 462/1000\n",
      "50/50 [==============================] - 32s 631ms/step - loss: 0.0706 - acc: 0.9717 - val_loss: 0.0702 - val_acc: 0.9691\n",
      "\n",
      "Epoch 00462: val_acc did not improve from 0.97938\n",
      "Epoch 463/1000\n",
      "50/50 [==============================] - 34s 680ms/step - loss: 0.0687 - acc: 0.9733 - val_loss: 0.1188 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00463: val_acc did not improve from 0.97938\n",
      "Epoch 464/1000\n",
      "50/50 [==============================] - 38s 769ms/step - loss: 0.0826 - acc: 0.9657 - val_loss: 0.1327 - val_acc: 0.9407\n",
      "\n",
      "Epoch 00464: val_acc did not improve from 0.97938\n",
      "Epoch 465/1000\n",
      "50/50 [==============================] - 33s 655ms/step - loss: 0.0674 - acc: 0.9717 - val_loss: 0.0810 - val_acc: 0.9639\n",
      "\n",
      "Epoch 00465: val_acc did not improve from 0.97938\n",
      "Epoch 466/1000\n",
      "50/50 [==============================] - 25s 499ms/step - loss: 0.0686 - acc: 0.9697 - val_loss: 0.0745 - val_acc: 0.9742\n",
      "\n",
      "Epoch 00466: val_acc did not improve from 0.97938\n",
      "Epoch 467/1000\n",
      "50/50 [==============================] - 25s 505ms/step - loss: 0.0565 - acc: 0.9753 - val_loss: 0.0851 - val_acc: 0.9639\n",
      "\n",
      "Epoch 00467: val_acc did not improve from 0.97938\n",
      "Epoch 468/1000\n",
      "50/50 [==============================] - 25s 496ms/step - loss: 0.0542 - acc: 0.9763 - val_loss: 0.1264 - val_acc: 0.9459\n",
      "\n",
      "Epoch 00468: val_acc did not improve from 0.97938\n",
      "Epoch 469/1000\n",
      "50/50 [==============================] - 24s 477ms/step - loss: 0.0831 - acc: 0.9683 - val_loss: 0.0830 - val_acc: 0.9613\n",
      "\n",
      "Epoch 00469: val_acc did not improve from 0.97938\n",
      "Epoch 470/1000\n",
      "50/50 [==============================] - 24s 475ms/step - loss: 0.0644 - acc: 0.9740 - val_loss: 0.0580 - val_acc: 0.9716\n",
      "\n",
      "Epoch 00470: val_acc did not improve from 0.97938\n",
      "Epoch 471/1000\n",
      "50/50 [==============================] - 23s 470ms/step - loss: 0.0620 - acc: 0.9757 - val_loss: 0.0918 - val_acc: 0.9510\n",
      "\n",
      "Epoch 00471: val_acc did not improve from 0.97938\n",
      "Epoch 472/1000\n",
      "50/50 [==============================] - 24s 481ms/step - loss: 0.0629 - acc: 0.9737 - val_loss: 0.0920 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00472: val_acc did not improve from 0.97938\n",
      "Epoch 473/1000\n",
      "50/50 [==============================] - 24s 482ms/step - loss: 0.0933 - acc: 0.9677 - val_loss: 0.0940 - val_acc: 0.9613\n",
      "\n",
      "Epoch 00473: val_acc did not improve from 0.97938\n",
      "Epoch 474/1000\n",
      "50/50 [==============================] - 23s 467ms/step - loss: 0.0853 - acc: 0.9699 - val_loss: 0.0773 - val_acc: 0.9665\n",
      "\n",
      "Epoch 00474: val_acc did not improve from 0.97938\n",
      "Epoch 475/1000\n",
      "50/50 [==============================] - 24s 471ms/step - loss: 0.0688 - acc: 0.9733 - val_loss: 0.0744 - val_acc: 0.9716\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00475: val_acc did not improve from 0.97938\n",
      "Epoch 476/1000\n",
      "50/50 [==============================] - 23s 466ms/step - loss: 0.0785 - acc: 0.9705 - val_loss: 0.1027 - val_acc: 0.9613\n",
      "\n",
      "Epoch 00476: val_acc did not improve from 0.97938\n",
      "Epoch 477/1000\n",
      "50/50 [==============================] - 24s 477ms/step - loss: 0.0484 - acc: 0.9827 - val_loss: 0.1543 - val_acc: 0.9433\n",
      "\n",
      "Epoch 00477: val_acc did not improve from 0.97938\n",
      "Epoch 478/1000\n",
      "50/50 [==============================] - 34s 674ms/step - loss: 0.0761 - acc: 0.9677 - val_loss: 0.0469 - val_acc: 0.9845\n",
      "\n",
      "Epoch 00478: val_acc improved from 0.97938 to 0.98454, saving model to best_cnn.h5\n",
      "Epoch 479/1000\n",
      "50/50 [==============================] - 24s 485ms/step - loss: 0.0878 - acc: 0.9660 - val_loss: 0.0906 - val_acc: 0.9562\n",
      "\n",
      "Epoch 00479: val_acc did not improve from 0.98454\n",
      "Epoch 480/1000\n",
      "50/50 [==============================] - 24s 488ms/step - loss: 0.0731 - acc: 0.9713 - val_loss: 0.0846 - val_acc: 0.9613\n",
      "\n",
      "Epoch 00480: val_acc did not improve from 0.98454\n",
      "Epoch 481/1000\n",
      "50/50 [==============================] - 30s 595ms/step - loss: 0.0682 - acc: 0.9733 - val_loss: 0.1156 - val_acc: 0.9485\n",
      "\n",
      "Epoch 00481: val_acc did not improve from 0.98454\n",
      "Epoch 482/1000\n",
      "50/50 [==============================] - 33s 659ms/step - loss: 0.0787 - acc: 0.9697 - val_loss: 0.0892 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00482: val_acc did not improve from 0.98454\n",
      "Epoch 483/1000\n",
      "50/50 [==============================] - 32s 631ms/step - loss: 0.0729 - acc: 0.9695 - val_loss: 0.0848 - val_acc: 0.9536\n",
      "\n",
      "Epoch 00483: val_acc did not improve from 0.98454\n",
      "Epoch 484/1000\n",
      "50/50 [==============================] - 30s 596ms/step - loss: 0.0701 - acc: 0.9733 - val_loss: 0.0551 - val_acc: 0.9691\n",
      "\n",
      "Epoch 00484: val_acc did not improve from 0.98454\n",
      "Epoch 485/1000\n",
      "50/50 [==============================] - 29s 571ms/step - loss: 0.0590 - acc: 0.9763 - val_loss: 0.0693 - val_acc: 0.9716\n",
      "\n",
      "Epoch 00485: val_acc did not improve from 0.98454\n",
      "Epoch 486/1000\n",
      "50/50 [==============================] - 36s 721ms/step - loss: 0.0527 - acc: 0.9763 - val_loss: 0.0833 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00486: val_acc did not improve from 0.98454\n",
      "Epoch 487/1000\n",
      "50/50 [==============================] - 25s 491ms/step - loss: 0.0638 - acc: 0.9730 - val_loss: 0.1551 - val_acc: 0.9485\n",
      "\n",
      "Epoch 00487: val_acc did not improve from 0.98454\n",
      "Epoch 488/1000\n",
      "50/50 [==============================] - 25s 493ms/step - loss: 0.0821 - acc: 0.9704 - val_loss: 0.0708 - val_acc: 0.9716\n",
      "\n",
      "Epoch 00488: val_acc did not improve from 0.98454\n",
      "Epoch 489/1000\n",
      "50/50 [==============================] - 25s 508ms/step - loss: 0.0684 - acc: 0.9757 - val_loss: 0.0703 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00489: val_acc did not improve from 0.98454\n",
      "Epoch 490/1000\n",
      "50/50 [==============================] - 24s 478ms/step - loss: 0.0657 - acc: 0.9717 - val_loss: 0.1472 - val_acc: 0.9613\n",
      "\n",
      "Epoch 00490: val_acc did not improve from 0.98454\n",
      "Epoch 491/1000\n",
      "50/50 [==============================] - 34s 690ms/step - loss: 0.0559 - acc: 0.9770 - val_loss: 0.1555 - val_acc: 0.9665\n",
      "\n",
      "Epoch 00491: val_acc did not improve from 0.98454\n",
      "Epoch 492/1000\n",
      "50/50 [==============================] - 36s 727ms/step - loss: 0.1385 - acc: 0.9543 - val_loss: 0.0865 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00492: val_acc did not improve from 0.98454\n",
      "Epoch 493/1000\n",
      "50/50 [==============================] - 29s 583ms/step - loss: 0.0689 - acc: 0.9700 - val_loss: 0.0508 - val_acc: 0.9820\n",
      "\n",
      "Epoch 00493: val_acc did not improve from 0.98454\n",
      "Epoch 494/1000\n",
      "50/50 [==============================] - 28s 557ms/step - loss: 0.0665 - acc: 0.9717 - val_loss: 0.1334 - val_acc: 0.9613\n",
      "\n",
      "Epoch 00494: val_acc did not improve from 0.98454\n",
      "Epoch 495/1000\n",
      "50/50 [==============================] - 26s 513ms/step - loss: 0.0658 - acc: 0.9730 - val_loss: 0.1297 - val_acc: 0.9665\n",
      "\n",
      "Epoch 00495: val_acc did not improve from 0.98454\n",
      "Epoch 496/1000\n",
      "50/50 [==============================] - 28s 570ms/step - loss: 0.0652 - acc: 0.9757 - val_loss: 0.1495 - val_acc: 0.9510\n",
      "\n",
      "Epoch 00496: val_acc did not improve from 0.98454\n",
      "Epoch 497/1000\n",
      "50/50 [==============================] - 1898s 38s/step - loss: 0.0660 - acc: 0.9727 - val_loss: 0.0924 - val_acc: 0.9639\n",
      "\n",
      "Epoch 00497: val_acc did not improve from 0.98454\n",
      "Epoch 498/1000\n",
      "50/50 [==============================] - 40s 791ms/step - loss: 0.0618 - acc: 0.9737 - val_loss: 0.1003 - val_acc: 0.9691\n",
      "\n",
      "Epoch 00498: val_acc did not improve from 0.98454\n",
      "Epoch 499/1000\n",
      "50/50 [==============================] - 32s 639ms/step - loss: 0.0954 - acc: 0.9617 - val_loss: 0.0657 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00499: val_acc did not improve from 0.98454\n",
      "Epoch 500/1000\n",
      "50/50 [==============================] - 25s 506ms/step - loss: 0.0691 - acc: 0.9699 - val_loss: 0.1165 - val_acc: 0.9536\n",
      "\n",
      "Epoch 00500: val_acc did not improve from 0.98454\n",
      "Epoch 501/1000\n",
      "50/50 [==============================] - 26s 516ms/step - loss: 0.0589 - acc: 0.9745 - val_loss: 0.0678 - val_acc: 0.9691\n",
      "\n",
      "Epoch 00501: val_acc did not improve from 0.98454\n",
      "Epoch 502/1000\n",
      "50/50 [==============================] - 25s 510ms/step - loss: 0.0696 - acc: 0.9747 - val_loss: 0.1500 - val_acc: 0.9459\n",
      "\n",
      "Epoch 00502: val_acc did not improve from 0.98454\n",
      "Epoch 503/1000\n",
      "50/50 [==============================] - 25s 494ms/step - loss: 0.0641 - acc: 0.9757 - val_loss: 0.0815 - val_acc: 0.9716\n",
      "\n",
      "Epoch 00503: val_acc did not improve from 0.98454\n",
      "Epoch 504/1000\n",
      "50/50 [==============================] - 25s 491ms/step - loss: 0.0633 - acc: 0.9743 - val_loss: 0.0656 - val_acc: 0.9639\n",
      "\n",
      "Epoch 00504: val_acc did not improve from 0.98454\n",
      "Epoch 505/1000\n",
      "50/50 [==============================] - 24s 479ms/step - loss: 0.0771 - acc: 0.9667 - val_loss: 0.1079 - val_acc: 0.9485\n",
      "\n",
      "Epoch 00505: val_acc did not improve from 0.98454\n",
      "Epoch 506/1000\n",
      "50/50 [==============================] - 30s 606ms/step - loss: 0.1000 - acc: 0.9592 - val_loss: 0.0761 - val_acc: 0.9665\n",
      "\n",
      "Epoch 00506: val_acc did not improve from 0.98454\n",
      "Epoch 507/1000\n",
      "50/50 [==============================] - 24s 480ms/step - loss: 0.0672 - acc: 0.9763 - val_loss: 0.0597 - val_acc: 0.9716\n",
      "\n",
      "Epoch 00507: val_acc did not improve from 0.98454\n",
      "Epoch 508/1000\n",
      "50/50 [==============================] - 25s 495ms/step - loss: 0.0709 - acc: 0.9720 - val_loss: 0.0874 - val_acc: 0.9665\n",
      "\n",
      "Epoch 00508: val_acc did not improve from 0.98454\n",
      "Epoch 509/1000\n",
      "50/50 [==============================] - 29s 573ms/step - loss: 0.0611 - acc: 0.9757 - val_loss: 0.0946 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00509: val_acc did not improve from 0.98454\n",
      "Epoch 510/1000\n",
      "50/50 [==============================] - 25s 504ms/step - loss: 0.0604 - acc: 0.9770 - val_loss: 0.0954 - val_acc: 0.9665\n",
      "\n",
      "Epoch 00510: val_acc did not improve from 0.98454\n",
      "Epoch 511/1000\n",
      "50/50 [==============================] - 24s 476ms/step - loss: 0.0657 - acc: 0.9750 - val_loss: 0.1432 - val_acc: 0.9510\n",
      "\n",
      "Epoch 00511: val_acc did not improve from 0.98454\n",
      "Epoch 512/1000\n",
      "50/50 [==============================] - 24s 476ms/step - loss: 0.0806 - acc: 0.9673 - val_loss: 0.1118 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00512: val_acc did not improve from 0.98454\n",
      "Epoch 513/1000\n",
      "50/50 [==============================] - 27s 537ms/step - loss: 0.0696 - acc: 0.9743 - val_loss: 0.1034 - val_acc: 0.9613\n",
      "\n",
      "Epoch 00513: val_acc did not improve from 0.98454\n",
      "Epoch 514/1000\n",
      "50/50 [==============================] - 24s 486ms/step - loss: 0.0783 - acc: 0.9705 - val_loss: 0.0630 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00514: val_acc did not improve from 0.98454\n",
      "Epoch 515/1000\n",
      "50/50 [==============================] - 24s 485ms/step - loss: 0.0578 - acc: 0.9792 - val_loss: 0.0946 - val_acc: 0.9665\n",
      "\n",
      "Epoch 00515: val_acc did not improve from 0.98454\n",
      "Epoch 516/1000\n",
      "50/50 [==============================] - 26s 526ms/step - loss: 0.0626 - acc: 0.9743 - val_loss: 0.1196 - val_acc: 0.9639\n",
      "\n",
      "Epoch 00516: val_acc did not improve from 0.98454\n",
      "Epoch 517/1000\n",
      "50/50 [==============================] - 28s 558ms/step - loss: 0.0571 - acc: 0.9800 - val_loss: 0.2190 - val_acc: 0.9536\n",
      "\n",
      "Epoch 00517: val_acc did not improve from 0.98454\n",
      "Epoch 518/1000\n",
      "50/50 [==============================] - 25s 507ms/step - loss: 0.0837 - acc: 0.9660 - val_loss: 0.0987 - val_acc: 0.9691\n",
      "\n",
      "Epoch 00518: val_acc did not improve from 0.98454\n",
      "Epoch 519/1000\n",
      "50/50 [==============================] - 26s 529ms/step - loss: 0.0664 - acc: 0.9707 - val_loss: 0.1838 - val_acc: 0.9381\n",
      "\n",
      "Epoch 00519: val_acc did not improve from 0.98454\n",
      "Epoch 520/1000\n",
      "50/50 [==============================] - 26s 513ms/step - loss: 0.0736 - acc: 0.9730 - val_loss: 0.1023 - val_acc: 0.9562\n",
      "\n",
      "Epoch 00520: val_acc did not improve from 0.98454\n",
      "Epoch 521/1000\n",
      "50/50 [==============================] - 31s 614ms/step - loss: 0.0683 - acc: 0.9709 - val_loss: 0.0846 - val_acc: 0.9639\n",
      "\n",
      "Epoch 00521: val_acc did not improve from 0.98454\n",
      "Epoch 522/1000\n",
      "50/50 [==============================] - 25s 496ms/step - loss: 0.0759 - acc: 0.9705 - val_loss: 0.1274 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00522: val_acc did not improve from 0.98454\n",
      "Epoch 523/1000\n",
      "50/50 [==============================] - 24s 475ms/step - loss: 0.0696 - acc: 0.9763 - val_loss: 0.1256 - val_acc: 0.9613\n",
      "\n",
      "Epoch 00523: val_acc did not improve from 0.98454\n",
      "Epoch 524/1000\n",
      "50/50 [==============================] - 24s 488ms/step - loss: 0.0561 - acc: 0.9787 - val_loss: 0.0801 - val_acc: 0.9665\n",
      "\n",
      "Epoch 00524: val_acc did not improve from 0.98454\n",
      "Epoch 525/1000\n",
      "50/50 [==============================] - 24s 479ms/step - loss: 0.0577 - acc: 0.9750 - val_loss: 0.1012 - val_acc: 0.9691\n",
      "\n",
      "Epoch 00525: val_acc did not improve from 0.98454\n",
      "Epoch 526/1000\n",
      "50/50 [==============================] - 24s 475ms/step - loss: 0.0928 - acc: 0.9723 - val_loss: 0.0695 - val_acc: 0.9716\n",
      "\n",
      "Epoch 00526: val_acc did not improve from 0.98454\n",
      "Epoch 527/1000\n",
      "50/50 [==============================] - 26s 512ms/step - loss: 0.1173 - acc: 0.9619 - val_loss: 0.0745 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00527: val_acc did not improve from 0.98454\n",
      "Epoch 528/1000\n",
      "50/50 [==============================] - 24s 485ms/step - loss: 0.0718 - acc: 0.9737 - val_loss: 0.1122 - val_acc: 0.9536\n",
      "\n",
      "Epoch 00528: val_acc did not improve from 0.98454\n",
      "Epoch 529/1000\n",
      "50/50 [==============================] - 24s 489ms/step - loss: 0.0536 - acc: 0.9793 - val_loss: 0.0856 - val_acc: 0.9613\n",
      "\n",
      "Epoch 00529: val_acc did not improve from 0.98454\n",
      "Epoch 530/1000\n",
      "50/50 [==============================] - 24s 486ms/step - loss: 0.0546 - acc: 0.9803 - val_loss: 0.0608 - val_acc: 0.9742\n",
      "\n",
      "Epoch 00530: val_acc did not improve from 0.98454\n",
      "Epoch 531/1000\n",
      "50/50 [==============================] - 24s 472ms/step - loss: 0.0733 - acc: 0.9750 - val_loss: 0.0871 - val_acc: 0.9613\n",
      "\n",
      "Epoch 00531: val_acc did not improve from 0.98454\n",
      "Epoch 532/1000\n",
      "50/50 [==============================] - 32s 634ms/step - loss: 0.0820 - acc: 0.9633 - val_loss: 0.1393 - val_acc: 0.9459\n",
      "\n",
      "Epoch 00532: val_acc did not improve from 0.98454\n",
      "Epoch 533/1000\n",
      "50/50 [==============================] - 29s 571ms/step - loss: 0.0745 - acc: 0.9687 - val_loss: 0.1040 - val_acc: 0.9639\n",
      "\n",
      "Epoch 00533: val_acc did not improve from 0.98454\n",
      "Epoch 534/1000\n",
      "50/50 [==============================] - 27s 534ms/step - loss: 0.0629 - acc: 0.9729 - val_loss: 0.1140 - val_acc: 0.9562\n",
      "\n",
      "Epoch 00534: val_acc did not improve from 0.98454\n",
      "Epoch 535/1000\n",
      "50/50 [==============================] - 24s 484ms/step - loss: 0.0959 - acc: 0.9681 - val_loss: 0.1452 - val_acc: 0.9407\n",
      "\n",
      "Epoch 00535: val_acc did not improve from 0.98454\n",
      "Epoch 536/1000\n",
      "50/50 [==============================] - 25s 510ms/step - loss: 0.1237 - acc: 0.9489 - val_loss: 0.0936 - val_acc: 0.9665\n",
      "\n",
      "Epoch 00536: val_acc did not improve from 0.98454\n",
      "Epoch 537/1000\n",
      "50/50 [==============================] - 24s 474ms/step - loss: 0.0752 - acc: 0.9719 - val_loss: 0.1760 - val_acc: 0.9356\n",
      "\n",
      "Epoch 00537: val_acc did not improve from 0.98454\n",
      "Epoch 538/1000\n",
      "50/50 [==============================] - 24s 484ms/step - loss: 0.0695 - acc: 0.9703 - val_loss: 0.0886 - val_acc: 0.9716\n",
      "\n",
      "Epoch 00538: val_acc did not improve from 0.98454\n",
      "Epoch 539/1000\n",
      "50/50 [==============================] - 25s 491ms/step - loss: 0.0569 - acc: 0.9762 - val_loss: 0.1012 - val_acc: 0.9639\n",
      "\n",
      "Epoch 00539: val_acc did not improve from 0.98454\n",
      "Epoch 540/1000\n",
      "50/50 [==============================] - 24s 474ms/step - loss: 0.0635 - acc: 0.9753 - val_loss: 0.1190 - val_acc: 0.9562\n",
      "\n",
      "Epoch 00540: val_acc did not improve from 0.98454\n",
      "Epoch 541/1000\n",
      "50/50 [==============================] - 24s 471ms/step - loss: 0.0777 - acc: 0.9697 - val_loss: 0.1184 - val_acc: 0.9536\n",
      "\n",
      "Epoch 00541: val_acc did not improve from 0.98454\n",
      "Epoch 542/1000\n",
      "50/50 [==============================] - 24s 476ms/step - loss: 0.0805 - acc: 0.9693 - val_loss: 0.1776 - val_acc: 0.9485\n",
      "\n",
      "Epoch 00542: val_acc did not improve from 0.98454\n",
      "Epoch 543/1000\n",
      "50/50 [==============================] - 24s 488ms/step - loss: 0.0772 - acc: 0.9683 - val_loss: 0.0636 - val_acc: 0.9691\n",
      "\n",
      "Epoch 00543: val_acc did not improve from 0.98454\n",
      "Epoch 544/1000\n",
      "50/50 [==============================] - 24s 488ms/step - loss: 0.0937 - acc: 0.9653 - val_loss: 0.1251 - val_acc: 0.9536\n",
      "\n",
      "Epoch 00544: val_acc did not improve from 0.98454\n",
      "Epoch 545/1000\n",
      "50/50 [==============================] - 24s 485ms/step - loss: 0.0889 - acc: 0.9657 - val_loss: 0.0586 - val_acc: 0.9742\n",
      "\n",
      "Epoch 00545: val_acc did not improve from 0.98454\n",
      "Epoch 546/1000\n",
      "50/50 [==============================] - 30s 607ms/step - loss: 0.0661 - acc: 0.9717 - val_loss: 0.1169 - val_acc: 0.9562\n",
      "\n",
      "Epoch 00546: val_acc did not improve from 0.98454\n",
      "Epoch 547/1000\n",
      "50/50 [==============================] - 25s 508ms/step - loss: 0.1010 - acc: 0.9621 - val_loss: 0.1304 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00547: val_acc did not improve from 0.98454\n",
      "Epoch 548/1000\n",
      "50/50 [==============================] - 25s 509ms/step - loss: 0.0658 - acc: 0.9733 - val_loss: 0.0470 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00548: val_acc did not improve from 0.98454\n",
      "Epoch 549/1000\n",
      "50/50 [==============================] - 965s 19s/step - loss: 0.0655 - acc: 0.9753 - val_loss: 0.0578 - val_acc: 0.9820\n",
      "\n",
      "Epoch 00549: val_acc did not improve from 0.98454\n",
      "Epoch 550/1000\n",
      "50/50 [==============================] - 37s 738ms/step - loss: 0.0691 - acc: 0.9707 - val_loss: 0.0754 - val_acc: 0.9665\n",
      "\n",
      "Epoch 00550: val_acc did not improve from 0.98454\n",
      "Epoch 551/1000\n",
      "50/50 [==============================] - 37s 742ms/step - loss: 0.0556 - acc: 0.9773 - val_loss: 0.0772 - val_acc: 0.9613\n",
      "\n",
      "Epoch 00551: val_acc did not improve from 0.98454\n",
      "Epoch 552/1000\n",
      "50/50 [==============================] - 36s 727ms/step - loss: 0.0611 - acc: 0.9767 - val_loss: 0.0707 - val_acc: 0.9613\n",
      "\n",
      "Epoch 00552: val_acc did not improve from 0.98454\n",
      "Epoch 553/1000\n",
      "50/50 [==============================] - 37s 733ms/step - loss: 0.0630 - acc: 0.9739 - val_loss: 0.0528 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00553: val_acc did not improve from 0.98454\n",
      "Epoch 554/1000\n",
      "50/50 [==============================] - 42s 846ms/step - loss: 0.0586 - acc: 0.9767 - val_loss: 0.0672 - val_acc: 0.9639\n",
      "\n",
      "Epoch 00554: val_acc did not improve from 0.98454\n",
      "Epoch 555/1000\n",
      "50/50 [==============================] - 32s 649ms/step - loss: 0.0627 - acc: 0.9773 - val_loss: 0.0611 - val_acc: 0.9716\n",
      "\n",
      "Epoch 00555: val_acc did not improve from 0.98454\n",
      "Epoch 556/1000\n",
      "50/50 [==============================] - 35s 695ms/step - loss: 0.0588 - acc: 0.9750 - val_loss: 0.1231 - val_acc: 0.9510\n",
      "\n",
      "Epoch 00556: val_acc did not improve from 0.98454\n",
      "Epoch 557/1000\n",
      "50/50 [==============================] - 29s 585ms/step - loss: 0.0560 - acc: 0.9757 - val_loss: 0.1215 - val_acc: 0.9613\n",
      "\n",
      "Epoch 00557: val_acc did not improve from 0.98454\n",
      "Epoch 558/1000\n",
      "50/50 [==============================] - 28s 562ms/step - loss: 0.0639 - acc: 0.9733 - val_loss: 0.1314 - val_acc: 0.9562\n",
      "\n",
      "Epoch 00558: val_acc did not improve from 0.98454\n",
      "Epoch 559/1000\n",
      "50/50 [==============================] - 27s 545ms/step - loss: 0.0647 - acc: 0.9733 - val_loss: 0.1324 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00559: val_acc did not improve from 0.98454\n",
      "Epoch 560/1000\n",
      "50/50 [==============================] - 36s 724ms/step - loss: 0.0606 - acc: 0.9767 - val_loss: 0.0519 - val_acc: 0.9742\n",
      "\n",
      "Epoch 00560: val_acc did not improve from 0.98454\n",
      "Epoch 561/1000\n",
      "50/50 [==============================] - 25s 494ms/step - loss: 0.0551 - acc: 0.9773 - val_loss: 0.0608 - val_acc: 0.9716\n",
      "\n",
      "Epoch 00561: val_acc did not improve from 0.98454\n",
      "Epoch 562/1000\n",
      "50/50 [==============================] - 27s 541ms/step - loss: 0.0645 - acc: 0.9750 - val_loss: 0.0774 - val_acc: 0.9588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00562: val_acc did not improve from 0.98454\n",
      "Epoch 563/1000\n",
      "50/50 [==============================] - 30s 594ms/step - loss: 0.0884 - acc: 0.9652 - val_loss: 0.0978 - val_acc: 0.9536\n",
      "\n",
      "Epoch 00563: val_acc did not improve from 0.98454\n",
      "Epoch 564/1000\n",
      "50/50 [==============================] - 30s 602ms/step - loss: 0.0602 - acc: 0.9753 - val_loss: 0.0537 - val_acc: 0.9665\n",
      "\n",
      "Epoch 00564: val_acc did not improve from 0.98454\n",
      "Epoch 565/1000\n",
      "50/50 [==============================] - 27s 532ms/step - loss: 0.0628 - acc: 0.9725 - val_loss: 0.0612 - val_acc: 0.9716\n",
      "\n",
      "Epoch 00565: val_acc did not improve from 0.98454\n",
      "Epoch 566/1000\n",
      "50/50 [==============================] - 28s 565ms/step - loss: 0.0553 - acc: 0.9783 - val_loss: 0.0955 - val_acc: 0.9613\n",
      "\n",
      "Epoch 00566: val_acc did not improve from 0.98454\n",
      "Epoch 567/1000\n",
      "50/50 [==============================] - 26s 529ms/step - loss: 0.0603 - acc: 0.9750 - val_loss: 0.1120 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00567: val_acc did not improve from 0.98454\n",
      "Epoch 568/1000\n",
      "50/50 [==============================] - 28s 559ms/step - loss: 0.0514 - acc: 0.9787 - val_loss: 0.0777 - val_acc: 0.9613\n",
      "\n",
      "Epoch 00568: val_acc did not improve from 0.98454\n",
      "Epoch 569/1000\n",
      "50/50 [==============================] - 34s 683ms/step - loss: 0.0768 - acc: 0.9725 - val_loss: 0.0908 - val_acc: 0.9716\n",
      "\n",
      "Epoch 00569: val_acc did not improve from 0.98454\n",
      "Epoch 570/1000\n",
      "50/50 [==============================] - 28s 564ms/step - loss: 0.0679 - acc: 0.9723 - val_loss: 0.0708 - val_acc: 0.9665\n",
      "\n",
      "Epoch 00570: val_acc did not improve from 0.98454\n",
      "Epoch 571/1000\n",
      "50/50 [==============================] - 27s 536ms/step - loss: 0.0570 - acc: 0.9790 - val_loss: 0.0770 - val_acc: 0.9665\n",
      "\n",
      "Epoch 00571: val_acc did not improve from 0.98454\n",
      "Epoch 572/1000\n",
      "50/50 [==============================] - 25s 493ms/step - loss: 0.0565 - acc: 0.9777 - val_loss: 0.1161 - val_acc: 0.9639\n",
      "\n",
      "Epoch 00572: val_acc did not improve from 0.98454\n",
      "Epoch 573/1000\n",
      "50/50 [==============================] - 25s 505ms/step - loss: 0.0618 - acc: 0.9760 - val_loss: 0.0941 - val_acc: 0.9691\n",
      "\n",
      "Epoch 00573: val_acc did not improve from 0.98454\n",
      "Epoch 574/1000\n",
      "50/50 [==============================] - 26s 516ms/step - loss: 0.0625 - acc: 0.9743 - val_loss: 0.1711 - val_acc: 0.9613\n",
      "\n",
      "Epoch 00574: val_acc did not improve from 0.98454\n",
      "Epoch 575/1000\n",
      "50/50 [==============================] - 25s 502ms/step - loss: 0.0731 - acc: 0.9725 - val_loss: 0.1344 - val_acc: 0.9613\n",
      "\n",
      "Epoch 00575: val_acc did not improve from 0.98454\n",
      "Epoch 576/1000\n",
      "50/50 [==============================] - 25s 497ms/step - loss: 0.0877 - acc: 0.9665 - val_loss: 0.1355 - val_acc: 0.9485\n",
      "\n",
      "Epoch 00576: val_acc did not improve from 0.98454\n",
      "Epoch 577/1000\n",
      "50/50 [==============================] - 25s 495ms/step - loss: 0.0718 - acc: 0.9743 - val_loss: 0.1894 - val_acc: 0.9613\n",
      "\n",
      "Epoch 00577: val_acc did not improve from 0.98454\n",
      "Epoch 578/1000\n",
      "50/50 [==============================] - 24s 481ms/step - loss: 0.0782 - acc: 0.9707 - val_loss: 0.0608 - val_acc: 0.9742\n",
      "\n",
      "Epoch 00578: val_acc did not improve from 0.98454\n",
      "Epoch 579/1000\n",
      "50/50 [==============================] - 24s 471ms/step - loss: 0.0700 - acc: 0.9700 - val_loss: 0.1082 - val_acc: 0.9639\n",
      "\n",
      "Epoch 00579: val_acc did not improve from 0.98454\n",
      "Epoch 580/1000\n",
      "50/50 [==============================] - 24s 477ms/step - loss: 0.0676 - acc: 0.9743 - val_loss: 0.0954 - val_acc: 0.9665\n",
      "\n",
      "Epoch 00580: val_acc did not improve from 0.98454\n",
      "Epoch 581/1000\n",
      "50/50 [==============================] - 24s 485ms/step - loss: 0.0678 - acc: 0.9740 - val_loss: 0.0848 - val_acc: 0.9665\n",
      "\n",
      "Epoch 00581: val_acc did not improve from 0.98454\n",
      "Epoch 582/1000\n",
      "50/50 [==============================] - 24s 472ms/step - loss: 0.0612 - acc: 0.9760 - val_loss: 0.0577 - val_acc: 0.9742\n",
      "\n",
      "Epoch 00582: val_acc did not improve from 0.98454\n",
      "Epoch 583/1000\n",
      "50/50 [==============================] - 27s 533ms/step - loss: 0.0572 - acc: 0.9763 - val_loss: 0.0860 - val_acc: 0.9613\n",
      "\n",
      "Epoch 00583: val_acc did not improve from 0.98454\n",
      "Epoch 584/1000\n",
      "50/50 [==============================] - 24s 484ms/step - loss: 0.0609 - acc: 0.9763 - val_loss: 0.1113 - val_acc: 0.9665\n",
      "\n",
      "Epoch 00584: val_acc did not improve from 0.98454\n",
      "Epoch 585/1000\n",
      "50/50 [==============================] - 25s 493ms/step - loss: 0.0507 - acc: 0.9770 - val_loss: 0.0872 - val_acc: 0.9639\n",
      "\n",
      "Epoch 00585: val_acc did not improve from 0.98454\n",
      "Epoch 586/1000\n",
      "50/50 [==============================] - 25s 500ms/step - loss: 0.0720 - acc: 0.9720 - val_loss: 0.0785 - val_acc: 0.9665\n",
      "\n",
      "Epoch 00586: val_acc did not improve from 0.98454\n",
      "Epoch 587/1000\n",
      "50/50 [==============================] - 35s 690ms/step - loss: 0.0729 - acc: 0.9729 - val_loss: 0.0615 - val_acc: 0.9665\n",
      "\n",
      "Epoch 00587: val_acc did not improve from 0.98454\n",
      "Epoch 588/1000\n",
      "50/50 [==============================] - 47s 940ms/step - loss: 0.0546 - acc: 0.9787 - val_loss: 0.0834 - val_acc: 0.9639\n",
      "\n",
      "Epoch 00588: val_acc did not improve from 0.98454\n",
      "Epoch 589/1000\n",
      "50/50 [==============================] - 30s 600ms/step - loss: 0.0583 - acc: 0.9760 - val_loss: 0.0651 - val_acc: 0.9691\n",
      "\n",
      "Epoch 00589: val_acc did not improve from 0.98454\n",
      "Epoch 590/1000\n",
      "50/50 [==============================] - 28s 563ms/step - loss: 0.0560 - acc: 0.9750 - val_loss: 0.0842 - val_acc: 0.9691\n",
      "\n",
      "Epoch 00590: val_acc did not improve from 0.98454\n",
      "Epoch 591/1000\n",
      "50/50 [==============================] - 25s 495ms/step - loss: 0.0540 - acc: 0.9773 - val_loss: 0.0742 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00591: val_acc did not improve from 0.98454\n",
      "Epoch 592/1000\n",
      "50/50 [==============================] - 30s 601ms/step - loss: 0.0933 - acc: 0.9625 - val_loss: 0.0631 - val_acc: 0.9716\n",
      "\n",
      "Epoch 00592: val_acc did not improve from 0.98454\n",
      "Epoch 593/1000\n",
      "50/50 [==============================] - 28s 562ms/step - loss: 0.0723 - acc: 0.9699 - val_loss: 0.0773 - val_acc: 0.9716\n",
      "\n",
      "Epoch 00593: val_acc did not improve from 0.98454\n",
      "Epoch 594/1000\n",
      "50/50 [==============================] - 35s 709ms/step - loss: 0.0677 - acc: 0.9747 - val_loss: 0.0763 - val_acc: 0.9716\n",
      "\n",
      "Epoch 00594: val_acc did not improve from 0.98454\n",
      "Epoch 595/1000\n",
      "50/50 [==============================] - 34s 673ms/step - loss: 0.0710 - acc: 0.9700 - val_loss: 0.0883 - val_acc: 0.9665\n",
      "\n",
      "Epoch 00595: val_acc did not improve from 0.98454\n",
      "Epoch 596/1000\n",
      "50/50 [==============================] - 30s 606ms/step - loss: 0.0561 - acc: 0.9783 - val_loss: 0.1479 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00596: val_acc did not improve from 0.98454\n",
      "Epoch 597/1000\n",
      "50/50 [==============================] - 25s 495ms/step - loss: 0.0621 - acc: 0.9757 - val_loss: 0.0888 - val_acc: 0.9742\n",
      "\n",
      "Epoch 00597: val_acc did not improve from 0.98454\n",
      "Epoch 598/1000\n",
      "50/50 [==============================] - 27s 533ms/step - loss: 0.0672 - acc: 0.9773 - val_loss: 0.0650 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00598: val_acc did not improve from 0.98454\n",
      "Epoch 599/1000\n",
      "50/50 [==============================] - 27s 538ms/step - loss: 0.0620 - acc: 0.9740 - val_loss: 0.1032 - val_acc: 0.9639\n",
      "\n",
      "Epoch 00599: val_acc did not improve from 0.98454\n",
      "Epoch 600/1000\n",
      "50/50 [==============================] - 31s 613ms/step - loss: 0.0646 - acc: 0.9707 - val_loss: 0.1318 - val_acc: 0.9536\n",
      "\n",
      "Epoch 00600: val_acc did not improve from 0.98454\n",
      "Epoch 601/1000\n",
      "50/50 [==============================] - 30s 604ms/step - loss: 0.0733 - acc: 0.9700 - val_loss: 0.0811 - val_acc: 0.9639\n",
      "\n",
      "Epoch 00601: val_acc did not improve from 0.98454\n",
      "Epoch 602/1000\n",
      "50/50 [==============================] - 29s 572ms/step - loss: 0.0905 - acc: 0.9619 - val_loss: 0.1657 - val_acc: 0.9510\n",
      "\n",
      "Epoch 00602: val_acc did not improve from 0.98454\n",
      "Epoch 603/1000\n",
      "50/50 [==============================] - 28s 563ms/step - loss: 0.0895 - acc: 0.9660 - val_loss: 0.0848 - val_acc: 0.9562\n",
      "\n",
      "Epoch 00603: val_acc did not improve from 0.98454\n",
      "Epoch 604/1000\n",
      "50/50 [==============================] - 32s 648ms/step - loss: 0.0658 - acc: 0.9760 - val_loss: 0.1207 - val_acc: 0.9562\n",
      "\n",
      "Epoch 00604: val_acc did not improve from 0.98454\n",
      "Epoch 605/1000\n",
      "50/50 [==============================] - 29s 584ms/step - loss: 0.0667 - acc: 0.9729 - val_loss: 0.1106 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00605: val_acc did not improve from 0.98454\n",
      "Epoch 606/1000\n",
      "50/50 [==============================] - 29s 581ms/step - loss: 0.0556 - acc: 0.9767 - val_loss: 0.0843 - val_acc: 0.9639\n",
      "\n",
      "Epoch 00606: val_acc did not improve from 0.98454\n",
      "Epoch 607/1000\n",
      "50/50 [==============================] - 32s 634ms/step - loss: 0.0768 - acc: 0.9674 - val_loss: 0.1362 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00607: val_acc did not improve from 0.98454\n",
      "Epoch 608/1000\n",
      "50/50 [==============================] - 31s 611ms/step - loss: 0.0773 - acc: 0.9680 - val_loss: 0.0932 - val_acc: 0.9639\n",
      "\n",
      "Epoch 00608: val_acc did not improve from 0.98454\n",
      "Epoch 609/1000\n",
      "50/50 [==============================] - 34s 672ms/step - loss: 0.0537 - acc: 0.9770 - val_loss: 0.0564 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00609: val_acc did not improve from 0.98454\n",
      "Epoch 610/1000\n",
      "50/50 [==============================] - 35s 707ms/step - loss: 0.0559 - acc: 0.9780 - val_loss: 0.0631 - val_acc: 0.9691\n",
      "\n",
      "Epoch 00610: val_acc did not improve from 0.98454\n",
      "Epoch 611/1000\n",
      "50/50 [==============================] - 48s 955ms/step - loss: 0.0886 - acc: 0.9673 - val_loss: 0.1034 - val_acc: 0.9639\n",
      "\n",
      "Epoch 00611: val_acc did not improve from 0.98454\n",
      "Epoch 612/1000\n",
      "50/50 [==============================] - 36s 718ms/step - loss: 0.0660 - acc: 0.9727 - val_loss: 0.0777 - val_acc: 0.9691\n",
      "\n",
      "Epoch 00612: val_acc did not improve from 0.98454\n",
      "Epoch 613/1000\n",
      "50/50 [==============================] - 41s 829ms/step - loss: 0.1006 - acc: 0.9659 - val_loss: 0.0608 - val_acc: 0.9691\n",
      "\n",
      "Epoch 00613: val_acc did not improve from 0.98454\n",
      "Epoch 614/1000\n",
      "50/50 [==============================] - 38s 759ms/step - loss: 0.0645 - acc: 0.9743 - val_loss: 0.0648 - val_acc: 0.9742\n",
      "\n",
      "Epoch 00614: val_acc did not improve from 0.98454\n",
      "Epoch 615/1000\n",
      "50/50 [==============================] - 32s 649ms/step - loss: 0.0638 - acc: 0.9757 - val_loss: 0.0722 - val_acc: 0.9716\n",
      "\n",
      "Epoch 00615: val_acc did not improve from 0.98454\n",
      "Epoch 616/1000\n",
      "50/50 [==============================] - 33s 666ms/step - loss: 0.0620 - acc: 0.9753 - val_loss: 0.1015 - val_acc: 0.9562\n",
      "\n",
      "Epoch 00616: val_acc did not improve from 0.98454\n",
      "Epoch 617/1000\n",
      "50/50 [==============================] - 30s 608ms/step - loss: 0.0712 - acc: 0.9730 - val_loss: 0.1115 - val_acc: 0.9562\n",
      "\n",
      "Epoch 00617: val_acc did not improve from 0.98454\n",
      "Epoch 618/1000\n",
      "50/50 [==============================] - 33s 670ms/step - loss: 0.0778 - acc: 0.9693 - val_loss: 0.0553 - val_acc: 0.9716\n",
      "\n",
      "Epoch 00618: val_acc did not improve from 0.98454\n",
      "Epoch 619/1000\n",
      "50/50 [==============================] - 42s 849ms/step - loss: 0.0688 - acc: 0.9730 - val_loss: 0.0817 - val_acc: 0.9536\n",
      "\n",
      "Epoch 00619: val_acc did not improve from 0.98454\n",
      "Epoch 620/1000\n",
      "50/50 [==============================] - 33s 651ms/step - loss: 0.0579 - acc: 0.9759 - val_loss: 0.1092 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00620: val_acc did not improve from 0.98454\n",
      "Epoch 621/1000\n",
      "50/50 [==============================] - 33s 663ms/step - loss: 0.0643 - acc: 0.9737 - val_loss: 0.0710 - val_acc: 0.9613\n",
      "\n",
      "Epoch 00621: val_acc did not improve from 0.98454\n",
      "Epoch 622/1000\n",
      "50/50 [==============================] - 31s 623ms/step - loss: 0.0589 - acc: 0.9753 - val_loss: 0.0816 - val_acc: 0.9639\n",
      "\n",
      "Epoch 00622: val_acc did not improve from 0.98454\n",
      "Epoch 623/1000\n",
      "50/50 [==============================] - 48s 966ms/step - loss: 0.0516 - acc: 0.9790 - val_loss: 0.0746 - val_acc: 0.9742\n",
      "\n",
      "Epoch 00623: val_acc did not improve from 0.98454\n",
      "Epoch 624/1000\n",
      "50/50 [==============================] - 29s 588ms/step - loss: 0.0666 - acc: 0.9703 - val_loss: 0.1098 - val_acc: 0.9613\n",
      "\n",
      "Epoch 00624: val_acc did not improve from 0.98454\n",
      "Epoch 625/1000\n",
      "50/50 [==============================] - 28s 555ms/step - loss: 0.0825 - acc: 0.9703 - val_loss: 0.1055 - val_acc: 0.9536\n",
      "\n",
      "Epoch 00625: val_acc did not improve from 0.98454\n",
      "Epoch 626/1000\n",
      "50/50 [==============================] - 32s 639ms/step - loss: 0.1108 - acc: 0.9590 - val_loss: 0.1306 - val_acc: 0.9536\n",
      "\n",
      "Epoch 00626: val_acc did not improve from 0.98454\n",
      "Epoch 627/1000\n",
      "50/50 [==============================] - 24s 485ms/step - loss: 0.0775 - acc: 0.9682 - val_loss: 0.0642 - val_acc: 0.9716\n",
      "\n",
      "Epoch 00627: val_acc did not improve from 0.98454\n",
      "Epoch 628/1000\n",
      "50/50 [==============================] - 24s 475ms/step - loss: 0.0630 - acc: 0.9753 - val_loss: 0.0636 - val_acc: 0.9742\n",
      "\n",
      "Epoch 00628: val_acc did not improve from 0.98454\n",
      "Epoch 629/1000\n",
      "50/50 [==============================] - 32s 635ms/step - loss: 0.0636 - acc: 0.9787 - val_loss: 0.0918 - val_acc: 0.9613\n",
      "\n",
      "Epoch 00629: val_acc did not improve from 0.98454\n",
      "Epoch 630/1000\n",
      "50/50 [==============================] - 36s 715ms/step - loss: 0.0579 - acc: 0.9780 - val_loss: 0.0791 - val_acc: 0.9613\n",
      "\n",
      "Epoch 00630: val_acc did not improve from 0.98454\n",
      "Epoch 631/1000\n",
      "50/50 [==============================] - 46s 911ms/step - loss: 0.0594 - acc: 0.9737 - val_loss: 0.0488 - val_acc: 0.9742\n",
      "\n",
      "Epoch 00631: val_acc did not improve from 0.98454\n",
      "Epoch 632/1000\n",
      "50/50 [==============================] - 36s 716ms/step - loss: 0.0575 - acc: 0.9743 - val_loss: 0.0604 - val_acc: 0.9716\n",
      "\n",
      "Epoch 00632: val_acc did not improve from 0.98454\n",
      "Epoch 633/1000\n",
      "50/50 [==============================] - 29s 574ms/step - loss: 0.0575 - acc: 0.9770 - val_loss: 0.0514 - val_acc: 0.9742\n",
      "\n",
      "Epoch 00633: val_acc did not improve from 0.98454\n",
      "Epoch 634/1000\n",
      "50/50 [==============================] - 33s 658ms/step - loss: 0.0648 - acc: 0.9740 - val_loss: 0.0907 - val_acc: 0.9639\n",
      "\n",
      "Epoch 00634: val_acc did not improve from 0.98454\n",
      "Epoch 635/1000\n",
      "50/50 [==============================] - 30s 598ms/step - loss: 0.0871 - acc: 0.9690 - val_loss: 0.1517 - val_acc: 0.9278\n",
      "\n",
      "Epoch 00635: val_acc did not improve from 0.98454\n",
      "Epoch 636/1000\n",
      "50/50 [==============================] - 32s 637ms/step - loss: 0.0854 - acc: 0.9653 - val_loss: 0.1015 - val_acc: 0.9510\n",
      "\n",
      "Epoch 00636: val_acc did not improve from 0.98454\n",
      "Epoch 637/1000\n",
      "50/50 [==============================] - 46s 918ms/step - loss: 0.0723 - acc: 0.9711 - val_loss: 0.0888 - val_acc: 0.9613\n",
      "\n",
      "Epoch 00637: val_acc did not improve from 0.98454\n",
      "Epoch 638/1000\n",
      "50/50 [==============================] - 33s 658ms/step - loss: 0.0634 - acc: 0.9719 - val_loss: 0.0785 - val_acc: 0.9639\n",
      "\n",
      "Epoch 00638: val_acc did not improve from 0.98454\n",
      "Epoch 639/1000\n",
      "50/50 [==============================] - 2032s 41s/step - loss: 0.0529 - acc: 0.9793 - val_loss: 0.0780 - val_acc: 0.9665\n",
      "\n",
      "Epoch 00639: val_acc did not improve from 0.98454\n",
      "Epoch 640/1000\n",
      "50/50 [==============================] - 38s 757ms/step - loss: 0.0607 - acc: 0.9740 - val_loss: 0.1165 - val_acc: 0.9562\n",
      "\n",
      "Epoch 00640: val_acc did not improve from 0.98454\n",
      "Epoch 641/1000\n",
      "50/50 [==============================] - 45s 906ms/step - loss: 0.0510 - acc: 0.9797 - val_loss: 0.0529 - val_acc: 0.9665\n",
      "\n",
      "Epoch 00641: val_acc did not improve from 0.98454\n",
      "Epoch 642/1000\n",
      "50/50 [==============================] - 42s 831ms/step - loss: 0.0505 - acc: 0.9795 - val_loss: 0.1493 - val_acc: 0.9510\n",
      "\n",
      "Epoch 00642: val_acc did not improve from 0.98454\n",
      "Epoch 643/1000\n",
      "50/50 [==============================] - 33s 653ms/step - loss: 0.0551 - acc: 0.9770 - val_loss: 0.1123 - val_acc: 0.9510\n",
      "\n",
      "Epoch 00643: val_acc did not improve from 0.98454\n",
      "Epoch 644/1000\n",
      "50/50 [==============================] - 35s 704ms/step - loss: 0.0777 - acc: 0.9700 - val_loss: 0.1250 - val_acc: 0.9613\n",
      "\n",
      "Epoch 00644: val_acc did not improve from 0.98454\n",
      "Epoch 645/1000\n",
      "50/50 [==============================] - 30s 606ms/step - loss: 0.0902 - acc: 0.9669 - val_loss: 0.0932 - val_acc: 0.9510\n",
      "\n",
      "Epoch 00645: val_acc did not improve from 0.98454\n",
      "Epoch 646/1000\n",
      "50/50 [==============================] - 35s 701ms/step - loss: 0.0651 - acc: 0.9737 - val_loss: 0.1022 - val_acc: 0.9536\n",
      "\n",
      "Epoch 00646: val_acc did not improve from 0.98454\n",
      "Epoch 647/1000\n",
      "50/50 [==============================] - 32s 642ms/step - loss: 0.0518 - acc: 0.9787 - val_loss: 0.0985 - val_acc: 0.9639\n",
      "\n",
      "Epoch 00647: val_acc did not improve from 0.98454\n",
      "Epoch 648/1000\n",
      "50/50 [==============================] - 40s 795ms/step - loss: 0.0534 - acc: 0.9807 - val_loss: 0.1546 - val_acc: 0.9485\n",
      "\n",
      "Epoch 00648: val_acc did not improve from 0.98454\n",
      "Epoch 649/1000\n",
      "50/50 [==============================] - 32s 644ms/step - loss: 0.0590 - acc: 0.9767 - val_loss: 0.0528 - val_acc: 0.9716\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00649: val_acc did not improve from 0.98454\n",
      "Epoch 650/1000\n",
      "50/50 [==============================] - 35s 699ms/step - loss: 0.0561 - acc: 0.9797 - val_loss: 0.0843 - val_acc: 0.9665\n",
      "\n",
      "Epoch 00650: val_acc did not improve from 0.98454\n",
      "Epoch 651/1000\n",
      "50/50 [==============================] - 35s 702ms/step - loss: 0.0602 - acc: 0.9753 - val_loss: 0.0992 - val_acc: 0.9562\n",
      "\n",
      "Epoch 00651: val_acc did not improve from 0.98454\n",
      "Epoch 652/1000\n",
      "50/50 [==============================] - 48s 953ms/step - loss: 0.0788 - acc: 0.9727 - val_loss: 0.1224 - val_acc: 0.9536\n",
      "\n",
      "Epoch 00652: val_acc did not improve from 0.98454\n",
      "Epoch 653/1000\n",
      "50/50 [==============================] - 36s 724ms/step - loss: 0.0613 - acc: 0.9757 - val_loss: 0.0972 - val_acc: 0.9536\n",
      "\n",
      "Epoch 00653: val_acc did not improve from 0.98454\n",
      "Epoch 654/1000\n",
      "50/50 [==============================] - 35s 696ms/step - loss: 0.0556 - acc: 0.9817 - val_loss: 0.0762 - val_acc: 0.9665\n",
      "\n",
      "Epoch 00654: val_acc did not improve from 0.98454\n",
      "Epoch 655/1000\n",
      "50/50 [==============================] - 33s 650ms/step - loss: 0.0530 - acc: 0.9800 - val_loss: 0.0625 - val_acc: 0.9665\n",
      "\n",
      "Epoch 00655: val_acc did not improve from 0.98454\n",
      "Epoch 656/1000\n",
      "50/50 [==============================] - 48s 964ms/step - loss: 0.0902 - acc: 0.9680 - val_loss: 0.0792 - val_acc: 0.9639\n",
      "\n",
      "Epoch 00656: val_acc did not improve from 0.98454\n",
      "Epoch 657/1000\n",
      "50/50 [==============================] - 32s 633ms/step - loss: 0.0676 - acc: 0.9733 - val_loss: 0.1082 - val_acc: 0.9691\n",
      "\n",
      "Epoch 00657: val_acc did not improve from 0.98454\n",
      "Epoch 658/1000\n",
      "50/50 [==============================] - 31s 627ms/step - loss: 0.0520 - acc: 0.9775 - val_loss: 0.0745 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00658: val_acc did not improve from 0.98454\n",
      "Epoch 659/1000\n",
      "50/50 [==============================] - 33s 665ms/step - loss: 0.0656 - acc: 0.9747 - val_loss: 0.0576 - val_acc: 0.9716\n",
      "\n",
      "Epoch 00659: val_acc did not improve from 0.98454\n",
      "Epoch 660/1000\n",
      "50/50 [==============================] - 39s 780ms/step - loss: 0.0553 - acc: 0.9780 - val_loss: 0.0593 - val_acc: 0.9665\n",
      "\n",
      "Epoch 00660: val_acc did not improve from 0.98454\n",
      "Epoch 661/1000\n",
      "50/50 [==============================] - 29s 585ms/step - loss: 0.0511 - acc: 0.9787 - val_loss: 0.0915 - val_acc: 0.9665\n",
      "\n",
      "Epoch 00661: val_acc did not improve from 0.98454\n",
      "Epoch 662/1000\n",
      "50/50 [==============================] - 32s 642ms/step - loss: 0.0578 - acc: 0.9767 - val_loss: 0.0479 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00662: val_acc did not improve from 0.98454\n",
      "Epoch 663/1000\n",
      "50/50 [==============================] - 34s 690ms/step - loss: 0.0698 - acc: 0.9757 - val_loss: 0.0569 - val_acc: 0.9742\n",
      "\n",
      "Epoch 00663: val_acc did not improve from 0.98454\n",
      "Epoch 664/1000\n",
      "50/50 [==============================] - 31s 627ms/step - loss: 0.0549 - acc: 0.9777 - val_loss: 0.0567 - val_acc: 0.9665\n",
      "\n",
      "Epoch 00664: val_acc did not improve from 0.98454\n",
      "Epoch 665/1000\n",
      "50/50 [==============================] - 30s 595ms/step - loss: 0.0604 - acc: 0.9763 - val_loss: 0.0634 - val_acc: 0.9613\n",
      "\n",
      "Epoch 00665: val_acc did not improve from 0.98454\n",
      "Epoch 666/1000\n",
      "50/50 [==============================] - 28s 559ms/step - loss: 0.0632 - acc: 0.9732 - val_loss: 0.0679 - val_acc: 0.9691\n",
      "\n",
      "Epoch 00666: val_acc did not improve from 0.98454\n",
      "Epoch 667/1000\n",
      "50/50 [==============================] - 34s 674ms/step - loss: 0.0638 - acc: 0.9767 - val_loss: 0.0526 - val_acc: 0.9691\n",
      "\n",
      "Epoch 00667: val_acc did not improve from 0.98454\n",
      "Epoch 668/1000\n",
      "50/50 [==============================] - 41s 821ms/step - loss: 0.0868 - acc: 0.9660 - val_loss: 0.2303 - val_acc: 0.9459\n",
      "\n",
      "Epoch 00668: val_acc did not improve from 0.98454\n",
      "Epoch 669/1000\n",
      "50/50 [==============================] - 35s 705ms/step - loss: 0.0849 - acc: 0.9677 - val_loss: 0.1107 - val_acc: 0.9613\n",
      "\n",
      "Epoch 00669: val_acc did not improve from 0.98454\n",
      "Epoch 670/1000\n",
      "50/50 [==============================] - 29s 586ms/step - loss: 0.0726 - acc: 0.9702 - val_loss: 0.1412 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00670: val_acc did not improve from 0.98454\n",
      "Epoch 671/1000\n",
      "50/50 [==============================] - 26s 526ms/step - loss: 0.0599 - acc: 0.9750 - val_loss: 0.1338 - val_acc: 0.9691\n",
      "\n",
      "Epoch 00671: val_acc did not improve from 0.98454\n",
      "Epoch 672/1000\n",
      "50/50 [==============================] - 33s 662ms/step - loss: 0.0664 - acc: 0.9702 - val_loss: 0.1020 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00672: val_acc did not improve from 0.98454\n",
      "Epoch 673/1000\n",
      "50/50 [==============================] - 36s 712ms/step - loss: 0.0689 - acc: 0.9793 - val_loss: 0.1055 - val_acc: 0.9510\n",
      "\n",
      "Epoch 00673: val_acc did not improve from 0.98454\n",
      "Epoch 674/1000\n",
      "50/50 [==============================] - 34s 683ms/step - loss: 0.0704 - acc: 0.9733 - val_loss: 0.1392 - val_acc: 0.9639\n",
      "\n",
      "Epoch 00674: val_acc did not improve from 0.98454\n",
      "Epoch 675/1000\n",
      "50/50 [==============================] - 40s 796ms/step - loss: 0.0854 - acc: 0.9687 - val_loss: 0.0932 - val_acc: 0.9665\n",
      "\n",
      "Epoch 00675: val_acc did not improve from 0.98454\n",
      "Epoch 676/1000\n",
      "50/50 [==============================] - 30s 607ms/step - loss: 0.0784 - acc: 0.9700 - val_loss: 0.1208 - val_acc: 0.9639\n",
      "\n",
      "Epoch 00676: val_acc did not improve from 0.98454\n",
      "Epoch 677/1000\n",
      "50/50 [==============================] - 28s 568ms/step - loss: 0.1153 - acc: 0.9640 - val_loss: 0.0600 - val_acc: 0.9742\n",
      "\n",
      "Epoch 00677: val_acc did not improve from 0.98454\n",
      "Epoch 678/1000\n",
      "50/50 [==============================] - 26s 516ms/step - loss: 0.0639 - acc: 0.9745 - val_loss: 0.0827 - val_acc: 0.9639\n",
      "\n",
      "Epoch 00678: val_acc did not improve from 0.98454\n",
      "Epoch 679/1000\n",
      "50/50 [==============================] - 25s 491ms/step - loss: 0.0597 - acc: 0.9787 - val_loss: 0.0700 - val_acc: 0.9665\n",
      "\n",
      "Epoch 00679: val_acc did not improve from 0.98454\n",
      "Epoch 680/1000\n",
      "50/50 [==============================] - 24s 482ms/step - loss: 0.0563 - acc: 0.9797 - val_loss: 0.1081 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00680: val_acc did not improve from 0.98454\n",
      "Epoch 681/1000\n",
      "50/50 [==============================] - 24s 481ms/step - loss: 0.0552 - acc: 0.9770 - val_loss: 0.0940 - val_acc: 0.9613\n",
      "\n",
      "Epoch 00681: val_acc did not improve from 0.98454\n",
      "Epoch 682/1000\n",
      "50/50 [==============================] - 25s 503ms/step - loss: 0.0614 - acc: 0.9763 - val_loss: 0.1022 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00682: val_acc did not improve from 0.98454\n",
      "Epoch 683/1000\n",
      "50/50 [==============================] - 24s 482ms/step - loss: 0.0516 - acc: 0.9807 - val_loss: 0.0644 - val_acc: 0.9639\n",
      "\n",
      "Epoch 00683: val_acc did not improve from 0.98454\n",
      "Epoch 684/1000\n",
      "50/50 [==============================] - 24s 475ms/step - loss: 0.0493 - acc: 0.9803 - val_loss: 0.0762 - val_acc: 0.9665\n",
      "\n",
      "Epoch 00684: val_acc did not improve from 0.98454\n",
      "Epoch 685/1000\n",
      "50/50 [==============================] - 24s 480ms/step - loss: 0.0578 - acc: 0.9767 - val_loss: 0.1007 - val_acc: 0.9510\n",
      "\n",
      "Epoch 00685: val_acc did not improve from 0.98454\n",
      "Epoch 686/1000\n",
      "50/50 [==============================] - 24s 483ms/step - loss: 0.0609 - acc: 0.9747 - val_loss: 0.0897 - val_acc: 0.9562\n",
      "\n",
      "Epoch 00686: val_acc did not improve from 0.98454\n",
      "Epoch 687/1000\n",
      "50/50 [==============================] - 24s 486ms/step - loss: 0.0602 - acc: 0.9782 - val_loss: 0.1324 - val_acc: 0.9485\n",
      "\n",
      "Epoch 00687: val_acc did not improve from 0.98454\n",
      "Epoch 688/1000\n",
      "50/50 [==============================] - 24s 484ms/step - loss: 0.0733 - acc: 0.9727 - val_loss: 0.1086 - val_acc: 0.9613\n",
      "\n",
      "Epoch 00688: val_acc did not improve from 0.98454\n",
      "Epoch 689/1000\n",
      "50/50 [==============================] - 24s 486ms/step - loss: 0.0662 - acc: 0.9717 - val_loss: 0.1138 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00689: val_acc did not improve from 0.98454\n",
      "Epoch 690/1000\n",
      "50/50 [==============================] - 25s 502ms/step - loss: 0.0959 - acc: 0.9643 - val_loss: 0.1044 - val_acc: 0.9510\n",
      "\n",
      "Epoch 00690: val_acc did not improve from 0.98454\n",
      "Epoch 691/1000\n",
      "50/50 [==============================] - 38s 752ms/step - loss: 0.0613 - acc: 0.9713 - val_loss: 0.0765 - val_acc: 0.9613\n",
      "\n",
      "Epoch 00691: val_acc did not improve from 0.98454\n",
      "Epoch 692/1000\n",
      "50/50 [==============================] - 38s 766ms/step - loss: 0.0625 - acc: 0.9732 - val_loss: 0.0551 - val_acc: 0.9716\n",
      "\n",
      "Epoch 00692: val_acc did not improve from 0.98454\n",
      "Epoch 693/1000\n",
      "50/50 [==============================] - 36s 723ms/step - loss: 0.0496 - acc: 0.9807 - val_loss: 0.0501 - val_acc: 0.9742\n",
      "\n",
      "Epoch 00693: val_acc did not improve from 0.98454\n",
      "Epoch 694/1000\n",
      "50/50 [==============================] - 31s 621ms/step - loss: 0.0527 - acc: 0.9773 - val_loss: 0.1220 - val_acc: 0.9562\n",
      "\n",
      "Epoch 00694: val_acc did not improve from 0.98454\n",
      "Epoch 695/1000\n",
      "50/50 [==============================] - 26s 523ms/step - loss: 0.0532 - acc: 0.9777 - val_loss: 0.0833 - val_acc: 0.9716\n",
      "\n",
      "Epoch 00695: val_acc did not improve from 0.98454\n",
      "Epoch 696/1000\n",
      "50/50 [==============================] - 25s 508ms/step - loss: 0.0777 - acc: 0.9633 - val_loss: 0.0821 - val_acc: 0.9613\n",
      "\n",
      "Epoch 00696: val_acc did not improve from 0.98454\n",
      "Epoch 697/1000\n",
      "50/50 [==============================] - 27s 549ms/step - loss: 0.0653 - acc: 0.9750 - val_loss: 0.0655 - val_acc: 0.9691\n",
      "\n",
      "Epoch 00697: val_acc did not improve from 0.98454\n",
      "Epoch 698/1000\n",
      "50/50 [==============================] - 25s 493ms/step - loss: 0.0490 - acc: 0.9790 - val_loss: 0.0691 - val_acc: 0.9665\n",
      "\n",
      "Epoch 00698: val_acc did not improve from 0.98454\n",
      "Epoch 699/1000\n",
      "50/50 [==============================] - 30s 599ms/step - loss: 0.0572 - acc: 0.9787 - val_loss: 0.1173 - val_acc: 0.9536\n",
      "\n",
      "Epoch 00699: val_acc did not improve from 0.98454\n",
      "Epoch 700/1000\n",
      "50/50 [==============================] - 26s 524ms/step - loss: 0.0587 - acc: 0.9777 - val_loss: 0.0766 - val_acc: 0.9613\n",
      "\n",
      "Epoch 00700: val_acc did not improve from 0.98454\n",
      "Epoch 701/1000\n",
      "50/50 [==============================] - 24s 482ms/step - loss: 0.0683 - acc: 0.9740 - val_loss: 0.1133 - val_acc: 0.9536\n",
      "\n",
      "Epoch 00701: val_acc did not improve from 0.98454\n",
      "Epoch 702/1000\n",
      "50/50 [==============================] - 25s 492ms/step - loss: 0.0582 - acc: 0.9747 - val_loss: 0.0581 - val_acc: 0.9742\n",
      "\n",
      "Epoch 00702: val_acc did not improve from 0.98454\n",
      "Epoch 703/1000\n",
      "50/50 [==============================] - 25s 508ms/step - loss: 0.0527 - acc: 0.9787 - val_loss: 0.0765 - val_acc: 0.9716\n",
      "\n",
      "Epoch 00703: val_acc did not improve from 0.98454\n",
      "Epoch 704/1000\n",
      "50/50 [==============================] - 27s 532ms/step - loss: 0.0709 - acc: 0.9713 - val_loss: 0.1476 - val_acc: 0.9381\n",
      "\n",
      "Epoch 00704: val_acc did not improve from 0.98454\n",
      "Epoch 705/1000\n",
      "50/50 [==============================] - 30s 598ms/step - loss: 0.0721 - acc: 0.9753 - val_loss: 0.0929 - val_acc: 0.9665\n",
      "\n",
      "Epoch 00705: val_acc did not improve from 0.98454\n",
      "Epoch 706/1000\n",
      "50/50 [==============================] - 29s 584ms/step - loss: 0.0686 - acc: 0.9717 - val_loss: 0.0588 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00706: val_acc did not improve from 0.98454\n",
      "Epoch 707/1000\n",
      "50/50 [==============================] - 30s 600ms/step - loss: 0.0805 - acc: 0.9722 - val_loss: 0.1296 - val_acc: 0.9459\n",
      "\n",
      "Epoch 00707: val_acc did not improve from 0.98454\n",
      "Epoch 708/1000\n",
      "50/50 [==============================] - 25s 492ms/step - loss: 0.0791 - acc: 0.9682 - val_loss: 0.1015 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00708: val_acc did not improve from 0.98454\n",
      "Epoch 709/1000\n",
      "50/50 [==============================] - 26s 522ms/step - loss: 0.0708 - acc: 0.9720 - val_loss: 0.1713 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00709: val_acc did not improve from 0.98454\n",
      "Epoch 710/1000\n",
      "50/50 [==============================] - 26s 523ms/step - loss: 0.0948 - acc: 0.9707 - val_loss: 0.0842 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00710: val_acc did not improve from 0.98454\n",
      "Epoch 711/1000\n",
      "50/50 [==============================] - 27s 535ms/step - loss: 0.0561 - acc: 0.9790 - val_loss: 0.0728 - val_acc: 0.9742\n",
      "\n",
      "Epoch 00711: val_acc did not improve from 0.98454\n",
      "Epoch 712/1000\n",
      "50/50 [==============================] - 25s 508ms/step - loss: 0.0544 - acc: 0.9800 - val_loss: 0.0643 - val_acc: 0.9613\n",
      "\n",
      "Epoch 00712: val_acc did not improve from 0.98454\n",
      "Epoch 713/1000\n",
      "50/50 [==============================] - 29s 580ms/step - loss: 0.0549 - acc: 0.9793 - val_loss: 0.1296 - val_acc: 0.9536\n",
      "\n",
      "Epoch 00713: val_acc did not improve from 0.98454\n",
      "Epoch 714/1000\n",
      "50/50 [==============================] - 42s 840ms/step - loss: 0.0531 - acc: 0.9800 - val_loss: 0.0759 - val_acc: 0.9665\n",
      "\n",
      "Epoch 00714: val_acc did not improve from 0.98454\n",
      "Epoch 715/1000\n",
      "50/50 [==============================] - 31s 621ms/step - loss: 0.0565 - acc: 0.9750 - val_loss: 0.1564 - val_acc: 0.9433\n",
      "\n",
      "Epoch 00715: val_acc did not improve from 0.98454\n",
      "Epoch 716/1000\n",
      "50/50 [==============================] - 28s 554ms/step - loss: 0.0613 - acc: 0.9753 - val_loss: 0.1450 - val_acc: 0.9459\n",
      "\n",
      "Epoch 00716: val_acc did not improve from 0.98454\n",
      "Epoch 717/1000\n",
      "50/50 [==============================] - 26s 526ms/step - loss: 0.0710 - acc: 0.9740 - val_loss: 0.0601 - val_acc: 0.9716\n",
      "\n",
      "Epoch 00717: val_acc did not improve from 0.98454\n",
      "Epoch 718/1000\n",
      "50/50 [==============================] - 24s 489ms/step - loss: 0.0656 - acc: 0.9747 - val_loss: 0.1666 - val_acc: 0.9536\n",
      "\n",
      "Epoch 00718: val_acc did not improve from 0.98454\n",
      "Epoch 719/1000\n",
      "50/50 [==============================] - 25s 501ms/step - loss: 0.0741 - acc: 0.9687 - val_loss: 0.0750 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00719: val_acc did not improve from 0.98454\n",
      "Epoch 720/1000\n",
      "50/50 [==============================] - 24s 488ms/step - loss: 0.0490 - acc: 0.9797 - val_loss: 0.1148 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00720: val_acc did not improve from 0.98454\n",
      "Epoch 721/1000\n",
      "50/50 [==============================] - 25s 496ms/step - loss: 0.0626 - acc: 0.9773 - val_loss: 0.0853 - val_acc: 0.9562\n",
      "\n",
      "Epoch 00721: val_acc did not improve from 0.98454\n",
      "Epoch 722/1000\n",
      "50/50 [==============================] - 26s 524ms/step - loss: 0.0597 - acc: 0.9790 - val_loss: 0.0493 - val_acc: 0.9820\n",
      "\n",
      "Epoch 00722: val_acc did not improve from 0.98454\n",
      "Epoch 723/1000\n",
      "50/50 [==============================] - 24s 484ms/step - loss: 0.0585 - acc: 0.9757 - val_loss: 0.0776 - val_acc: 0.9691\n",
      "\n",
      "Epoch 00723: val_acc did not improve from 0.98454\n",
      "Epoch 724/1000\n",
      "50/50 [==============================] - 24s 481ms/step - loss: 0.0697 - acc: 0.9733 - val_loss: 0.1218 - val_acc: 0.9510\n",
      "\n",
      "Epoch 00724: val_acc did not improve from 0.98454\n",
      "Epoch 725/1000\n",
      "50/50 [==============================] - 24s 487ms/step - loss: 0.0659 - acc: 0.9739 - val_loss: 0.0903 - val_acc: 0.9562\n",
      "\n",
      "Epoch 00725: val_acc did not improve from 0.98454\n",
      "Epoch 726/1000\n",
      "50/50 [==============================] - 24s 482ms/step - loss: 0.0489 - acc: 0.9813 - val_loss: 0.1070 - val_acc: 0.9536\n",
      "\n",
      "Epoch 00726: val_acc did not improve from 0.98454\n",
      "Epoch 727/1000\n",
      "50/50 [==============================] - 30s 607ms/step - loss: 0.0591 - acc: 0.9777 - val_loss: 0.1264 - val_acc: 0.9485\n",
      "\n",
      "Epoch 00727: val_acc did not improve from 0.98454\n",
      "Epoch 728/1000\n",
      "50/50 [==============================] - 40s 791ms/step - loss: 0.0713 - acc: 0.9750 - val_loss: 0.0766 - val_acc: 0.9691\n",
      "\n",
      "Epoch 00728: val_acc did not improve from 0.98454\n",
      "Epoch 729/1000\n",
      "50/50 [==============================] - 25s 509ms/step - loss: 0.0760 - acc: 0.9733 - val_loss: 0.0618 - val_acc: 0.9716\n",
      "\n",
      "Epoch 00729: val_acc did not improve from 0.98454\n",
      "Epoch 730/1000\n",
      "50/50 [==============================] - 35s 709ms/step - loss: 0.0852 - acc: 0.9657 - val_loss: 0.0659 - val_acc: 0.9639\n",
      "\n",
      "Epoch 00730: val_acc did not improve from 0.98454\n",
      "Epoch 731/1000\n",
      "50/50 [==============================] - 25s 494ms/step - loss: 0.0483 - acc: 0.9767 - val_loss: 0.1055 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00731: val_acc did not improve from 0.98454\n",
      "Epoch 732/1000\n",
      "50/50 [==============================] - 27s 540ms/step - loss: 0.0555 - acc: 0.9787 - val_loss: 0.0607 - val_acc: 0.9691\n",
      "\n",
      "Epoch 00732: val_acc did not improve from 0.98454\n",
      "Epoch 733/1000\n",
      "50/50 [==============================] - 35s 704ms/step - loss: 0.0640 - acc: 0.9757 - val_loss: 0.1127 - val_acc: 0.9562\n",
      "\n",
      "Epoch 00733: val_acc did not improve from 0.98454\n",
      "Epoch 734/1000\n",
      "50/50 [==============================] - 30s 604ms/step - loss: 0.0613 - acc: 0.9753 - val_loss: 0.0836 - val_acc: 0.9613\n",
      "\n",
      "Epoch 00734: val_acc did not improve from 0.98454\n",
      "Epoch 735/1000\n",
      "50/50 [==============================] - 27s 536ms/step - loss: 0.0540 - acc: 0.9750 - val_loss: 0.0694 - val_acc: 0.9665\n",
      "\n",
      "Epoch 00735: val_acc did not improve from 0.98454\n",
      "Epoch 736/1000\n",
      "50/50 [==============================] - 29s 579ms/step - loss: 0.0691 - acc: 0.9729 - val_loss: 0.0430 - val_acc: 0.9716\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00736: val_acc did not improve from 0.98454\n",
      "Epoch 737/1000\n",
      "50/50 [==============================] - 30s 600ms/step - loss: 0.0468 - acc: 0.9833 - val_loss: 0.0662 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00737: val_acc did not improve from 0.98454\n",
      "Epoch 738/1000\n",
      "50/50 [==============================] - 36s 715ms/step - loss: 0.0514 - acc: 0.9797 - val_loss: 0.0630 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00738: val_acc did not improve from 0.98454\n",
      "Epoch 739/1000\n",
      "50/50 [==============================] - 36s 713ms/step - loss: 0.0564 - acc: 0.9740 - val_loss: 0.0559 - val_acc: 0.9742\n",
      "\n",
      "Epoch 00739: val_acc did not improve from 0.98454\n",
      "Epoch 740/1000\n",
      "50/50 [==============================] - 29s 586ms/step - loss: 0.0575 - acc: 0.9787 - val_loss: 0.0784 - val_acc: 0.9639\n",
      "\n",
      "Epoch 00740: val_acc did not improve from 0.98454\n",
      "Epoch 741/1000\n",
      "50/50 [==============================] - 30s 607ms/step - loss: 0.0513 - acc: 0.9800 - val_loss: 0.0833 - val_acc: 0.9613\n",
      "\n",
      "Epoch 00741: val_acc did not improve from 0.98454\n",
      "Epoch 742/1000\n",
      "50/50 [==============================] - 58s 1s/step - loss: 0.0610 - acc: 0.9727 - val_loss: 0.0645 - val_acc: 0.9691\n",
      "\n",
      "Epoch 00742: val_acc did not improve from 0.98454\n",
      "Epoch 743/1000\n",
      "50/50 [==============================] - 46s 924ms/step - loss: 0.1030 - acc: 0.9727 - val_loss: 0.7935 - val_acc: 0.7706\n",
      "\n",
      "Epoch 00743: val_acc did not improve from 0.98454\n",
      "Epoch 744/1000\n",
      "50/50 [==============================] - 35s 693ms/step - loss: 0.1639 - acc: 0.9517 - val_loss: 0.0928 - val_acc: 0.9639\n",
      "\n",
      "Epoch 00744: val_acc did not improve from 0.98454\n",
      "Epoch 745/1000\n",
      "50/50 [==============================] - 28s 570ms/step - loss: 0.0676 - acc: 0.9727 - val_loss: 0.0620 - val_acc: 0.9716\n",
      "\n",
      "Epoch 00745: val_acc did not improve from 0.98454\n",
      "Epoch 746/1000\n",
      "50/50 [==============================] - 37s 730ms/step - loss: 0.0537 - acc: 0.9783 - val_loss: 0.0934 - val_acc: 0.9639\n",
      "\n",
      "Epoch 00746: val_acc did not improve from 0.98454\n",
      "Epoch 747/1000\n",
      "50/50 [==============================] - 31s 611ms/step - loss: 0.0508 - acc: 0.9800 - val_loss: 0.0628 - val_acc: 0.9742\n",
      "\n",
      "Epoch 00747: val_acc did not improve from 0.98454\n",
      "Epoch 748/1000\n",
      "50/50 [==============================] - 43s 864ms/step - loss: 0.0591 - acc: 0.9790 - val_loss: 0.0797 - val_acc: 0.9691\n",
      "\n",
      "Epoch 00748: val_acc did not improve from 0.98454\n",
      "Epoch 749/1000\n",
      "50/50 [==============================] - 40s 794ms/step - loss: 0.0672 - acc: 0.9753 - val_loss: 0.0963 - val_acc: 0.9639\n",
      "\n",
      "Epoch 00749: val_acc did not improve from 0.98454\n",
      "Epoch 750/1000\n",
      "50/50 [==============================] - 38s 754ms/step - loss: 0.0612 - acc: 0.9795 - val_loss: 0.0578 - val_acc: 0.9742\n",
      "\n",
      "Epoch 00750: val_acc did not improve from 0.98454\n",
      "Epoch 751/1000\n",
      "50/50 [==============================] - 35s 707ms/step - loss: 0.0937 - acc: 0.9715 - val_loss: 0.1828 - val_acc: 0.9433\n",
      "\n",
      "Epoch 00751: val_acc did not improve from 0.98454\n",
      "Epoch 752/1000\n",
      "50/50 [==============================] - 33s 665ms/step - loss: 0.0648 - acc: 0.9749 - val_loss: 0.0919 - val_acc: 0.9665\n",
      "\n",
      "Epoch 00752: val_acc did not improve from 0.98454\n",
      "Epoch 753/1000\n",
      "50/50 [==============================] - 32s 646ms/step - loss: 0.0627 - acc: 0.9790 - val_loss: 0.0648 - val_acc: 0.9691\n",
      "\n",
      "Epoch 00753: val_acc did not improve from 0.98454\n",
      "Epoch 754/1000\n",
      "50/50 [==============================] - 33s 663ms/step - loss: 0.0572 - acc: 0.9763 - val_loss: 0.1204 - val_acc: 0.9562\n",
      "\n",
      "Epoch 00754: val_acc did not improve from 0.98454\n",
      "Epoch 755/1000\n",
      "50/50 [==============================] - 57s 1s/step - loss: 0.0625 - acc: 0.9775 - val_loss: 0.0902 - val_acc: 0.9665\n",
      "\n",
      "Epoch 00755: val_acc did not improve from 0.98454\n",
      "Epoch 756/1000\n",
      "50/50 [==============================] - 41s 830ms/step - loss: 0.0547 - acc: 0.9763 - val_loss: 0.0703 - val_acc: 0.9716\n",
      "\n",
      "Epoch 00756: val_acc did not improve from 0.98454\n",
      "Epoch 757/1000\n",
      "50/50 [==============================] - 43s 870ms/step - loss: 0.0580 - acc: 0.9785 - val_loss: 0.0623 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00757: val_acc did not improve from 0.98454\n",
      "Epoch 758/1000\n",
      "50/50 [==============================] - 33s 668ms/step - loss: 0.0545 - acc: 0.9795 - val_loss: 0.0678 - val_acc: 0.9613\n",
      "\n",
      "Epoch 00758: val_acc did not improve from 0.98454\n",
      "Epoch 759/1000\n",
      "50/50 [==============================] - 34s 677ms/step - loss: 0.0567 - acc: 0.9780 - val_loss: 0.0980 - val_acc: 0.9742\n",
      "\n",
      "Epoch 00759: val_acc did not improve from 0.98454\n",
      "Epoch 760/1000\n",
      "50/50 [==============================] - 41s 830ms/step - loss: 0.0444 - acc: 0.9840 - val_loss: 0.0832 - val_acc: 0.9716\n",
      "\n",
      "Epoch 00760: val_acc did not improve from 0.98454\n",
      "Epoch 761/1000\n",
      "50/50 [==============================] - 41s 811ms/step - loss: 0.0526 - acc: 0.9760 - val_loss: 0.0856 - val_acc: 0.9639\n",
      "\n",
      "Epoch 00761: val_acc did not improve from 0.98454\n",
      "Epoch 762/1000\n",
      "50/50 [==============================] - 56s 1s/step - loss: 0.0525 - acc: 0.9813 - val_loss: 0.0537 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00762: val_acc did not improve from 0.98454\n",
      "Epoch 763/1000\n",
      "50/50 [==============================] - 56s 1s/step - loss: 0.0585 - acc: 0.9773 - val_loss: 0.0669 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00763: val_acc did not improve from 0.98454\n",
      "Epoch 764/1000\n",
      "50/50 [==============================] - 33s 669ms/step - loss: 0.0795 - acc: 0.9710 - val_loss: 0.0963 - val_acc: 0.9742\n",
      "\n",
      "Epoch 00764: val_acc did not improve from 0.98454\n",
      "Epoch 765/1000\n",
      "50/50 [==============================] - 34s 682ms/step - loss: 0.1383 - acc: 0.9492 - val_loss: 0.1135 - val_acc: 0.9510\n",
      "\n",
      "Epoch 00765: val_acc did not improve from 0.98454\n",
      "Epoch 766/1000\n",
      "50/50 [==============================] - 38s 769ms/step - loss: 0.0639 - acc: 0.9727 - val_loss: 0.1001 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00766: val_acc did not improve from 0.98454\n",
      "Epoch 767/1000\n",
      "50/50 [==============================] - 53s 1s/step - loss: 0.0534 - acc: 0.9787 - val_loss: 0.0773 - val_acc: 0.9716\n",
      "\n",
      "Epoch 00767: val_acc did not improve from 0.98454\n",
      "Epoch 768/1000\n",
      "50/50 [==============================] - 37s 739ms/step - loss: 0.0526 - acc: 0.9790 - val_loss: 0.0541 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00768: val_acc did not improve from 0.98454\n",
      "Epoch 769/1000\n",
      "50/50 [==============================] - 31s 623ms/step - loss: 0.0666 - acc: 0.9743 - val_loss: 0.1767 - val_acc: 0.9510\n",
      "\n",
      "Epoch 00769: val_acc did not improve from 0.98454\n",
      "Epoch 770/1000\n",
      "50/50 [==============================] - 31s 629ms/step - loss: 0.0614 - acc: 0.9740 - val_loss: 0.0883 - val_acc: 0.9665\n",
      "\n",
      "Epoch 00770: val_acc did not improve from 0.98454\n",
      "Epoch 771/1000\n",
      "50/50 [==============================] - 39s 786ms/step - loss: 0.0385 - acc: 0.9853 - val_loss: 0.0811 - val_acc: 0.9716\n",
      "\n",
      "Epoch 00771: val_acc did not improve from 0.98454\n",
      "Epoch 772/1000\n",
      "50/50 [==============================] - 46s 927ms/step - loss: 0.0390 - acc: 0.9847 - val_loss: 0.0869 - val_acc: 0.9639\n",
      "\n",
      "Epoch 00772: val_acc did not improve from 0.98454\n",
      "Epoch 773/1000\n",
      "50/50 [==============================] - 48s 956ms/step - loss: 0.0500 - acc: 0.9797 - val_loss: 0.0588 - val_acc: 0.9742\n",
      "\n",
      "Epoch 00773: val_acc did not improve from 0.98454\n",
      "Epoch 774/1000\n",
      "50/50 [==============================] - 29s 580ms/step - loss: 0.0397 - acc: 0.9823 - val_loss: 0.0966 - val_acc: 0.9665\n",
      "\n",
      "Epoch 00774: val_acc did not improve from 0.98454\n",
      "Epoch 775/1000\n",
      "50/50 [==============================] - 26s 524ms/step - loss: 0.0550 - acc: 0.9780 - val_loss: 0.1117 - val_acc: 0.9510\n",
      "\n",
      "Epoch 00775: val_acc did not improve from 0.98454\n",
      "Epoch 776/1000\n",
      "50/50 [==============================] - 26s 514ms/step - loss: 0.0497 - acc: 0.9833 - val_loss: 0.0675 - val_acc: 0.9691\n",
      "\n",
      "Epoch 00776: val_acc did not improve from 0.98454\n",
      "Epoch 777/1000\n",
      "50/50 [==============================] - 26s 518ms/step - loss: 0.0468 - acc: 0.9807 - val_loss: 0.0570 - val_acc: 0.9716\n",
      "\n",
      "Epoch 00777: val_acc did not improve from 0.98454\n",
      "Epoch 778/1000\n",
      "50/50 [==============================] - 25s 507ms/step - loss: 0.0655 - acc: 0.9767 - val_loss: 0.0978 - val_acc: 0.9613\n",
      "\n",
      "Epoch 00778: val_acc did not improve from 0.98454\n",
      "Epoch 779/1000\n",
      "50/50 [==============================] - 25s 500ms/step - loss: 0.0465 - acc: 0.9815 - val_loss: 0.1172 - val_acc: 0.9510\n",
      "\n",
      "Epoch 00779: val_acc did not improve from 0.98454\n",
      "Epoch 780/1000\n",
      "50/50 [==============================] - 25s 502ms/step - loss: 0.0843 - acc: 0.9687 - val_loss: 0.0724 - val_acc: 0.9639\n",
      "\n",
      "Epoch 00780: val_acc did not improve from 0.98454\n",
      "Epoch 781/1000\n",
      "50/50 [==============================] - 27s 537ms/step - loss: 0.0669 - acc: 0.9753 - val_loss: 0.1078 - val_acc: 0.9639\n",
      "\n",
      "Epoch 00781: val_acc did not improve from 0.98454\n",
      "Epoch 782/1000\n",
      "50/50 [==============================] - 27s 540ms/step - loss: 0.0508 - acc: 0.9813 - val_loss: 0.0987 - val_acc: 0.9536\n",
      "\n",
      "Epoch 00782: val_acc did not improve from 0.98454\n",
      "Epoch 783/1000\n",
      "50/50 [==============================] - 26s 524ms/step - loss: 0.0529 - acc: 0.9807 - val_loss: 0.1848 - val_acc: 0.9407\n",
      "\n",
      "Epoch 00783: val_acc did not improve from 0.98454\n",
      "Epoch 784/1000\n",
      "50/50 [==============================] - 28s 553ms/step - loss: 0.0593 - acc: 0.9760 - val_loss: 0.0639 - val_acc: 0.9665\n",
      "\n",
      "Epoch 00784: val_acc did not improve from 0.98454\n",
      "Epoch 785/1000\n",
      "50/50 [==============================] - 26s 514ms/step - loss: 0.0573 - acc: 0.9767 - val_loss: 0.0558 - val_acc: 0.9665\n",
      "\n",
      "Epoch 00785: val_acc did not improve from 0.98454\n",
      "Epoch 786/1000\n",
      "50/50 [==============================] - 25s 496ms/step - loss: 0.0492 - acc: 0.9820 - val_loss: 0.0910 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00786: val_acc did not improve from 0.98454\n",
      "Epoch 787/1000\n",
      "50/50 [==============================] - 25s 496ms/step - loss: 0.0573 - acc: 0.9773 - val_loss: 0.1315 - val_acc: 0.9562\n",
      "\n",
      "Epoch 00787: val_acc did not improve from 0.98454\n",
      "Epoch 788/1000\n",
      "50/50 [==============================] - 25s 504ms/step - loss: 0.0505 - acc: 0.9773 - val_loss: 0.0767 - val_acc: 0.9613\n",
      "\n",
      "Epoch 00788: val_acc did not improve from 0.98454\n",
      "Epoch 789/1000\n",
      "50/50 [==============================] - 25s 503ms/step - loss: 0.0706 - acc: 0.9702 - val_loss: 0.0700 - val_acc: 0.9691\n",
      "\n",
      "Epoch 00789: val_acc did not improve from 0.98454\n",
      "Epoch 790/1000\n",
      "50/50 [==============================] - 26s 519ms/step - loss: 0.0493 - acc: 0.9782 - val_loss: 0.0765 - val_acc: 0.9639\n",
      "\n",
      "Epoch 00790: val_acc did not improve from 0.98454\n",
      "Epoch 791/1000\n",
      "50/50 [==============================] - 25s 507ms/step - loss: 0.0595 - acc: 0.9777 - val_loss: 0.0777 - val_acc: 0.9691\n",
      "\n",
      "Epoch 00791: val_acc did not improve from 0.98454\n",
      "Epoch 792/1000\n",
      "50/50 [==============================] - 25s 507ms/step - loss: 0.0610 - acc: 0.9787 - val_loss: 0.0736 - val_acc: 0.9639\n",
      "\n",
      "Epoch 00792: val_acc did not improve from 0.98454\n",
      "Epoch 793/1000\n",
      "50/50 [==============================] - 26s 515ms/step - loss: 0.0533 - acc: 0.9792 - val_loss: 0.0754 - val_acc: 0.9665\n",
      "\n",
      "Epoch 00793: val_acc did not improve from 0.98454\n",
      "Epoch 794/1000\n",
      "50/50 [==============================] - 47s 931ms/step - loss: 0.0704 - acc: 0.9743 - val_loss: 0.0784 - val_acc: 0.9613\n",
      "\n",
      "Epoch 00794: val_acc did not improve from 0.98454\n",
      "Epoch 795/1000\n",
      "50/50 [==============================] - 31s 625ms/step - loss: 0.0753 - acc: 0.9730 - val_loss: 0.1898 - val_acc: 0.9433\n",
      "\n",
      "Epoch 00795: val_acc did not improve from 0.98454\n",
      "Epoch 796/1000\n",
      "50/50 [==============================] - 30s 594ms/step - loss: 0.0589 - acc: 0.9783 - val_loss: 0.1042 - val_acc: 0.9716\n",
      "\n",
      "Epoch 00796: val_acc did not improve from 0.98454\n",
      "Epoch 797/1000\n",
      "50/50 [==============================] - 30s 599ms/step - loss: 0.0627 - acc: 0.9757 - val_loss: 0.0529 - val_acc: 0.9716\n",
      "\n",
      "Epoch 00797: val_acc did not improve from 0.98454\n",
      "Epoch 798/1000\n",
      "50/50 [==============================] - 35s 709ms/step - loss: 0.0597 - acc: 0.9753 - val_loss: 0.0854 - val_acc: 0.9716\n",
      "\n",
      "Epoch 00798: val_acc did not improve from 0.98454\n",
      "Epoch 799/1000\n",
      "50/50 [==============================] - 51s 1s/step - loss: 0.0565 - acc: 0.9780 - val_loss: 0.0861 - val_acc: 0.9665\n",
      "\n",
      "Epoch 00799: val_acc did not improve from 0.98454\n",
      "Epoch 800/1000\n",
      "50/50 [==============================] - 33s 662ms/step - loss: 0.0627 - acc: 0.9747 - val_loss: 0.0508 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00800: val_acc did not improve from 0.98454\n",
      "Epoch 801/1000\n",
      "50/50 [==============================] - 31s 613ms/step - loss: 0.0576 - acc: 0.9797 - val_loss: 0.0573 - val_acc: 0.9742\n",
      "\n",
      "Epoch 00801: val_acc did not improve from 0.98454\n",
      "Epoch 802/1000\n",
      "50/50 [==============================] - 30s 608ms/step - loss: 0.0619 - acc: 0.9767 - val_loss: 0.0785 - val_acc: 0.9691\n",
      "\n",
      "Epoch 00802: val_acc did not improve from 0.98454\n",
      "Epoch 803/1000\n",
      "50/50 [==============================] - 43s 852ms/step - loss: 0.0578 - acc: 0.9770 - val_loss: 0.1235 - val_acc: 0.9562\n",
      "\n",
      "Epoch 00803: val_acc did not improve from 0.98454\n",
      "Epoch 804/1000\n",
      "50/50 [==============================] - 39s 773ms/step - loss: 0.0567 - acc: 0.9780 - val_loss: 0.0781 - val_acc: 0.9691\n",
      "\n",
      "Epoch 00804: val_acc did not improve from 0.98454\n",
      "Epoch 805/1000\n",
      "50/50 [==============================] - 33s 653ms/step - loss: 0.0506 - acc: 0.9767 - val_loss: 0.0860 - val_acc: 0.9639\n",
      "\n",
      "Epoch 00805: val_acc did not improve from 0.98454\n",
      "Epoch 806/1000\n",
      "50/50 [==============================] - 35s 704ms/step - loss: 0.0574 - acc: 0.9720 - val_loss: 0.1178 - val_acc: 0.9485\n",
      "\n",
      "Epoch 00806: val_acc did not improve from 0.98454\n",
      "Epoch 807/1000\n",
      "50/50 [==============================] - 29s 587ms/step - loss: 0.0707 - acc: 0.9750 - val_loss: 0.0818 - val_acc: 0.9691\n",
      "\n",
      "Epoch 00807: val_acc did not improve from 0.98454\n",
      "Epoch 808/1000\n",
      "50/50 [==============================] - 28s 558ms/step - loss: 0.0633 - acc: 0.9735 - val_loss: 0.0813 - val_acc: 0.9665\n",
      "\n",
      "Epoch 00808: val_acc did not improve from 0.98454\n",
      "Epoch 809/1000\n",
      "50/50 [==============================] - 36s 714ms/step - loss: 0.0511 - acc: 0.9820 - val_loss: 0.0957 - val_acc: 0.9716\n",
      "\n",
      "Epoch 00809: val_acc did not improve from 0.98454\n",
      "Epoch 810/1000\n",
      "50/50 [==============================] - 33s 654ms/step - loss: 0.0588 - acc: 0.9753 - val_loss: 0.0707 - val_acc: 0.9639\n",
      "\n",
      "Epoch 00810: val_acc did not improve from 0.98454\n",
      "Epoch 811/1000\n",
      "50/50 [==============================] - 45s 892ms/step - loss: 0.0553 - acc: 0.9827 - val_loss: 0.0783 - val_acc: 0.9716\n",
      "\n",
      "Epoch 00811: val_acc did not improve from 0.98454\n",
      "Epoch 812/1000\n",
      "50/50 [==============================] - 40s 796ms/step - loss: 0.0480 - acc: 0.9800 - val_loss: 0.0887 - val_acc: 0.9691\n",
      "\n",
      "Epoch 00812: val_acc did not improve from 0.98454\n",
      "Epoch 813/1000\n",
      "50/50 [==============================] - 31s 613ms/step - loss: 0.0432 - acc: 0.9837 - val_loss: 0.0688 - val_acc: 0.9691\n",
      "\n",
      "Epoch 00813: val_acc did not improve from 0.98454\n",
      "Epoch 814/1000\n",
      "50/50 [==============================] - 33s 662ms/step - loss: 0.0453 - acc: 0.9843 - val_loss: 0.1059 - val_acc: 0.9665\n",
      "\n",
      "Epoch 00814: val_acc did not improve from 0.98454\n",
      "Epoch 815/1000\n",
      "50/50 [==============================] - 40s 792ms/step - loss: 0.0703 - acc: 0.9725 - val_loss: 0.1022 - val_acc: 0.9510\n",
      "\n",
      "Epoch 00815: val_acc did not improve from 0.98454\n",
      "Epoch 816/1000\n",
      "50/50 [==============================] - 38s 755ms/step - loss: 0.0636 - acc: 0.9750 - val_loss: 0.1409 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00816: val_acc did not improve from 0.98454\n",
      "Epoch 817/1000\n",
      "50/50 [==============================] - 39s 774ms/step - loss: 0.0531 - acc: 0.9807 - val_loss: 0.0812 - val_acc: 0.9613\n",
      "\n",
      "Epoch 00817: val_acc did not improve from 0.98454\n",
      "Epoch 818/1000\n",
      "50/50 [==============================] - 44s 888ms/step - loss: 0.0545 - acc: 0.9770 - val_loss: 0.0855 - val_acc: 0.9613\n",
      "\n",
      "Epoch 00818: val_acc did not improve from 0.98454\n",
      "Epoch 819/1000\n",
      "50/50 [==============================] - 56s 1s/step - loss: 0.0514 - acc: 0.9787 - val_loss: 0.0688 - val_acc: 0.9742\n",
      "\n",
      "Epoch 00819: val_acc did not improve from 0.98454\n",
      "Epoch 820/1000\n",
      "50/50 [==============================] - 34s 674ms/step - loss: 0.0701 - acc: 0.9763 - val_loss: 0.0647 - val_acc: 0.9742\n",
      "\n",
      "Epoch 00820: val_acc did not improve from 0.98454\n",
      "Epoch 821/1000\n",
      "50/50 [==============================] - 34s 679ms/step - loss: 0.0838 - acc: 0.9683 - val_loss: 0.1159 - val_acc: 0.9562\n",
      "\n",
      "Epoch 00821: val_acc did not improve from 0.98454\n",
      "Epoch 822/1000\n",
      "50/50 [==============================] - 33s 656ms/step - loss: 0.0665 - acc: 0.9743 - val_loss: 0.0779 - val_acc: 0.9665\n",
      "\n",
      "Epoch 00822: val_acc did not improve from 0.98454\n",
      "Epoch 823/1000\n",
      "50/50 [==============================] - 36s 716ms/step - loss: 0.0770 - acc: 0.9697 - val_loss: 0.0993 - val_acc: 0.9510\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00823: val_acc did not improve from 0.98454\n",
      "Epoch 824/1000\n",
      "50/50 [==============================] - 34s 678ms/step - loss: 0.0558 - acc: 0.9762 - val_loss: 0.0524 - val_acc: 0.9742\n",
      "\n",
      "Epoch 00824: val_acc did not improve from 0.98454\n",
      "Epoch 825/1000\n",
      "50/50 [==============================] - 34s 681ms/step - loss: 0.0565 - acc: 0.9777 - val_loss: 0.0676 - val_acc: 0.9742\n",
      "\n",
      "Epoch 00825: val_acc did not improve from 0.98454\n",
      "Epoch 826/1000\n",
      "50/50 [==============================] - 36s 723ms/step - loss: 0.0548 - acc: 0.9755 - val_loss: 0.0821 - val_acc: 0.9665\n",
      "\n",
      "Epoch 00826: val_acc did not improve from 0.98454\n",
      "Epoch 827/1000\n",
      "50/50 [==============================] - 51s 1s/step - loss: 0.0608 - acc: 0.9813 - val_loss: 0.1142 - val_acc: 0.9459\n",
      "\n",
      "Epoch 00827: val_acc did not improve from 0.98454\n",
      "Epoch 828/1000\n",
      "50/50 [==============================] - 36s 715ms/step - loss: 0.0512 - acc: 0.9822 - val_loss: 0.0546 - val_acc: 0.9716\n",
      "\n",
      "Epoch 00828: val_acc did not improve from 0.98454\n",
      "Epoch 829/1000\n",
      "50/50 [==============================] - 39s 789ms/step - loss: 0.0574 - acc: 0.9790 - val_loss: 0.0612 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00829: val_acc did not improve from 0.98454\n",
      "Epoch 830/1000\n",
      "50/50 [==============================] - 43s 851ms/step - loss: 0.0590 - acc: 0.9770 - val_loss: 0.0787 - val_acc: 0.9716\n",
      "\n",
      "Epoch 00830: val_acc did not improve from 0.98454\n",
      "Epoch 831/1000\n",
      "50/50 [==============================] - 34s 687ms/step - loss: 0.0710 - acc: 0.9720 - val_loss: 0.0638 - val_acc: 0.9613\n",
      "\n",
      "Epoch 00831: val_acc did not improve from 0.98454\n",
      "Epoch 832/1000\n",
      "50/50 [==============================] - 32s 636ms/step - loss: 0.0543 - acc: 0.9797 - val_loss: 0.0684 - val_acc: 0.9716\n",
      "\n",
      "Epoch 00832: val_acc did not improve from 0.98454\n",
      "Epoch 833/1000\n",
      "50/50 [==============================] - 37s 749ms/step - loss: 0.0514 - acc: 0.9783 - val_loss: 0.0594 - val_acc: 0.9691\n",
      "\n",
      "Epoch 00833: val_acc did not improve from 0.98454\n",
      "Epoch 834/1000\n",
      "50/50 [==============================] - 28s 550ms/step - loss: 0.0517 - acc: 0.9787 - val_loss: 0.0582 - val_acc: 0.9691\n",
      "\n",
      "Epoch 00834: val_acc did not improve from 0.98454\n",
      "Epoch 835/1000\n",
      "50/50 [==============================] - 24s 482ms/step - loss: 0.0486 - acc: 0.9803 - val_loss: 0.0574 - val_acc: 0.9742\n",
      "\n",
      "Epoch 00835: val_acc did not improve from 0.98454\n",
      "Epoch 836/1000\n",
      "50/50 [==============================] - 32s 637ms/step - loss: 0.0419 - acc: 0.9857 - val_loss: 0.0863 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00836: val_acc did not improve from 0.98454\n",
      "Epoch 837/1000\n",
      "50/50 [==============================] - 35s 695ms/step - loss: 0.0447 - acc: 0.9817 - val_loss: 0.1187 - val_acc: 0.9536\n",
      "\n",
      "Epoch 00837: val_acc did not improve from 0.98454\n",
      "Epoch 838/1000\n",
      "50/50 [==============================] - 30s 603ms/step - loss: 0.0743 - acc: 0.9723 - val_loss: 0.0631 - val_acc: 0.9665\n",
      "\n",
      "Epoch 00838: val_acc did not improve from 0.98454\n",
      "Epoch 839/1000\n",
      "50/50 [==============================] - 30s 607ms/step - loss: 0.0556 - acc: 0.9785 - val_loss: 0.0877 - val_acc: 0.9613\n",
      "\n",
      "Epoch 00839: val_acc did not improve from 0.98454\n",
      "Epoch 840/1000\n",
      "50/50 [==============================] - 27s 547ms/step - loss: 0.0639 - acc: 0.9750 - val_loss: 0.0974 - val_acc: 0.9613\n",
      "\n",
      "Epoch 00840: val_acc did not improve from 0.98454\n",
      "Epoch 841/1000\n",
      "50/50 [==============================] - 31s 622ms/step - loss: 0.0465 - acc: 0.9803 - val_loss: 0.0620 - val_acc: 0.9691\n",
      "\n",
      "Epoch 00841: val_acc did not improve from 0.98454\n",
      "Epoch 842/1000\n",
      "50/50 [==============================] - 27s 533ms/step - loss: 0.0477 - acc: 0.9803 - val_loss: 0.0956 - val_acc: 0.9536\n",
      "\n",
      "Epoch 00842: val_acc did not improve from 0.98454\n",
      "Epoch 843/1000\n",
      "50/50 [==============================] - 28s 562ms/step - loss: 0.0463 - acc: 0.9817 - val_loss: 0.0639 - val_acc: 0.9716\n",
      "\n",
      "Epoch 00843: val_acc did not improve from 0.98454\n",
      "Epoch 844/1000\n",
      "50/50 [==============================] - 28s 562ms/step - loss: 0.0569 - acc: 0.9783 - val_loss: 0.0768 - val_acc: 0.9665\n",
      "\n",
      "Epoch 00844: val_acc did not improve from 0.98454\n",
      "Epoch 845/1000\n",
      "50/50 [==============================] - 31s 620ms/step - loss: 0.0818 - acc: 0.9700 - val_loss: 0.0703 - val_acc: 0.9613\n",
      "\n",
      "Epoch 00845: val_acc did not improve from 0.98454\n",
      "Epoch 846/1000\n",
      "50/50 [==============================] - 26s 518ms/step - loss: 0.0667 - acc: 0.9743 - val_loss: 0.0676 - val_acc: 0.9691\n",
      "\n",
      "Epoch 00846: val_acc did not improve from 0.98454\n",
      "Epoch 847/1000\n",
      "50/50 [==============================] - 28s 561ms/step - loss: 0.0619 - acc: 0.9733 - val_loss: 0.0704 - val_acc: 0.9691\n",
      "\n",
      "Epoch 00847: val_acc did not improve from 0.98454\n",
      "Epoch 848/1000\n",
      "50/50 [==============================] - 27s 540ms/step - loss: 0.0761 - acc: 0.9703 - val_loss: 0.0841 - val_acc: 0.9716\n",
      "\n",
      "Epoch 00848: val_acc did not improve from 0.98454\n",
      "Epoch 849/1000\n",
      "50/50 [==============================] - 33s 653ms/step - loss: 0.1944 - acc: 0.9446 - val_loss: 0.2025 - val_acc: 0.9227\n",
      "\n",
      "Epoch 00849: val_acc did not improve from 0.98454\n",
      "Epoch 850/1000\n",
      "50/50 [==============================] - 32s 648ms/step - loss: 0.0960 - acc: 0.9645 - val_loss: 0.0890 - val_acc: 0.9716\n",
      "\n",
      "Epoch 00850: val_acc did not improve from 0.98454\n",
      "Epoch 851/1000\n",
      "50/50 [==============================] - 36s 730ms/step - loss: 0.0550 - acc: 0.9777 - val_loss: 0.1192 - val_acc: 0.9639\n",
      "\n",
      "Epoch 00851: val_acc did not improve from 0.98454\n",
      "Epoch 852/1000\n",
      "50/50 [==============================] - 27s 545ms/step - loss: 0.0598 - acc: 0.9740 - val_loss: 0.1061 - val_acc: 0.9716\n",
      "\n",
      "Epoch 00852: val_acc did not improve from 0.98454\n",
      "Epoch 853/1000\n",
      "50/50 [==============================] - 28s 554ms/step - loss: 0.0625 - acc: 0.9750 - val_loss: 0.0809 - val_acc: 0.9639\n",
      "\n",
      "Epoch 00853: val_acc did not improve from 0.98454\n",
      "Epoch 854/1000\n",
      "50/50 [==============================] - 31s 619ms/step - loss: 0.0705 - acc: 0.9743 - val_loss: 0.0796 - val_acc: 0.9716\n",
      "\n",
      "Epoch 00854: val_acc did not improve from 0.98454\n",
      "Epoch 855/1000\n",
      "50/50 [==============================] - 31s 616ms/step - loss: 0.0632 - acc: 0.9742 - val_loss: 0.0767 - val_acc: 0.9665\n",
      "\n",
      "Epoch 00855: val_acc did not improve from 0.98454\n",
      "Epoch 856/1000\n",
      "50/50 [==============================] - 30s 593ms/step - loss: 0.0634 - acc: 0.9750 - val_loss: 0.0991 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00856: val_acc did not improve from 0.98454\n",
      "Epoch 857/1000\n",
      "50/50 [==============================] - 29s 571ms/step - loss: 0.0439 - acc: 0.9830 - val_loss: 0.0750 - val_acc: 0.9691\n",
      "\n",
      "Epoch 00857: val_acc did not improve from 0.98454\n",
      "Epoch 858/1000\n",
      "50/50 [==============================] - 33s 652ms/step - loss: 0.0525 - acc: 0.9780 - val_loss: 0.0557 - val_acc: 0.9742\n",
      "\n",
      "Epoch 00858: val_acc did not improve from 0.98454\n",
      "Epoch 859/1000\n",
      "50/50 [==============================] - 26s 519ms/step - loss: 0.0515 - acc: 0.9773 - val_loss: 0.0942 - val_acc: 0.9691\n",
      "\n",
      "Epoch 00859: val_acc did not improve from 0.98454\n",
      "Epoch 860/1000\n",
      "50/50 [==============================] - 29s 583ms/step - loss: 0.0533 - acc: 0.9810 - val_loss: 0.0871 - val_acc: 0.9742\n",
      "\n",
      "Epoch 00860: val_acc did not improve from 0.98454\n",
      "Epoch 861/1000\n",
      "50/50 [==============================] - 29s 570ms/step - loss: 0.0516 - acc: 0.9803 - val_loss: 0.1053 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00861: val_acc did not improve from 0.98454\n",
      "Epoch 862/1000\n",
      "50/50 [==============================] - 34s 684ms/step - loss: 0.0511 - acc: 0.9787 - val_loss: 0.1099 - val_acc: 0.9613\n",
      "\n",
      "Epoch 00862: val_acc did not improve from 0.98454\n",
      "Epoch 863/1000\n",
      "50/50 [==============================] - 30s 591ms/step - loss: 0.0460 - acc: 0.9817 - val_loss: 0.0538 - val_acc: 0.9742\n",
      "\n",
      "Epoch 00863: val_acc did not improve from 0.98454\n",
      "Epoch 864/1000\n",
      "50/50 [==============================] - 29s 582ms/step - loss: 0.0510 - acc: 0.9760 - val_loss: 0.0782 - val_acc: 0.9691\n",
      "\n",
      "Epoch 00864: val_acc did not improve from 0.98454\n",
      "Epoch 865/1000\n",
      "50/50 [==============================] - 32s 646ms/step - loss: 0.0518 - acc: 0.9777 - val_loss: 0.0427 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00865: val_acc did not improve from 0.98454\n",
      "Epoch 866/1000\n",
      "50/50 [==============================] - 52s 1s/step - loss: 0.0677 - acc: 0.9743 - val_loss: 0.0824 - val_acc: 0.9562\n",
      "\n",
      "Epoch 00866: val_acc did not improve from 0.98454\n",
      "Epoch 867/1000\n",
      "50/50 [==============================] - 51s 1s/step - loss: 0.0636 - acc: 0.9723 - val_loss: 0.0746 - val_acc: 0.9691\n",
      "\n",
      "Epoch 00867: val_acc did not improve from 0.98454\n",
      "Epoch 868/1000\n",
      "50/50 [==============================] - 36s 727ms/step - loss: 0.0516 - acc: 0.9785 - val_loss: 0.0483 - val_acc: 0.9742\n",
      "\n",
      "Epoch 00868: val_acc did not improve from 0.98454\n",
      "Epoch 869/1000\n",
      "50/50 [==============================] - 26s 516ms/step - loss: 0.0635 - acc: 0.9730 - val_loss: 0.0496 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00869: val_acc did not improve from 0.98454\n",
      "Epoch 870/1000\n",
      "50/50 [==============================] - 35s 699ms/step - loss: 0.0510 - acc: 0.9763 - val_loss: 0.0729 - val_acc: 0.9691\n",
      "\n",
      "Epoch 00870: val_acc did not improve from 0.98454\n",
      "Epoch 871/1000\n",
      "50/50 [==============================] - 37s 740ms/step - loss: 0.0464 - acc: 0.9857 - val_loss: 0.0647 - val_acc: 0.9665\n",
      "\n",
      "Epoch 00871: val_acc did not improve from 0.98454\n",
      "Epoch 872/1000\n",
      "50/50 [==============================] - 31s 629ms/step - loss: 0.0686 - acc: 0.9767 - val_loss: 0.0697 - val_acc: 0.9665\n",
      "\n",
      "Epoch 00872: val_acc did not improve from 0.98454\n",
      "Epoch 873/1000\n",
      "50/50 [==============================] - 31s 621ms/step - loss: 0.0461 - acc: 0.9830 - val_loss: 0.0862 - val_acc: 0.9691\n",
      "\n",
      "Epoch 00873: val_acc did not improve from 0.98454\n",
      "Epoch 874/1000\n",
      "50/50 [==============================] - 27s 534ms/step - loss: 0.0696 - acc: 0.9733 - val_loss: 0.1299 - val_acc: 0.9433\n",
      "\n",
      "Epoch 00874: val_acc did not improve from 0.98454\n",
      "Epoch 875/1000\n",
      "50/50 [==============================] - 26s 526ms/step - loss: 0.0634 - acc: 0.9803 - val_loss: 0.1032 - val_acc: 0.9613\n",
      "\n",
      "Epoch 00875: val_acc did not improve from 0.98454\n",
      "Epoch 876/1000\n",
      "50/50 [==============================] - 26s 527ms/step - loss: 0.0610 - acc: 0.9743 - val_loss: 0.0581 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00876: val_acc did not improve from 0.98454\n",
      "Epoch 877/1000\n",
      "50/50 [==============================] - 26s 512ms/step - loss: 0.0631 - acc: 0.9770 - val_loss: 0.0737 - val_acc: 0.9716\n",
      "\n",
      "Epoch 00877: val_acc did not improve from 0.98454\n",
      "Epoch 878/1000\n",
      "50/50 [==============================] - 29s 571ms/step - loss: 0.0445 - acc: 0.9803 - val_loss: 0.0613 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00878: val_acc did not improve from 0.98454\n",
      "Epoch 879/1000\n",
      "50/50 [==============================] - 34s 677ms/step - loss: 0.0538 - acc: 0.9793 - val_loss: 0.0952 - val_acc: 0.9613\n",
      "\n",
      "Epoch 00879: val_acc did not improve from 0.98454\n",
      "Epoch 880/1000\n",
      "50/50 [==============================] - 34s 673ms/step - loss: 0.0422 - acc: 0.9837 - val_loss: 0.0469 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00880: val_acc did not improve from 0.98454\n",
      "Epoch 881/1000\n",
      "50/50 [==============================] - 29s 590ms/step - loss: 0.0664 - acc: 0.9767 - val_loss: 0.0545 - val_acc: 0.9665\n",
      "\n",
      "Epoch 00881: val_acc did not improve from 0.98454\n",
      "Epoch 882/1000\n",
      "50/50 [==============================] - 34s 689ms/step - loss: 0.0679 - acc: 0.9690 - val_loss: 0.0610 - val_acc: 0.9691\n",
      "\n",
      "Epoch 00882: val_acc did not improve from 0.98454\n",
      "Epoch 883/1000\n",
      "50/50 [==============================] - 30s 605ms/step - loss: 0.0647 - acc: 0.9743 - val_loss: 0.0510 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00883: val_acc did not improve from 0.98454\n",
      "Epoch 884/1000\n",
      "50/50 [==============================] - 27s 541ms/step - loss: 0.0506 - acc: 0.9800 - val_loss: 0.0576 - val_acc: 0.9742\n",
      "\n",
      "Epoch 00884: val_acc did not improve from 0.98454\n",
      "Epoch 885/1000\n",
      "50/50 [==============================] - 28s 569ms/step - loss: 0.0679 - acc: 0.9712 - val_loss: 0.1097 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00885: val_acc did not improve from 0.98454\n",
      "Epoch 886/1000\n",
      "50/50 [==============================] - 39s 780ms/step - loss: 0.0788 - acc: 0.9740 - val_loss: 0.1245 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00886: val_acc did not improve from 0.98454\n",
      "Epoch 887/1000\n",
      "50/50 [==============================] - 39s 774ms/step - loss: 0.0668 - acc: 0.9777 - val_loss: 0.0743 - val_acc: 0.9716\n",
      "\n",
      "Epoch 00887: val_acc did not improve from 0.98454\n",
      "Epoch 888/1000\n",
      "50/50 [==============================] - 41s 824ms/step - loss: 0.1338 - acc: 0.9553 - val_loss: 0.1699 - val_acc: 0.9330\n",
      "\n",
      "Epoch 00888: val_acc did not improve from 0.98454\n",
      "Epoch 889/1000\n",
      "50/50 [==============================] - 26s 525ms/step - loss: 0.0714 - acc: 0.9705 - val_loss: 0.0910 - val_acc: 0.9639\n",
      "\n",
      "Epoch 00889: val_acc did not improve from 0.98454\n",
      "Epoch 890/1000\n",
      "50/50 [==============================] - 25s 491ms/step - loss: 0.0654 - acc: 0.9753 - val_loss: 0.1057 - val_acc: 0.9613\n",
      "\n",
      "Epoch 00890: val_acc did not improve from 0.98454\n",
      "Epoch 891/1000\n",
      "50/50 [==============================] - 29s 585ms/step - loss: 0.0688 - acc: 0.9733 - val_loss: 0.0600 - val_acc: 0.9716\n",
      "\n",
      "Epoch 00891: val_acc did not improve from 0.98454\n",
      "Epoch 892/1000\n",
      "50/50 [==============================] - 37s 735ms/step - loss: 0.0505 - acc: 0.9810 - val_loss: 0.0535 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00892: val_acc did not improve from 0.98454\n",
      "Epoch 893/1000\n",
      "50/50 [==============================] - 36s 716ms/step - loss: 0.0463 - acc: 0.9820 - val_loss: 0.1345 - val_acc: 0.9562\n",
      "\n",
      "Epoch 00893: val_acc did not improve from 0.98454\n",
      "Epoch 894/1000\n",
      "50/50 [==============================] - 29s 575ms/step - loss: 0.0652 - acc: 0.9757 - val_loss: 0.0820 - val_acc: 0.9665\n",
      "\n",
      "Epoch 00894: val_acc did not improve from 0.98454\n",
      "Epoch 895/1000\n",
      "50/50 [==============================] - 30s 594ms/step - loss: 0.0540 - acc: 0.9793 - val_loss: 0.0700 - val_acc: 0.9742\n",
      "\n",
      "Epoch 00895: val_acc did not improve from 0.98454\n",
      "Epoch 896/1000\n",
      "50/50 [==============================] - 39s 774ms/step - loss: 0.0701 - acc: 0.9739 - val_loss: 0.0707 - val_acc: 0.9716\n",
      "\n",
      "Epoch 00896: val_acc did not improve from 0.98454\n",
      "Epoch 897/1000\n",
      "50/50 [==============================] - 36s 712ms/step - loss: 0.0552 - acc: 0.9773 - val_loss: 0.0643 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00897: val_acc did not improve from 0.98454\n",
      "Epoch 898/1000\n",
      "50/50 [==============================] - 31s 628ms/step - loss: 0.0509 - acc: 0.9810 - val_loss: 0.1165 - val_acc: 0.9510\n",
      "\n",
      "Epoch 00898: val_acc did not improve from 0.98454\n",
      "Epoch 899/1000\n",
      "50/50 [==============================] - 35s 710ms/step - loss: 0.0509 - acc: 0.9810 - val_loss: 0.0882 - val_acc: 0.9639\n",
      "\n",
      "Epoch 00899: val_acc did not improve from 0.98454\n",
      "Epoch 900/1000\n",
      "50/50 [==============================] - 62s 1s/step - loss: 0.0529 - acc: 0.9802 - val_loss: 0.0831 - val_acc: 0.9613\n",
      "\n",
      "Epoch 00900: val_acc did not improve from 0.98454\n",
      "Epoch 901/1000\n",
      "50/50 [==============================] - 53s 1s/step - loss: 0.0417 - acc: 0.9820 - val_loss: 0.0488 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00901: val_acc did not improve from 0.98454\n",
      "Epoch 902/1000\n",
      "50/50 [==============================] - 63s 1s/step - loss: 0.0398 - acc: 0.9853 - val_loss: 0.0845 - val_acc: 0.9639\n",
      "\n",
      "Epoch 00902: val_acc did not improve from 0.98454\n",
      "Epoch 903/1000\n",
      "50/50 [==============================] - 52s 1s/step - loss: 0.0575 - acc: 0.9780 - val_loss: 0.0600 - val_acc: 0.9665\n",
      "\n",
      "Epoch 00903: val_acc did not improve from 0.98454\n",
      "Epoch 904/1000\n",
      "50/50 [==============================] - 35s 706ms/step - loss: 0.0527 - acc: 0.9823 - val_loss: 0.1203 - val_acc: 0.9613\n",
      "\n",
      "Epoch 00904: val_acc did not improve from 0.98454\n",
      "Epoch 905/1000\n",
      "50/50 [==============================] - 30s 603ms/step - loss: 0.0424 - acc: 0.9833 - val_loss: 0.1311 - val_acc: 0.9665\n",
      "\n",
      "Epoch 00905: val_acc did not improve from 0.98454\n",
      "Epoch 906/1000\n",
      "50/50 [==============================] - 28s 568ms/step - loss: 0.0468 - acc: 0.9827 - val_loss: 0.1081 - val_acc: 0.9716\n",
      "\n",
      "Epoch 00906: val_acc did not improve from 0.98454\n",
      "Epoch 907/1000\n",
      "50/50 [==============================] - 35s 693ms/step - loss: 0.0643 - acc: 0.9749 - val_loss: 0.0946 - val_acc: 0.9639\n",
      "\n",
      "Epoch 00907: val_acc did not improve from 0.98454\n",
      "Epoch 908/1000\n",
      "50/50 [==============================] - 42s 834ms/step - loss: 0.0535 - acc: 0.9785 - val_loss: 0.1627 - val_acc: 0.9510\n",
      "\n",
      "Epoch 00908: val_acc did not improve from 0.98454\n",
      "Epoch 909/1000\n",
      "50/50 [==============================] - 35s 696ms/step - loss: 0.0403 - acc: 0.9853 - val_loss: 0.1013 - val_acc: 0.9716\n",
      "\n",
      "Epoch 00909: val_acc did not improve from 0.98454\n",
      "Epoch 910/1000\n",
      "50/50 [==============================] - 25s 492ms/step - loss: 0.0554 - acc: 0.9803 - val_loss: 0.0520 - val_acc: 0.9742\n",
      "\n",
      "Epoch 00910: val_acc did not improve from 0.98454\n",
      "Epoch 911/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 26s 512ms/step - loss: 0.0464 - acc: 0.9807 - val_loss: 0.0760 - val_acc: 0.9716\n",
      "\n",
      "Epoch 00911: val_acc did not improve from 0.98454\n",
      "Epoch 912/1000\n",
      "50/50 [==============================] - 29s 584ms/step - loss: 0.0701 - acc: 0.9713 - val_loss: 0.0638 - val_acc: 0.9665\n",
      "\n",
      "Epoch 00912: val_acc did not improve from 0.98454\n",
      "Epoch 913/1000\n",
      "50/50 [==============================] - 27s 538ms/step - loss: 0.0502 - acc: 0.9797 - val_loss: 0.0523 - val_acc: 0.9742\n",
      "\n",
      "Epoch 00913: val_acc did not improve from 0.98454\n",
      "Epoch 914/1000\n",
      "50/50 [==============================] - 30s 595ms/step - loss: 0.0475 - acc: 0.9813 - val_loss: 0.0734 - val_acc: 0.9691\n",
      "\n",
      "Epoch 00914: val_acc did not improve from 0.98454\n",
      "Epoch 915/1000\n",
      "50/50 [==============================] - 30s 601ms/step - loss: 0.0683 - acc: 0.9795 - val_loss: 0.0600 - val_acc: 0.9716\n",
      "\n",
      "Epoch 00915: val_acc did not improve from 0.98454\n",
      "Epoch 916/1000\n",
      "50/50 [==============================] - 28s 565ms/step - loss: 0.0618 - acc: 0.9727 - val_loss: 0.0638 - val_acc: 0.9716\n",
      "\n",
      "Epoch 00916: val_acc did not improve from 0.98454\n",
      "Epoch 917/1000\n",
      "50/50 [==============================] - 26s 524ms/step - loss: 0.0503 - acc: 0.9779 - val_loss: 0.1043 - val_acc: 0.9639\n",
      "\n",
      "Epoch 00917: val_acc did not improve from 0.98454\n",
      "Epoch 918/1000\n",
      "50/50 [==============================] - 26s 527ms/step - loss: 0.0466 - acc: 0.9800 - val_loss: 0.0971 - val_acc: 0.9613\n",
      "\n",
      "Epoch 00918: val_acc did not improve from 0.98454\n",
      "Epoch 919/1000\n",
      "50/50 [==============================] - 29s 576ms/step - loss: 0.0517 - acc: 0.9783 - val_loss: 0.0751 - val_acc: 0.9665\n",
      "\n",
      "Epoch 00919: val_acc did not improve from 0.98454\n",
      "Epoch 920/1000\n",
      "50/50 [==============================] - 24s 473ms/step - loss: 0.0625 - acc: 0.9783 - val_loss: 0.0784 - val_acc: 0.9716\n",
      "\n",
      "Epoch 00920: val_acc did not improve from 0.98454\n",
      "Epoch 921/1000\n",
      "50/50 [==============================] - 24s 480ms/step - loss: 0.0674 - acc: 0.9737 - val_loss: 0.1129 - val_acc: 0.9536\n",
      "\n",
      "Epoch 00921: val_acc did not improve from 0.98454\n",
      "Epoch 922/1000\n",
      "50/50 [==============================] - 24s 471ms/step - loss: 0.0620 - acc: 0.9783 - val_loss: 0.1324 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00922: val_acc did not improve from 0.98454\n",
      "Epoch 923/1000\n",
      "50/50 [==============================] - 33s 657ms/step - loss: 0.0686 - acc: 0.9731 - val_loss: 0.1128 - val_acc: 0.9665\n",
      "\n",
      "Epoch 00923: val_acc did not improve from 0.98454\n",
      "Epoch 924/1000\n",
      "50/50 [==============================] - 27s 536ms/step - loss: 0.0624 - acc: 0.9733 - val_loss: 0.1316 - val_acc: 0.9485\n",
      "\n",
      "Epoch 00924: val_acc did not improve from 0.98454\n",
      "Epoch 925/1000\n",
      "50/50 [==============================] - 26s 529ms/step - loss: 0.0733 - acc: 0.9713 - val_loss: 0.1407 - val_acc: 0.9536\n",
      "\n",
      "Epoch 00925: val_acc did not improve from 0.98454\n",
      "Epoch 926/1000\n",
      "50/50 [==============================] - 28s 563ms/step - loss: 0.0753 - acc: 0.9705 - val_loss: 0.1081 - val_acc: 0.9562\n",
      "\n",
      "Epoch 00926: val_acc did not improve from 0.98454\n",
      "Epoch 927/1000\n",
      "50/50 [==============================] - 27s 543ms/step - loss: 0.0434 - acc: 0.9829 - val_loss: 0.1179 - val_acc: 0.9613\n",
      "\n",
      "Epoch 00927: val_acc did not improve from 0.98454\n",
      "Epoch 928/1000\n",
      "50/50 [==============================] - 29s 577ms/step - loss: 0.0765 - acc: 0.9723 - val_loss: 0.1870 - val_acc: 0.9330\n",
      "\n",
      "Epoch 00928: val_acc did not improve from 0.98454\n",
      "Epoch 929/1000\n",
      "50/50 [==============================] - 33s 657ms/step - loss: 0.0866 - acc: 0.9690 - val_loss: 0.1394 - val_acc: 0.9665\n",
      "\n",
      "Epoch 00929: val_acc did not improve from 0.98454\n",
      "Epoch 930/1000\n",
      "50/50 [==============================] - 28s 562ms/step - loss: 0.0676 - acc: 0.9727 - val_loss: 0.0543 - val_acc: 0.9691\n",
      "\n",
      "Epoch 00930: val_acc did not improve from 0.98454\n",
      "Epoch 931/1000\n",
      "50/50 [==============================] - 32s 643ms/step - loss: 0.0478 - acc: 0.9830 - val_loss: 0.1508 - val_acc: 0.9562\n",
      "\n",
      "Epoch 00931: val_acc did not improve from 0.98454\n",
      "Epoch 932/1000\n",
      "50/50 [==============================] - 37s 750ms/step - loss: 0.0452 - acc: 0.9803 - val_loss: 0.0868 - val_acc: 0.9691\n",
      "\n",
      "Epoch 00932: val_acc did not improve from 0.98454\n",
      "Epoch 933/1000\n",
      "50/50 [==============================] - 31s 626ms/step - loss: 0.0439 - acc: 0.9833 - val_loss: 0.0847 - val_acc: 0.9691\n",
      "\n",
      "Epoch 00933: val_acc did not improve from 0.98454\n",
      "Epoch 934/1000\n",
      "50/50 [==============================] - 24s 489ms/step - loss: 0.0423 - acc: 0.9850 - val_loss: 0.0520 - val_acc: 0.9691\n",
      "\n",
      "Epoch 00934: val_acc did not improve from 0.98454\n",
      "Epoch 935/1000\n",
      "50/50 [==============================] - 33s 654ms/step - loss: 0.0567 - acc: 0.9780 - val_loss: 0.0786 - val_acc: 0.9639\n",
      "\n",
      "Epoch 00935: val_acc did not improve from 0.98454\n",
      "Epoch 936/1000\n",
      "50/50 [==============================] - 33s 665ms/step - loss: 0.0734 - acc: 0.9733 - val_loss: 0.0751 - val_acc: 0.9639\n",
      "\n",
      "Epoch 00936: val_acc did not improve from 0.98454\n",
      "Epoch 937/1000\n",
      "50/50 [==============================] - 33s 667ms/step - loss: 0.0519 - acc: 0.9840 - val_loss: 0.0887 - val_acc: 0.9716\n",
      "\n",
      "Epoch 00937: val_acc did not improve from 0.98454\n",
      "Epoch 938/1000\n",
      "50/50 [==============================] - 30s 602ms/step - loss: 0.0383 - acc: 0.9847 - val_loss: 0.0735 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00938: val_acc did not improve from 0.98454\n",
      "Epoch 939/1000\n",
      "50/50 [==============================] - 33s 650ms/step - loss: 0.0475 - acc: 0.9797 - val_loss: 0.0545 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00939: val_acc did not improve from 0.98454\n",
      "Epoch 940/1000\n",
      "50/50 [==============================] - 29s 583ms/step - loss: 0.0558 - acc: 0.9809 - val_loss: 0.1069 - val_acc: 0.9613\n",
      "\n",
      "Epoch 00940: val_acc did not improve from 0.98454\n",
      "Epoch 941/1000\n",
      "50/50 [==============================] - 31s 618ms/step - loss: 0.0504 - acc: 0.9797 - val_loss: 0.0542 - val_acc: 0.9742\n",
      "\n",
      "Epoch 00941: val_acc did not improve from 0.98454\n",
      "Epoch 942/1000\n",
      "50/50 [==============================] - 43s 859ms/step - loss: 0.0497 - acc: 0.9833 - val_loss: 0.0897 - val_acc: 0.9691\n",
      "\n",
      "Epoch 00942: val_acc did not improve from 0.98454\n",
      "Epoch 943/1000\n",
      "50/50 [==============================] - 45s 909ms/step - loss: 0.0452 - acc: 0.9847 - val_loss: 0.0527 - val_acc: 0.9845\n",
      "\n",
      "Epoch 00943: val_acc improved from 0.98454 to 0.98454, saving model to best_cnn.h5\n",
      "Epoch 944/1000\n",
      "50/50 [==============================] - 37s 731ms/step - loss: 0.0577 - acc: 0.9730 - val_loss: 0.0543 - val_acc: 0.9716\n",
      "\n",
      "Epoch 00944: val_acc did not improve from 0.98454\n",
      "Epoch 945/1000\n",
      "50/50 [==============================] - 50s 1000ms/step - loss: 0.0429 - acc: 0.9820 - val_loss: 0.0455 - val_acc: 0.9820\n",
      "\n",
      "Epoch 00945: val_acc did not improve from 0.98454\n",
      "Epoch 946/1000\n",
      "50/50 [==============================] - 55s 1s/step - loss: 0.0458 - acc: 0.9827 - val_loss: 0.0664 - val_acc: 0.9742\n",
      "\n",
      "Epoch 00946: val_acc did not improve from 0.98454\n",
      "Epoch 947/1000\n",
      "50/50 [==============================] - 32s 645ms/step - loss: 0.0511 - acc: 0.9795 - val_loss: 0.0608 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00947: val_acc did not improve from 0.98454\n",
      "Epoch 948/1000\n",
      "50/50 [==============================] - 28s 562ms/step - loss: 0.0434 - acc: 0.9807 - val_loss: 0.1410 - val_acc: 0.9510\n",
      "\n",
      "Epoch 00948: val_acc did not improve from 0.98454\n",
      "Epoch 949/1000\n",
      "50/50 [==============================] - 32s 640ms/step - loss: 0.0477 - acc: 0.9837 - val_loss: 0.1041 - val_acc: 0.9562\n",
      "\n",
      "Epoch 00949: val_acc did not improve from 0.98454\n",
      "Epoch 950/1000\n",
      "50/50 [==============================] - 36s 722ms/step - loss: 0.0534 - acc: 0.9770 - val_loss: 0.0498 - val_acc: 0.9716\n",
      "\n",
      "Epoch 00950: val_acc did not improve from 0.98454\n",
      "Epoch 951/1000\n",
      "50/50 [==============================] - 32s 646ms/step - loss: 0.0598 - acc: 0.9810 - val_loss: 0.0566 - val_acc: 0.9691\n",
      "\n",
      "Epoch 00951: val_acc did not improve from 0.98454\n",
      "Epoch 952/1000\n",
      "50/50 [==============================] - 30s 602ms/step - loss: 0.0947 - acc: 0.9647 - val_loss: 0.1502 - val_acc: 0.9381\n",
      "\n",
      "Epoch 00952: val_acc did not improve from 0.98454\n",
      "Epoch 953/1000\n",
      "50/50 [==============================] - 28s 568ms/step - loss: 0.0577 - acc: 0.9760 - val_loss: 0.0706 - val_acc: 0.9691\n",
      "\n",
      "Epoch 00953: val_acc did not improve from 0.98454\n",
      "Epoch 954/1000\n",
      "50/50 [==============================] - 38s 759ms/step - loss: 0.0625 - acc: 0.9793 - val_loss: 0.0652 - val_acc: 0.9691\n",
      "\n",
      "Epoch 00954: val_acc did not improve from 0.98454\n",
      "Epoch 955/1000\n",
      "50/50 [==============================] - 36s 728ms/step - loss: 0.0586 - acc: 0.9769 - val_loss: 0.0932 - val_acc: 0.9613\n",
      "\n",
      "Epoch 00955: val_acc did not improve from 0.98454\n",
      "Epoch 956/1000\n",
      "50/50 [==============================] - 31s 618ms/step - loss: 0.0564 - acc: 0.9770 - val_loss: 0.0682 - val_acc: 0.9691\n",
      "\n",
      "Epoch 00956: val_acc did not improve from 0.98454\n",
      "Epoch 957/1000\n",
      "50/50 [==============================] - 31s 616ms/step - loss: 0.0580 - acc: 0.9787 - val_loss: 0.0702 - val_acc: 0.9639\n",
      "\n",
      "Epoch 00957: val_acc did not improve from 0.98454\n",
      "Epoch 958/1000\n",
      "50/50 [==============================] - 29s 579ms/step - loss: 0.0570 - acc: 0.9770 - val_loss: 0.0460 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00958: val_acc did not improve from 0.98454\n",
      "Epoch 959/1000\n",
      "50/50 [==============================] - 30s 602ms/step - loss: 0.0456 - acc: 0.9820 - val_loss: 0.0842 - val_acc: 0.9691\n",
      "\n",
      "Epoch 00959: val_acc did not improve from 0.98454\n",
      "Epoch 960/1000\n",
      "50/50 [==============================] - 28s 562ms/step - loss: 0.0631 - acc: 0.9743 - val_loss: 0.0548 - val_acc: 0.9716\n",
      "\n",
      "Epoch 00960: val_acc did not improve from 0.98454\n",
      "Epoch 961/1000\n",
      "50/50 [==============================] - 30s 593ms/step - loss: 0.0370 - acc: 0.9860 - val_loss: 0.0617 - val_acc: 0.9716\n",
      "\n",
      "Epoch 00961: val_acc did not improve from 0.98454\n",
      "Epoch 962/1000\n",
      "50/50 [==============================] - 28s 555ms/step - loss: 0.0540 - acc: 0.9797 - val_loss: 0.1041 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00962: val_acc did not improve from 0.98454\n",
      "Epoch 963/1000\n",
      "50/50 [==============================] - 28s 550ms/step - loss: 0.0860 - acc: 0.9717 - val_loss: 0.0637 - val_acc: 0.9742\n",
      "\n",
      "Epoch 00963: val_acc did not improve from 0.98454\n",
      "Epoch 964/1000\n",
      "50/50 [==============================] - 30s 601ms/step - loss: 0.0660 - acc: 0.9743 - val_loss: 0.1059 - val_acc: 0.9562\n",
      "\n",
      "Epoch 00964: val_acc did not improve from 0.98454\n",
      "Epoch 965/1000\n",
      "50/50 [==============================] - 30s 598ms/step - loss: 0.0677 - acc: 0.9762 - val_loss: 0.0679 - val_acc: 0.9716\n",
      "\n",
      "Epoch 00965: val_acc did not improve from 0.98454\n",
      "Epoch 966/1000\n",
      "50/50 [==============================] - 32s 645ms/step - loss: 0.0384 - acc: 0.9873 - val_loss: 0.0866 - val_acc: 0.9691\n",
      "\n",
      "Epoch 00966: val_acc did not improve from 0.98454\n",
      "Epoch 967/1000\n",
      "50/50 [==============================] - 31s 620ms/step - loss: 0.0482 - acc: 0.9793 - val_loss: 0.0669 - val_acc: 0.9691\n",
      "\n",
      "Epoch 00967: val_acc did not improve from 0.98454\n",
      "Epoch 968/1000\n",
      "50/50 [==============================] - 28s 560ms/step - loss: 0.0456 - acc: 0.9840 - val_loss: 0.1122 - val_acc: 0.9536\n",
      "\n",
      "Epoch 00968: val_acc did not improve from 0.98454\n",
      "Epoch 969/1000\n",
      "50/50 [==============================] - 28s 551ms/step - loss: 0.0480 - acc: 0.9820 - val_loss: 0.0794 - val_acc: 0.9691\n",
      "\n",
      "Epoch 00969: val_acc did not improve from 0.98454\n",
      "Epoch 970/1000\n",
      "50/50 [==============================] - 27s 545ms/step - loss: 0.0362 - acc: 0.9860 - val_loss: 0.0618 - val_acc: 0.9716\n",
      "\n",
      "Epoch 00970: val_acc did not improve from 0.98454\n",
      "Epoch 971/1000\n",
      "50/50 [==============================] - 28s 565ms/step - loss: 0.0854 - acc: 0.9743 - val_loss: 0.0741 - val_acc: 0.9639\n",
      "\n",
      "Epoch 00971: val_acc did not improve from 0.98454\n",
      "Epoch 972/1000\n",
      "50/50 [==============================] - 29s 589ms/step - loss: 0.0903 - acc: 0.9669 - val_loss: 0.0782 - val_acc: 0.9665\n",
      "\n",
      "Epoch 00972: val_acc did not improve from 0.98454\n",
      "Epoch 973/1000\n",
      "50/50 [==============================] - 35s 698ms/step - loss: 0.0852 - acc: 0.9722 - val_loss: 0.1209 - val_acc: 0.9356\n",
      "\n",
      "Epoch 00973: val_acc did not improve from 0.98454\n",
      "Epoch 974/1000\n",
      "50/50 [==============================] - 32s 647ms/step - loss: 0.0656 - acc: 0.9740 - val_loss: 0.0562 - val_acc: 0.9613\n",
      "\n",
      "Epoch 00974: val_acc did not improve from 0.98454\n",
      "Epoch 975/1000\n",
      "50/50 [==============================] - 29s 588ms/step - loss: 0.0528 - acc: 0.9787 - val_loss: 0.0501 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00975: val_acc did not improve from 0.98454\n",
      "Epoch 976/1000\n",
      "50/50 [==============================] - 29s 588ms/step - loss: 0.0668 - acc: 0.9727 - val_loss: 0.0580 - val_acc: 0.9665\n",
      "\n",
      "Epoch 00976: val_acc did not improve from 0.98454\n",
      "Epoch 977/1000\n",
      "50/50 [==============================] - 28s 565ms/step - loss: 0.0464 - acc: 0.9837 - val_loss: 0.0593 - val_acc: 0.9665\n",
      "\n",
      "Epoch 00977: val_acc did not improve from 0.98454\n",
      "Epoch 978/1000\n",
      "50/50 [==============================] - 28s 551ms/step - loss: 0.0657 - acc: 0.9749 - val_loss: 0.1476 - val_acc: 0.9407\n",
      "\n",
      "Epoch 00978: val_acc did not improve from 0.98454\n",
      "Epoch 979/1000\n",
      "50/50 [==============================] - 27s 545ms/step - loss: 0.0546 - acc: 0.9763 - val_loss: 0.1091 - val_acc: 0.9485\n",
      "\n",
      "Epoch 00979: val_acc did not improve from 0.98454\n",
      "Epoch 980/1000\n",
      "50/50 [==============================] - 40s 794ms/step - loss: 0.0579 - acc: 0.9750 - val_loss: 0.0926 - val_acc: 0.9639\n",
      "\n",
      "Epoch 00980: val_acc did not improve from 0.98454\n",
      "Epoch 981/1000\n",
      "50/50 [==============================] - 51s 1s/step - loss: 0.0598 - acc: 0.9787 - val_loss: 0.1211 - val_acc: 0.9485\n",
      "\n",
      "Epoch 00981: val_acc did not improve from 0.98454\n",
      "Epoch 982/1000\n",
      "50/50 [==============================] - 35s 697ms/step - loss: 0.0584 - acc: 0.9760 - val_loss: 0.0847 - val_acc: 0.9613\n",
      "\n",
      "Epoch 00982: val_acc did not improve from 0.98454\n",
      "Epoch 983/1000\n",
      "50/50 [==============================] - 35s 706ms/step - loss: 0.0562 - acc: 0.9783 - val_loss: 0.1325 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00983: val_acc did not improve from 0.98454\n",
      "Epoch 984/1000\n",
      "50/50 [==============================] - 41s 815ms/step - loss: 0.0571 - acc: 0.9790 - val_loss: 0.0757 - val_acc: 0.9691\n",
      "\n",
      "Epoch 00984: val_acc did not improve from 0.98454\n",
      "Epoch 985/1000\n",
      "50/50 [==============================] - 37s 737ms/step - loss: 0.0577 - acc: 0.9775 - val_loss: 0.0781 - val_acc: 0.9665\n",
      "\n",
      "Epoch 00985: val_acc did not improve from 0.98454\n",
      "Epoch 986/1000\n",
      "50/50 [==============================] - 33s 668ms/step - loss: 0.0640 - acc: 0.9730 - val_loss: 0.1088 - val_acc: 0.9639\n",
      "\n",
      "Epoch 00986: val_acc did not improve from 0.98454\n",
      "Epoch 987/1000\n",
      "50/50 [==============================] - 31s 611ms/step - loss: 0.0406 - acc: 0.9823 - val_loss: 0.0958 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00987: val_acc did not improve from 0.98454\n",
      "Epoch 988/1000\n",
      "50/50 [==============================] - 30s 599ms/step - loss: 0.0465 - acc: 0.9823 - val_loss: 0.1363 - val_acc: 0.9510\n",
      "\n",
      "Epoch 00988: val_acc did not improve from 0.98454\n",
      "Epoch 989/1000\n",
      "50/50 [==============================] - 31s 615ms/step - loss: 0.0514 - acc: 0.9810 - val_loss: 0.1202 - val_acc: 0.9562\n",
      "\n",
      "Epoch 00989: val_acc did not improve from 0.98454\n",
      "Epoch 990/1000\n",
      "50/50 [==============================] - 31s 614ms/step - loss: 0.0447 - acc: 0.9810 - val_loss: 0.0635 - val_acc: 0.9691\n",
      "\n",
      "Epoch 00990: val_acc did not improve from 0.98454\n",
      "Epoch 991/1000\n",
      "50/50 [==============================] - 28s 552ms/step - loss: 0.0452 - acc: 0.9813 - val_loss: 0.0810 - val_acc: 0.9665\n",
      "\n",
      "Epoch 00991: val_acc did not improve from 0.98454\n",
      "Epoch 992/1000\n",
      "50/50 [==============================] - 41s 825ms/step - loss: 0.0553 - acc: 0.9777 - val_loss: 0.1040 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00992: val_acc did not improve from 0.98454\n",
      "Epoch 993/1000\n",
      "50/50 [==============================] - 37s 742ms/step - loss: 0.0410 - acc: 0.9830 - val_loss: 0.1172 - val_acc: 0.9613\n",
      "\n",
      "Epoch 00993: val_acc did not improve from 0.98454\n",
      "Epoch 994/1000\n",
      "50/50 [==============================] - 29s 574ms/step - loss: 0.0517 - acc: 0.9797 - val_loss: 0.0855 - val_acc: 0.9691\n",
      "\n",
      "Epoch 00994: val_acc did not improve from 0.98454\n",
      "Epoch 995/1000\n",
      "50/50 [==============================] - 27s 537ms/step - loss: 0.0771 - acc: 0.9727 - val_loss: 0.0596 - val_acc: 0.9691\n",
      "\n",
      "Epoch 00995: val_acc did not improve from 0.98454\n",
      "Epoch 996/1000\n",
      "50/50 [==============================] - 25s 505ms/step - loss: 0.0687 - acc: 0.9747 - val_loss: 0.0911 - val_acc: 0.9665\n",
      "\n",
      "Epoch 00996: val_acc did not improve from 0.98454\n",
      "Epoch 997/1000\n",
      "50/50 [==============================] - 25s 507ms/step - loss: 0.0559 - acc: 0.9793 - val_loss: 0.1227 - val_acc: 0.9639\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00997: val_acc did not improve from 0.98454\n",
      "Epoch 998/1000\n",
      "50/50 [==============================] - 25s 493ms/step - loss: 0.0641 - acc: 0.9767 - val_loss: 0.0628 - val_acc: 0.9742\n",
      "\n",
      "Epoch 00998: val_acc did not improve from 0.98454\n",
      "Epoch 999/1000\n",
      "50/50 [==============================] - 24s 488ms/step - loss: 0.0628 - acc: 0.9732 - val_loss: 0.0593 - val_acc: 0.9691\n",
      "\n",
      "Epoch 00999: val_acc did not improve from 0.98454\n",
      "Epoch 1000/1000\n",
      "50/50 [==============================] - 29s 573ms/step - loss: 0.0561 - acc: 0.9783 - val_loss: 0.1111 - val_acc: 0.9639\n",
      "\n",
      "Epoch 01000: val_acc did not improve from 0.98454\n"
     ]
    }
   ],
   "source": [
    "# We'll stop training if no improvement after some epochs\n",
    "earlystopper = EarlyStopping(monitor='val_acc', patience=500, verbose=1)\n",
    "\n",
    "# Save the best model during the traning\n",
    "checkpointer = ModelCheckpoint('best_cnn.h5',\n",
    "                                monitor='val_acc',\n",
    "                                verbose=1,\n",
    "                                save_best_only=True,\n",
    "                                save_weights_only=True)\n",
    "\n",
    "####### Build CNN \n",
    "model = Sequential()\n",
    "model.add(Conv2D(5, kernel_size=3, input_shape=(img_width, img_height,3), activation='relu', padding='same'))\n",
    "model.add(MaxPool2D(2))\n",
    "\n",
    "model.add(Conv2D(10, kernel_size=3, activation='relu', padding='same'))\n",
    "model.add(MaxPool2D(2))\n",
    "\n",
    "model.add(Conv2D(50, kernel_size=3, activation='relu', padding='same'))\n",
    "model.add(MaxPool2D(2))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(units=100, activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(units=100, activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(units=100, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(train_y.columns.size, activation='softmax'))\n",
    "#######\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train\n",
    "training = model.fit_generator(generator.flow(train_X,train_y, batch_size=60),\n",
    "                        epochs = 1000,\n",
    "                        validation_data = [val_X, val_y],\n",
    "                        steps_per_epoch = 50,\n",
    "                        callbacks = [earlystopper, checkpointer])\n",
    "\n",
    "# Get the best saved weights\n",
    "model.load_weights('best_cnn.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Evaluate CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(training, model, test_X, test_y, field_name, savename1, savename2):\n",
    "    \"\"\"\n",
    "    Model evaluation: plots, classification report\n",
    "    @param training: model training history\n",
    "    @param model: trained model\n",
    "    @param test_X: features \n",
    "    @param test_y: labels\n",
    "    @param field_name: label name to display on plots\n",
    "    \"\"\"\n",
    "    line_width = 1\n",
    "\n",
    "    ## Trained model analysis and evaluation\n",
    "    f, ax = plt.subplots(2,1, figsize=(5,5))\n",
    "    ax[0].plot(training.history['loss'], label=\"Train loss\", linewidth=line_width)\n",
    "    ax[0].plot(training.history['val_loss'], label=\"Validation loss\", linewidth=line_width)\n",
    "    ax[0].set_title('%s: Loss' % field_name)\n",
    "    ax[0].set_xlabel('Epoch')\n",
    "    ax[0].set_ylabel('Loss')\n",
    "    leg0 = ax[0].legend()\n",
    "    for line in leg0.get_lines():\n",
    "        line.set_linewidth(2)\n",
    "\n",
    "    # Hide the right and top spines\n",
    "    ax[0].spines['right'].set_visible(False)\n",
    "    ax[0].spines['top'].set_visible(False)\n",
    "\n",
    "    # Accuracy\n",
    "    ax[1].plot(training.history['acc'], label=\"Train accuracy\", linewidth=line_width)\n",
    "    ax[1].plot(training.history['val_acc'], label=\"Validation accuracy\", linewidth=line_width)\n",
    "    ax[1].set_title('%s: Accuracy' % field_name)\n",
    "    ax[1].set_xlabel('Epoch')\n",
    "    ax[1].set_ylabel('Accuracy')\n",
    "    leg1 = ax[1].legend()    \n",
    "    for line in leg1.get_lines():\n",
    "        line.set_linewidth(2)\n",
    "\n",
    "    # Hide the right and top spines\n",
    "    ax[1].spines['right'].set_visible(False)\n",
    "    ax[1].spines['top'].set_visible(False)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"{}.png\".format(savename1))\n",
    "    plt.show()\n",
    "\n",
    "    # Accuracy by class\n",
    "    plt.figure(figsize=(3, 4))\n",
    "    test_pred = model.predict(test_X)\n",
    "    acc_by_subspecies = np.logical_and((test_pred > 0.5), test_y).sum()/test_y.sum()\n",
    "    acc_by_subspecies.plot(kind='bar', title='Accuracy by class',\n",
    "                          align='center', width=0.8)\n",
    "    plt.ylabel('Accuracy')\n",
    "    for spine_i, spine in enumerate(plt.gca().spines.values()):\n",
    "        if spine_i == 1 or spine_i == 3:\n",
    "            spine.set_visible(False)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"{}.png\".format(savename2))\n",
    "    plt.show()\n",
    "\n",
    "    # Print metrics\n",
    "    print(\"Classification report\")\n",
    "    test_pred = np.argmax(test_pred, axis=1)\n",
    "    test_truth = np.argmax(test_y.values, axis=1)\n",
    "    print(metrics.classification_report(test_truth, test_pred, target_names=test_y.columns))\n",
    "\n",
    "    # Loss function and accuracy\n",
    "    test_res = model.evaluate(test_X, test_y.values, verbose=0)\n",
    "    print('Loss function: %s, accuracy:' % test_res[0], test_res[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c23dbbd68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c25624710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "                            precision    recall  f1-score   support\n",
      "\n",
      "Varroa, Small Hive Beetles       0.84      0.89      0.87       102\n",
      "              ant problems       1.00      1.00      1.00       117\n",
      "  few varrao, hive beetles       0.92      0.86      0.89       139\n",
      "                   healthy       1.00      1.00      1.00       866\n",
      "         hive being robbed       0.97      1.00      0.98        61\n",
      "             missing queen       1.00      0.75      0.86         8\n",
      "\n",
      "               avg / total       0.98      0.98      0.98      1293\n",
      "\n",
      "Loss function: 0.07741288123821605, accuracy: 0.9752513534416086\n"
     ]
    }
   ],
   "source": [
    "# Call evaluation with accuracy curves and bar plot\n",
    "eval_model(training, model, \n",
    "           test_X, test_y, \n",
    "          'Health classification',\n",
    "          'cnn_curves', 'cnn_accs')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
